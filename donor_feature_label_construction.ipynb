{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Donor Feature Schema for DonorsChoose\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements a comprehensive, reusable donor feature engineering pipeline that:\n",
    "\n",
    "1. **Re-uses existing feature engineering work** while consolidating near-duplicate concepts\n",
    "2. **Separates features by time scope**:\n",
    "   - `STATIC`: Does not depend on reference time T (or treated as fixed once per donor)\n",
    "   - `AS_OF_T`: Uses cumulative data up to time T\n",
    "   - `WINDOWED`: Uses specific lookback windows relative to T\n",
    "   - `LABEL`: Natural target variables for various use cases\n",
    "\n",
    "3. **Pulls from 5 main data sources**:\n",
    "   - Donor Project Records (gifts/donations)\n",
    "   - Email Events (12-month summary)\n",
    "   - Site Events (FY25-26 activity)\n",
    "   - Monthly Donation Program (all-time)\n",
    "   - Share Events (all-time)\n",
    "   - Plus: ZIP-level ACS demographics\n",
    "\n",
    "## Feature Categories\n",
    "\n",
    "The schema includes approximately 150+ features across these domains:\n",
    "\n",
    "1. **Identity & Demographics** (ZIP-based ACS)\n",
    "2. **Lifetime Giving Behavior** (tenure, amounts, patterns)\n",
    "3. **Windowed Giving** (3m, 12m, 36m activity + velocity)\n",
    "4. **Channel/Payment Mix** (DAF, green, gift cards, etc.)\n",
    "5. **Monthly Program Dynamics** (subscription behavior)\n",
    "6. **Teacher/School/Content Preferences** (loyalty vs diversification)\n",
    "7. **Seasonality** (back-to-school, year-end, etc.)\n",
    "8. **Email Engagement** (opens, clicks, velocity)\n",
    "9. **Site Behavior** (sessions, pages, devices)\n",
    "10. **Share Activity** (social sharing patterns)\n",
    "11. **Project Outcomes** (fully-funded rates, matching)\n",
    "12. **Labels** (optional, for various prediction tasks)\n",
    "\n",
    "## Key Design Principles\n",
    "\n",
    "- **No duplicate concepts**: Single distance metric, single velocity calculation pattern\n",
    "- **Consistent windowing**: 3-month (short), 12-month (mid), 36-month (long)\n",
    "- **Defensive coding**: Small epsilon values prevent division by zero\n",
    "- **Separation of concerns**: Feature building â‰  imputation/encoding\n",
    "- **Time-relative**: All features parameterized by reference time T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyproj import Geod\n",
    "from typing import Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Helper Functions\n",
    "\n",
    "These utility functions support the main feature engineering pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Label configuration constants\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "MIDLEVEL_THRESHOLD = 1000.0           # annual midlevel threshold for \"grand\" revenue\n",
    "TIPTOP_THRESHOLD = 10000.0            # threshold for \"major gift\" classification\n",
    "LARGE_SINGLE_GIFT_THRESHOLD = 500.0   # large single gift threshold (e.g., $500)\n",
    "TIME_TO_NEXT_GIFT_CENSOR_DAYS = 366   # censoring value for time-to-next-gift labels\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Core validation and utility helpers\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def _validate_dpr_for_labels(df_dpr: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Ensure df_dpr has the minimum required columns for label construction.\n",
    "    Raises a ValueError if core columns are missing.\n",
    "    \"\"\"\n",
    "    required = {\"donor_id\", \"payment_date\", \"payment_amount\"}\n",
    "    missing = required - set(df_dpr.columns)\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            f\"df_dpr is missing required columns for label construction: {missing}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def _future_window(df, date_col: str, T: pd.Timestamp, horizon_days: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generic helper: slice df to [T, T + horizon_days).\n",
    "    Returns an empty DataFrame if df is None or empty.\n",
    "    \"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        return pd.DataFrame(columns=[date_col])\n",
    "    df = df.copy()\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    end = T + pd.Timedelta(days=horizon_days)\n",
    "    mask = (df[date_col] >= T) & (df[date_col] < end)\n",
    "    return df.loc[mask]\n",
    "\n",
    "\n",
    "def _any_by_donor(df, donor_col: str = \"donor_id\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Return 1/0 per donor for \"any rows in df\".\n",
    "    Empty input returns an empty Series.\n",
    "    \"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        return pd.Series([], dtype=\"float64\", name=donor_col)\n",
    "    return df.groupby(donor_col).size().gt(0).astype(float)\n",
    "\n",
    "\n",
    "def _count_by_donor(df, donor_col: str = \"donor_id\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Return count of rows per donor.\n",
    "    \"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        return pd.Series([], dtype=\"float64\", name=donor_col)\n",
    "    return df.groupby(donor_col).size().astype(float)\n",
    "\n",
    "\n",
    "def _sum_by_donor(df, value_col: str, donor_col: str = \"donor_id\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Sum of value_col per donor.\n",
    "    \"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        return pd.Series([], dtype=\"float64\", name=donor_col)\n",
    "    return df.groupby(donor_col)[value_col].sum().astype(float)\n",
    "\n",
    "\n",
    "def _max_by_donor(df, value_col: str, donor_col: str = \"donor_id\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Max of value_col per donor.\n",
    "    \"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        return pd.Series([], dtype=\"float64\", name=donor_col)\n",
    "    return df.groupby(donor_col)[value_col].max().astype(float)\n",
    "\n",
    "\n",
    "def haversine_miles(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Compute great-circle distance between two points in miles using Haversine formula.\n",
    "    \n",
    "    All arguments can be scalars or pandas Series (for vectorized computation).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lat1, lon1 : float or pd.Series\n",
    "        Latitude and longitude of first point(s) in decimal degrees\n",
    "    lat2, lon2 : float or pd.Series\n",
    "        Latitude and longitude of second point(s) in decimal degrees\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    distance : float or pd.Series\n",
    "        Great-circle distance in miles\n",
    "    \"\"\"\n",
    "    # Earth's radius in miles\n",
    "    R = 3958.8\n",
    "    \n",
    "    # Convert all coordinates from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    # Calculate differences\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    # Haversine formula\n",
    "    a = np.sin(dlat / 2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    \n",
    "    return R * c\n",
    "\n",
    "def entropy_vectorized(df, group_col, cat_col):\n",
    "    \"\"\"\n",
    "    Calculate Shannon entropy in a fully vectorized way.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing the data\n",
    "    group_col : str\n",
    "        Column to group by (e.g., 'donor_id')\n",
    "    cat_col : str\n",
    "        Categorical column to calculate entropy for (e.g., 'teacher_id')\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    entropy : pd.Series\n",
    "        Entropy value for each group, indexed by group_col\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return pd.Series(dtype=float, name='entropy')\n",
    "    \n",
    "    # Count occurrences of each category within each group\n",
    "    counts = df.groupby([group_col, cat_col]).size()\n",
    "    \n",
    "    # Calculate probabilities (normalize within each group)\n",
    "    probs = counts.groupby(level=0).transform(lambda x: x / x.sum())\n",
    "    \n",
    "    # Calculate entropy: -sum(p * log(p)) for each group\n",
    "    entropy = -(probs * np.log(probs + 1e-9)).groupby(level=0).sum()\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "\n",
    "def pct_amount(df, flag_col, amount_col='payment_amount'):\n",
    "    \"\"\"\n",
    "    Calculate the fraction of total donation amount coming from flagged rows.\n",
    "    \n",
    "    Example: If flag_col='daf_payment', returns what % of each donor's\n",
    "    total giving came through DAF donations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Donation records with donor_id column\n",
    "    flag_col : str\n",
    "        Name of binary indicator column (1 = flagged, 0 = not flagged)\n",
    "    amount_col : str, default='payment_amount'\n",
    "        Name of amount column to aggregate\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pct : pd.Series\n",
    "        Fraction of amount from flagged rows, indexed by donor_id\n",
    "    \"\"\"\n",
    "\n",
    "    if df.empty:\n",
    "        return pd.Series(dtype=float)\n",
    "    \n",
    "    # Filter THEN group (vectorized, no lambda)\n",
    "    flagged_df = df[df[flag_col] == 1]\n",
    "    amt_flag = flagged_df.groupby('donor_id')[amount_col].sum()\n",
    "    amt_total = df.groupby('donor_id')[amount_col].sum()\n",
    "    amt_flag = amt_flag.reindex(amt_total.index, fill_value=0)\n",
    "    \n",
    "    # Return fraction (with small epsilon to avoid division by zero)\n",
    "    return amt_flag / (amt_total + 1e-6)\n",
    "\n",
    "\n",
    "def pct_count(df, flag_col):\n",
    "    \"\"\"\n",
    "    Calculate the fraction of total gift count coming from flagged rows.\n",
    "    \n",
    "    Example: If flag_col='gift_card_purchase', returns what % of each donor's\n",
    "    gifts were gift card purchases.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Donation records with donor_id column\n",
    "    flag_col : str\n",
    "        Name of binary indicator column\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pct : pd.Series\n",
    "        Fraction of gifts that are flagged, indexed by donor_id\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return pd.Series(dtype=float)\n",
    "        \n",
    "    # Filter THEN group (vectorized)\n",
    "    flagged_df = df[df[flag_col] == 1]\n",
    "    cnt_flag = flagged_df.groupby('donor_id').size()\n",
    "    cnt_total = df.groupby('donor_id').size()\n",
    "    cnt_flag = cnt_flag.reindex(cnt_total.index, fill_value=0)\n",
    "    \n",
    "    return cnt_flag / (cnt_total + 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Group Functions\n",
    "\n",
    "Each function builds a logical group of related features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Identity & Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _identity_and_zip_features(dpr_pre_T, df_zip_acs, md_pre_T=None):\n",
    "    \"\"\"\n",
    "    Build identity features and ZIP-level demographics.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dpr_pre_T : pd.DataFrame\n",
    "        Donation records before T\n",
    "    df_zip_acs : pd.DataFrame\n",
    "        ZIP-level ACS demographics\n",
    "    md_pre_T : pd.DataFrame, optional\n",
    "        Monthly donation data (for ZIP fallback for monthly-only donors)\n",
    "    \"\"\"\n",
    "    # Create base index from all possible donors\n",
    "    all_donor_ids = dpr_pre_T['donor_id'].unique()\n",
    "    if md_pre_T is not None:\n",
    "        all_donor_ids = pd.Index(\n",
    "            pd.unique(\n",
    "                pd.concat([\n",
    "                    pd.Series(dpr_pre_T['donor_id'].unique()),\n",
    "                    pd.Series(md_pre_T['donor_id'].unique())\n",
    "                ])\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    if dpr_pre_T.empty and (md_pre_T is None or md_pre_T.empty):\n",
    "        return pd.DataFrame(index=pd.Index([], name='donor_id'))\n",
    "\n",
    "    # Get ZIP from PROJECT donations (if available)\n",
    "    if not dpr_pre_T.empty:\n",
    "        donor_zip5_from_dpr = (\n",
    "            dpr_pre_T\n",
    "            .sort_values('payment_date')\n",
    "            .groupby('donor_id')['donor_zip']\n",
    "            .first()\n",
    "        )\n",
    "    else:\n",
    "        donor_zip5_from_dpr = pd.Series(dtype=object, name='donor_zip')\n",
    "    \n",
    "    # Get ZIP from MONTHLY data as fallback\n",
    "    if md_pre_T is not None and not md_pre_T.empty and 'donor_zip' in md_pre_T.columns:\n",
    "        donor_zip5_from_monthly = (\n",
    "            md_pre_T\n",
    "            .sort_values('monthly_subscription_joined_date')\n",
    "            .groupby('donor_id')['donor_zip']\n",
    "            .first()\n",
    "        )\n",
    "        # Combine: use dpr ZIP if available, otherwise monthly ZIP\n",
    "        donor_zip5_raw = donor_zip5_from_dpr.combine_first(donor_zip5_from_monthly)\n",
    "    else:\n",
    "        donor_zip5_raw = donor_zip5_from_dpr\n",
    "\n",
    "    # Binary status flags (from dpr_pre_T)\n",
    "    if not dpr_pre_T.empty:\n",
    "        is_teacher = dpr_pre_T.groupby('donor_id')['is_teacher'].max()\n",
    "        is_teacher_referred = dpr_pre_T.groupby('donor_id')['is_teacher_referred'].max()\n",
    "        is_marketing_subscribed = dpr_pre_T.groupby('donor_id')['subscribed_to_marketing_emails'].max()\n",
    "        is_major_gift_donor = dpr_pre_T.groupby('donor_id')['major_gift_donor'].max()\n",
    "        \n",
    "        # Account credit\n",
    "        ever_used_account_credit = (\n",
    "            dpr_pre_T.groupby('donor_id')['account_credit_balance']\n",
    "            .max()\n",
    "            .gt(0)\n",
    "            .astype(int)\n",
    "        )\n",
    "        current_account_credit_balance = (\n",
    "            dpr_pre_T\n",
    "            .sort_values('payment_date')\n",
    "            .groupby('donor_id')['account_credit_balance']\n",
    "            .last()\n",
    "        )\n",
    "    else:\n",
    "        # Create empty series if no dpr data\n",
    "        is_teacher = pd.Series(dtype=float)\n",
    "        is_teacher_referred = pd.Series(dtype=float)\n",
    "        is_marketing_subscribed = pd.Series(dtype=float)\n",
    "        is_major_gift_donor = pd.Series(dtype=float)\n",
    "        ever_used_account_credit = pd.Series(dtype=int)\n",
    "        current_account_credit_balance = pd.Series(dtype=float)\n",
    "\n",
    "    # --- Donor Type Flags (always create for all donors) ---\n",
    "    # Determine which donors appear in each data source\n",
    "    project_donor_ids = set(dpr_pre_T['donor_id'].unique()) if not dpr_pre_T.empty else set()\n",
    "    monthly_donor_ids = set(md_pre_T['donor_id'].unique()) if md_pre_T is not None and not md_pre_T.empty else set()\n",
    "    \n",
    "    # Create flags for all donors in our universe\n",
    "    has_project_history = pd.Series([d in project_donor_ids for d in all_donor_ids], index=all_donor_ids, dtype=int)\n",
    "    has_monthly_history = pd.Series([d in monthly_donor_ids for d in all_donor_ids], index=all_donor_ids, dtype=int)\n",
    "    \n",
    "    # Composite flags for donor segmentation\n",
    "    is_monthly_only_donor = ((has_monthly_history == 1) & (has_project_history == 0)).astype(int)\n",
    "    is_project_only_donor = ((has_project_history == 1) & (has_monthly_history == 0)).astype(int)\n",
    "    is_hybrid_donor = ((has_project_history == 1) & (has_monthly_history == 1)).astype(int)\n",
    "\n",
    "    # --- ZIP / ACS JOIN (dtype-safe) ------------------------------------\n",
    "    donor_zip5 = pd.to_numeric(donor_zip5_raw, errors=\"coerce\")\n",
    "\n",
    "    df_zip_acs = df_zip_acs.copy()\n",
    "    if 'ZIP5' in df_zip_acs.columns:\n",
    "        df_zip_acs = df_zip_acs.set_index('ZIP5')\n",
    "    df_zip_acs.index = pd.to_numeric(df_zip_acs.index, errors=\"coerce\")\n",
    "\n",
    "    acs = donor_zip5.to_frame('donor_zip5').join(\n",
    "        df_zip_acs,\n",
    "        on='donor_zip5',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Assemble output\n",
    "    out = pd.DataFrame(index=donor_zip5.index)\n",
    "    out['donor_zip5'] = donor_zip5\n",
    "    out['has_project_history'] = has_project_history\n",
    "    out['has_monthly_history'] = has_monthly_history\n",
    "    out['is_monthly_only_donor'] = is_monthly_only_donor\n",
    "    out['is_project_only_donor'] = is_project_only_donor\n",
    "    out['is_hybrid_donor'] = is_hybrid_donor\n",
    "    out['is_teacher'] = is_teacher\n",
    "    out['is_teacher_referred'] = is_teacher_referred\n",
    "    out['is_marketing_subscribed'] = is_marketing_subscribed\n",
    "    out['is_major_gift_donor'] = is_major_gift_donor\n",
    "    out['ever_used_account_credit'] = ever_used_account_credit\n",
    "    out['current_account_credit_balance'] = current_account_credit_balance\n",
    "\n",
    "    # ACS features\n",
    "    out['zip_pct_households_with_children'] = acs['pct_households_with_children']\n",
    "    out['zip_pct_in_labor_force'] = acs['pct_in_labor_force']\n",
    "    out['zip_unemployment_rate'] = acs['unemployment_rate']\n",
    "    out['zip_pct_single_parent'] = acs['pct_single_parent']\n",
    "    out['zip_pct_minority'] = acs['pct_minority']\n",
    "    out['zip_avg_household_size'] = acs['avg_household_size']\n",
    "    out['zip_median_age'] = acs['median_age']\n",
    "    out['zip_median_home_value'] = acs['median_home_value']\n",
    "    \n",
    "    if 'total_population' in acs.columns:\n",
    "        out['zip_log_total_population'] = np.log1p(acs['total_population'])\n",
    "    elif 'log_total_population' in acs.columns:\n",
    "        out['zip_log_total_population'] = acs['log_total_population']\n",
    "    else:\n",
    "        out['zip_log_total_population'] = np.nan\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Lifetime Giving Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _lifetime_giving_features(dpr_pre_T, T):\n",
    "    \"\"\"\n",
    "    Build cumulative giving features using all donations before T.\n",
    "    \n",
    "    CORRECTED VERSION with:\n",
    "    - Tenure relative to T (not last_donation_date)\n",
    "    - Gap calculations only for last 730 days\n",
    "    \n",
    "    Features created:\n",
    "    - first_donation_date, last_donation_date: Temporal boundaries\n",
    "    - tenure_days, tenure_years, tenure_bucket: How long donor has been active (relative to T)\n",
    "    - lifetime_gift_count, lifetime_amount: Total volume\n",
    "    - lifetime_median/max/cv_gift_amount: Distribution of gift sizes\n",
    "    - mean/cv_gap_between_gifts_days: Giving rhythm/consistency (last 730 days only)\n",
    "    - max_donation_sequence_number: How many gifts total\n",
    "    - pct_early_gifts_in_lifetime: Concentration in first 3 gifts\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dpr_pre_T : pd.DataFrame\n",
    "        Donor Project Records filtered to payment_date < T\n",
    "    T : pd.Timestamp\n",
    "        Reference time (end of training period)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id\n",
    "    \"\"\"\n",
    "    if dpr_pre_T.empty:\n",
    "        return pd.DataFrame(index=pd.Index([], name='donor_id'))\n",
    "    \n",
    "    dpr = dpr_pre_T.copy()\n",
    "    dpr = dpr.sort_values(['donor_id', 'payment_date'])\n",
    "    \n",
    "    # --- Temporal boundaries ---\n",
    "    first_donation_date = dpr.groupby('donor_id')['payment_date'].min()\n",
    "    last_donation_date = dpr.groupby('donor_id')['payment_date'].max()\n",
    "    \n",
    "    # CORRECTED: Tenure relative to T (end of training period), not last donation\n",
    "    tenure_days = (T - first_donation_date).dt.days\n",
    "    tenure_years = tenure_days / 365.25\n",
    "    \n",
    "    # Bucket tenure for non-linear patterns (categorical)\n",
    "    tenure_bucket_cat = pd.cut(\n",
    "        tenure_years,\n",
    "        bins=[0, 1, 3, 5, 100],\n",
    "        labels=['<1y', '1-3y', '3-5y', '5y+'],\n",
    "        right=False\n",
    "    )\n",
    "    \n",
    "    # Map bucket to lower-bound in YEARS as float64\n",
    "    tenure_bucket = tenure_bucket_cat.map({\n",
    "        '<1y': 0.0,\n",
    "        '1-3y': 1.0,\n",
    "        '3-5y': 3.0,\n",
    "        '5y+': 5.0,\n",
    "    }).astype(float)\n",
    "    \n",
    "    # --- Volume metrics ---\n",
    "    lifetime_gift_count = dpr.groupby('donor_id')['payment_amount'].size()\n",
    "    lifetime_amount = dpr.groupby('donor_id')['payment_amount'].sum()\n",
    "    \n",
    "    # --- Distribution of gift sizes ---\n",
    "    gifts_by_donor = dpr.groupby('donor_id')['payment_amount']\n",
    "    med = gifts_by_donor.median()\n",
    "    mx = gifts_by_donor.max()\n",
    "    mean = gifts_by_donor.mean()\n",
    "    std = gifts_by_donor.std()\n",
    "    # Coefficient of variation: std/mean\n",
    "    # High CV = erratic giving amounts, Low CV = consistent amounts\n",
    "    cv = std / (mean + 1e-9)\n",
    "    \n",
    "    # --- Inter-gift timing patterns (LAST 730 DAYS ONLY) ---\n",
    "    # CORRECTED: Only use donations in last 730 days for gap calculations\n",
    "    cutoff_730 = T - pd.Timedelta(days=730)\n",
    "    dpr_730 = dpr[dpr['payment_date'] >= cutoff_730].copy()\n",
    "    \n",
    "    if not dpr_730.empty:\n",
    "        # Calculate days between consecutive gifts\n",
    "        dpr_730['prev_payment_date'] = dpr_730.groupby('donor_id')['payment_date'].shift(1)\n",
    "        dpr_730['gap_days'] = (dpr_730['payment_date'] - dpr_730['prev_payment_date']).dt.days\n",
    "        \n",
    "        gap_by_donor = dpr_730.groupby('donor_id')['gap_days']\n",
    "        gap_mean = gap_by_donor.mean()\n",
    "        gap_std = gap_by_donor.std()\n",
    "        # CV of gaps: High = irregular giving, Low = regular/predictable\n",
    "        cv_gap = gap_std / (gap_mean + 1e-9)\n",
    "    else:\n",
    "        # No donations in last 730 days\n",
    "        gap_mean = pd.Series(dtype=float)\n",
    "        cv_gap = pd.Series(dtype=float)\n",
    "    \n",
    "    # --- Gift sequence metrics ---\n",
    "    # donation_n = sequential gift number for this donor\n",
    "    max_donation_sequence_number = dpr.groupby('donor_id')['donation_n'].max()\n",
    "    \n",
    "    # What fraction of gifts were in the \"early stage\" (first 3 gifts)?\n",
    "    # High concentration here might indicate acquisition success but poor retention\n",
    "    dpr['is_early_gift'] = dpr['donation_n'] <= 3\n",
    "    pct_early_gifts = dpr.groupby('donor_id')['is_early_gift'].mean()\n",
    "    \n",
    "    # --- Assemble output ---\n",
    "    out = pd.DataFrame(index=lifetime_amount.index)\n",
    "    \n",
    "    out['first_donation_date'] = first_donation_date\n",
    "    out['last_donation_date'] = last_donation_date\n",
    "    out['tenure_days'] = tenure_days\n",
    "    out['tenure_years'] = tenure_years\n",
    "    out['tenure_bucket'] = tenure_bucket\n",
    "    \n",
    "    out['lifetime_gift_count'] = lifetime_gift_count\n",
    "    out['lifetime_amount'] = lifetime_amount\n",
    "    out['lifetime_median_gift_amount'] = med\n",
    "    out['lifetime_max_gift_amount'] = mx\n",
    "    out['lifetime_cv_gift_amount'] = cv\n",
    "    \n",
    "    out['mean_gap_between_gifts_days_last2yr'] = gap_mean\n",
    "    out['cv_gap_between_gifts_days_last2yr'] = cv_gap\n",
    "    \n",
    "    out['max_donation_sequence_number'] = max_donation_sequence_number\n",
    "    out['pct_early_gifts_in_lifetime'] = pct_early_gifts\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Windowed Giving & Velocity\n",
    "\n",
    "These features capture recent activity and trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _windowed_giving_features(dpr_pre_T, dpr_3m, dpr_12m, dpr_36m, dpr_3to12m, dpr_12to36m, T):\n",
    "    \"\"\"\n",
    "    Build windowed giving features and velocity metrics.\n",
    "    \n",
    "    Features created:\n",
    "    - gift_count/amount/median_amount for 3m, 12m, 36m windows\n",
    "    - days_since_last_gift, days_since_second_to_last_gift: Recency\n",
    "    - amount_velocity_0to3_vs_3to12: Is giving accelerating or decelerating?\n",
    "    - amount_velocity_0to12_vs_12to36: Longer-term trend\n",
    "    - count_velocity_0to12_vs_12to36: Frequency trend\n",
    "    \n",
    "    Velocity > 1 indicates acceleration (more recent activity)\n",
    "    Velocity < 1 indicates deceleration (declining activity)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dpr_pre_T : pd.DataFrame\n",
    "        All donations before T\n",
    "    dpr_3m, dpr_12m, dpr_36m : pd.DataFrame\n",
    "        Donations in respective windows\n",
    "    dpr_3to12m, dpr_12to36m : pd.DataFrame\n",
    "        Intermediate periods for velocity calculations\n",
    "    T : pd.Timestamp\n",
    "        Reference time\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id\n",
    "    \"\"\"\n",
    "    out_index = dpr_pre_T['donor_id'].unique()\n",
    "    out = pd.DataFrame(index=out_index)\n",
    "    \n",
    "    # --- 3-month window (recent/short-term) ---\n",
    "    if not dpr_3m.empty:\n",
    "        by_3m = dpr_3m.groupby('donor_id')['payment_amount']\n",
    "        out['gift_count_3m'] = by_3m.size()\n",
    "        out['gift_amount_3m'] = by_3m.sum()\n",
    "        out['median_gift_amount_3m'] = by_3m.median()\n",
    "\n",
    "        # Split by green vs non-green payments\n",
    "        if 'is_green_payment' in dpr_3m.columns:\n",
    "            # Handle 't'/'f' as well as 1/0/True/False\n",
    "            green_mask_3m = dpr_3m['is_green_payment'].isin(['t', 'T', True, 1])\n",
    "            nongreen_mask_3m = dpr_3m['is_green_payment'].isin(['f', 'F', False, 0])\n",
    "\n",
    "            dpr_3m_green = dpr_3m[green_mask_3m]\n",
    "            dpr_3m_nongreen = dpr_3m[nongreen_mask_3m]\n",
    "\n",
    "            by_3m_green = dpr_3m_green.groupby('donor_id')['payment_amount']\n",
    "            by_3m_nongreen = dpr_3m_nongreen.groupby('donor_id')['payment_amount']\n",
    "\n",
    "            out['gift_count_green_3m'] = by_3m_green.size()\n",
    "            out['gift_amount_green_3m'] = by_3m_green.sum()\n",
    "            out['gift_count_nongreen_3m'] = by_3m_nongreen.size()\n",
    "            out['gift_amount_nongreen_3m'] = by_3m_nongreen.sum()\n",
    "    \n",
    "    # --- 12-month window (mid-term) ---\n",
    "    if not dpr_12m.empty:\n",
    "        by_12m = dpr_12m.groupby('donor_id')['payment_amount']\n",
    "        out['gift_count_12m'] = by_12m.size()\n",
    "        out['gift_amount_12m'] = by_12m.sum()\n",
    "        out['median_gift_amount_12m'] = by_12m.median()\n",
    "\n",
    "        if 'is_green_payment' in dpr_12m.columns:\n",
    "            green_mask_12m = dpr_12m['is_green_payment'].isin(['t', 'T', True, 1])\n",
    "            nongreen_mask_12m = dpr_12m['is_green_payment'].isin(['f', 'F', False, 0])\n",
    "\n",
    "            dpr_12m_green = dpr_12m[green_mask_12m]\n",
    "            dpr_12m_nongreen = dpr_12m[nongreen_mask_12m]\n",
    "\n",
    "            by_12m_green = dpr_12m_green.groupby('donor_id')['payment_amount']\n",
    "            by_12m_nongreen = dpr_12m_nongreen.groupby('donor_id')['payment_amount']\n",
    "\n",
    "            out['gift_count_green_12m'] = by_12m_green.size()\n",
    "            out['gift_amount_green_12m'] = by_12m_green.sum()\n",
    "            out['gift_count_nongreen_12m'] = by_12m_nongreen.size()\n",
    "            out['gift_amount_nongreen_12m'] = by_12m_nongreen.sum()\n",
    "    \n",
    "    # --- 36-month window (long-term) ---\n",
    "    if not dpr_36m.empty:\n",
    "        by_36m = dpr_36m.groupby('donor_id')['payment_amount']\n",
    "        out['gift_count_36m'] = by_36m.size()\n",
    "        out['gift_amount_36m'] = by_36m.sum()\n",
    "        out['median_gift_amount_36m'] = by_36m.median()\n",
    "\n",
    "        if 'is_green_payment' in dpr_36m.columns:\n",
    "            green_mask_36m = dpr_36m['is_green_payment'].isin(['t', 'T', True, 1])\n",
    "            nongreen_mask_36m = dpr_36m['is_green_payment'].isin(['f', 'F', False, 0])\n",
    "\n",
    "            dpr_36m_green = dpr_36m[green_mask_36m]\n",
    "            dpr_36m_nongreen = dpr_36m[nongreen_mask_36m]\n",
    "\n",
    "            by_36m_green = dpr_36m_green.groupby('donor_id')['payment_amount']\n",
    "            by_36m_nongreen = dpr_36m_nongreen.groupby('donor_id')['payment_amount']\n",
    "\n",
    "            out['gift_count_green_36m'] = by_36m_green.size()\n",
    "            out['gift_amount_green_36m'] = by_36m_green.sum()\n",
    "            out['gift_count_nongreen_36m'] = by_36m_nongreen.size()\n",
    "            out['gift_amount_nongreen_36m'] = by_36m_nongreen.sum()\n",
    "    \n",
    "    # --- Recency: days since last activity ---\n",
    "    last_gift_date = dpr_pre_T.groupby('donor_id')['payment_date'].max()\n",
    "    out['days_since_last_gift'] = (T - last_gift_date).dt.days\n",
    "    \n",
    "    # Second-to-last gift: helps detect if donor is becoming less frequent\n",
    "    # Sort by payment_date descending and use groupby.nth(1)\n",
    "    second_last = (\n",
    "        dpr_pre_T\n",
    "        .sort_values(['donor_id', 'payment_date'], ascending=[True, False])\n",
    "        .groupby('donor_id')['payment_date']\n",
    "        .nth(1)  # second row per donor, or NaT if fewer than 2\n",
    "    )\n",
    "    \n",
    "    out['days_since_second_to_last_gift'] = (T - second_last).dt.days\n",
    "    \n",
    "    # --- Velocity metrics: are donations accelerating or decelerating? ---\n",
    "    \n",
    "    # Recent 3m vs prior 9m (months 3-12)\n",
    "    amt_0_3 = out.get('gift_amount_3m', pd.Series(0, index=out.index))\n",
    "    amt_3_12 = (\n",
    "        dpr_3to12m.groupby('donor_id')['payment_amount'].sum()\n",
    "        if not dpr_3to12m.empty\n",
    "        else pd.Series(0, index=out.index)\n",
    "    )\n",
    "    # Ratio > 1 means recent giving exceeds prior period\n",
    "    out['amount_velocity_0to3_vs_3to12'] = amt_0_3 / (amt_3_12 + 1e-6)\n",
    "    \n",
    "    # Recent 12m vs prior 24m (months 12-36)\n",
    "    amt_0_12 = out.get('gift_amount_12m', pd.Series(0, index=out.index))\n",
    "    amt_12_36 = (\n",
    "        dpr_12to36m.groupby('donor_id')['payment_amount'].sum()\n",
    "        if not dpr_12to36m.empty\n",
    "        else pd.Series(0, index=out.index)\n",
    "    )\n",
    "    out['amount_velocity_0to12_vs_12to36'] = amt_0_12 / (amt_12_36 + 1e-6)\n",
    "    \n",
    "    # Gift frequency velocity (count-based)\n",
    "    cnt_0_12 = out.get('gift_count_12m', pd.Series(0, index=out.index))\n",
    "    cnt_12_36 = (\n",
    "        dpr_12to36m.groupby('donor_id')['payment_amount'].size()\n",
    "        if not dpr_12to36m.empty\n",
    "        else pd.Series(0, index=out.index)\n",
    "    )\n",
    "    out['count_velocity_0to12_vs_12to36'] = cnt_0_12 / (cnt_12_36 + 1e-6)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Channel & Payment Type Mix\n",
    "\n",
    "How donors give: DAF, green payments, gift cards, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _channel_mix_features(dpr_pre_T, dpr_12m):\n",
    "    \"\"\"\n",
    "    Build features describing how donors give (payment methods, channels).\n",
    "    \n",
    "    For each channel, we compute both lifetime and 12-month versions:\n",
    "    - pct_amount_*: What fraction of $ came through this channel?\n",
    "    - pct_count_*: What fraction of gifts came through this channel?\n",
    "    \n",
    "    Channels covered:\n",
    "    - DAF (Donor Advised Fund) payments\n",
    "    - Green payments (environmental offset donations)\n",
    "    - Gift card purchases\n",
    "    - Big event donations (e.g., giving days)\n",
    "    - Optional donation behavior\n",
    "    - Anonymous gifts\n",
    "    - Classroom essentials projects\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dpr_pre_T : pd.DataFrame\n",
    "        All donations before T (for lifetime metrics)\n",
    "    dpr_12m : pd.DataFrame\n",
    "        Donations in last 12 months (for recent behavior)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id\n",
    "    \"\"\"\n",
    "    out_index = dpr_pre_T['donor_id'].unique()\n",
    "    out = pd.DataFrame(index=out_index)\n",
    "    \n",
    "    # --- DAF donations ---\n",
    "    # DAF = Donor Advised Fund, typically indicates sophisticated/high-capacity donors\n",
    "    out['pct_amount_daf_lifetime'] = pct_amount(dpr_pre_T, 'daf_payment')\n",
    "    out['pct_count_daf_lifetime'] = pct_count(dpr_pre_T, 'daf_payment')\n",
    "    out['pct_amount_daf_12m'] = pct_amount(dpr_12m, 'daf_payment')\n",
    "    out['pct_count_daf_12m'] = pct_count(dpr_12m, 'daf_payment')\n",
    "    \n",
    "    # --- Green payments ---\n",
    "    # Optional environmental offset donations\n",
    "    if 'green_payment_amount' in dpr_pre_T.columns:\n",
    "        by_life = dpr_pre_T.groupby('donor_id')\n",
    "        by_12 = dpr_12m.groupby('donor_id')\n",
    "        \n",
    "        out['pct_amount_green_lifetime'] = (\n",
    "            by_life['green_payment_amount'].sum()\n",
    "            / (by_life['payment_amount'].sum() + 1e-6)\n",
    "        )\n",
    "        out['pct_amount_green_12m'] = (\n",
    "            by_12['green_payment_amount'].sum()\n",
    "            / (by_12['payment_amount'].sum() + 1e-6)\n",
    "        )\n",
    "        out['pct_count_green_lifetime'] = pct_count(dpr_pre_T, 'is_green_payment')\n",
    "        out['pct_count_green_12m'] = pct_count(dpr_12m, 'is_green_payment')\n",
    "    \n",
    "    # --- Gift card purchases ---\n",
    "    # Donors buying gift cards to give to others\n",
    "    out['pct_gifts_gift_card_lifetime'] = pct_count(dpr_pre_T, 'gift_card_purchase')\n",
    "    out['pct_amount_gift_card_lifetime'] = pct_amount(dpr_pre_T, 'gift_card_purchase')\n",
    "    out['pct_gifts_gift_card_12m'] = pct_count(dpr_12m, 'gift_card_purchase')\n",
    "    out['pct_amount_gift_card_12m'] = pct_amount(dpr_12m, 'gift_card_purchase')\n",
    "    \n",
    "    # --- Big event donations ---\n",
    "    # Giving days, campaigns, etc.\n",
    "    out['pct_amount_big_event_lifetime'] = pct_amount(dpr_pre_T, 'payment_on_big_event')\n",
    "    out['pct_count_big_event_lifetime'] = pct_count(dpr_pre_T, 'payment_on_big_event')\n",
    "    out['pct_amount_big_event_12m'] = pct_amount(dpr_12m, 'payment_on_big_event')\n",
    "    out['pct_count_big_event_12m'] = pct_count(dpr_12m, 'payment_on_big_event')\n",
    "    \n",
    "    # --- Optional donation rate ---\n",
    "    # When donors can add optional amounts (e.g., to cover fees)\n",
    "    out['avg_optional_donation_rate_lifetime'] = (\n",
    "        dpr_pre_T.groupby('donor_id')['optional_donation_rate'].mean()\n",
    "    )\n",
    "    out['avg_optional_donation_rate_12m'] = (\n",
    "        dpr_12m.groupby('donor_id')['optional_donation_rate'].mean()\n",
    "    )\n",
    "    \n",
    "    # --- Anonymous donations ---\n",
    "    # Privacy-conscious or humble donors\n",
    "    out['pct_gifts_anonymous_lifetime'] = pct_count(dpr_pre_T, 'donation_is_anonymous')\n",
    "    out['pct_gifts_anonymous_12m'] = pct_count(dpr_12m, 'donation_is_anonymous')\n",
    "    \n",
    "    # --- Classroom essentials ---\n",
    "    # Donations to specific project type (basic supplies)\n",
    "    out['pct_amount_classroom_essentials_lifetime'] = pct_amount(\n",
    "        dpr_pre_T, 'is_classroom_essentials_list'\n",
    "    )\n",
    "    out['pct_amount_classroom_essentials_12m'] = pct_amount(\n",
    "        dpr_12m, 'is_classroom_essentials_list'\n",
    "    )\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Monthly Giving Program\n",
    "\n",
    "Subscription/recurring donation features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _monthly_features(md_pre_T, dpr_pre_T, dpr_12m, T):\n",
    "    \"\"\"\n",
    "    Build monthly subscription program features.\n",
    "    \n",
    "    Features created:\n",
    "    - is_monthly_donor_current: Currently subscribed?\n",
    "    - monthly_lifetime_amount, monthly_amount_12m: How much via subscription\n",
    "    - monthly_median_gift_amount: Typical subscription size\n",
    "    - pct_amount_monthly_*: What fraction of total giving is subscription\n",
    "    - months_on_program, months_since_last_monthly_charge: Tenure metrics\n",
    "    - monthly_longest_streak_months: Longest uninterrupted run\n",
    "    - monthly_joined_before_first_project_gift: Acquisition source indicator\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    md_pre_T : pd.DataFrame\n",
    "        Monthly subscription records where join date < T\n",
    "    dpr_pre_T : pd.DataFrame\n",
    "        All donations before T (for computing fractions)\n",
    "    dpr_12m : pd.DataFrame\n",
    "        Donations in last 12 months\n",
    "    T : pd.Timestamp\n",
    "        Reference time\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id\n",
    "    \"\"\"\n",
    "    if md_pre_T.empty:\n",
    "        return pd.DataFrame(index=dpr_pre_T['donor_id'].unique())\n",
    "    \n",
    "    out_index = pd.Index(md_pre_T['donor_id'].unique(), name='donor_id')\n",
    "    out = pd.DataFrame(index=out_index)\n",
    "    \n",
    "    # --- Current subscription status ---\n",
    "    def is_active(row):\n",
    "        \"\"\"Check if subscription is active at time T\"\"\"\n",
    "        retired = row['monthly_subscription_retired_date']\n",
    "        return (\n",
    "            (row['monthly_subscription_joined_date'] <= T) and\n",
    "            (pd.isna(retired) or (retired > T))\n",
    "        )\n",
    "    \n",
    "    # Vectorized boolean operations (processes all rows at once)\n",
    "    md_pre_T['is_active'] = (\n",
    "        (md_pre_T['monthly_subscription_joined_date'] <= T) &\n",
    "        (md_pre_T['monthly_subscription_retired_date'].isna() | \n",
    "         (md_pre_T['monthly_subscription_retired_date'] > T))\n",
    "    )\n",
    "    \n",
    "    out['is_monthly_donor_current'] = md_pre_T.groupby('donor_id')['is_active'].max().astype(float)\n",
    "    \n",
    "    # --- Lifetime monthly amounts ---\n",
    "    by_life = md_pre_T.groupby('donor_id')\n",
    "    out['monthly_lifetime_amount'] = by_life['monthly_subscription_payment_amount'].sum()\n",
    "    out['monthly_median_gift_amount'] = by_life['monthly_subscription_payment_amount'].median()\n",
    "    \n",
    "    # --- 12-month window ---\n",
    "    if 'charge_date' in md_pre_T.columns:\n",
    "        md_12m = md_pre_T[\n",
    "            (md_pre_T['charge_date'] >= T - pd.DateOffset(months=12)) &\n",
    "            (md_pre_T['charge_date'] < T)\n",
    "        ]\n",
    "        out['monthly_amount_12m'] = (\n",
    "            md_12m.groupby('donor_id')['monthly_subscription_payment_amount'].sum()\n",
    "        )\n",
    "    \n",
    "    # --- Fraction of total giving that's monthly ---\n",
    "    # This shows how dependent a donor is on subscription vs one-time gifts\n",
    "    total_life = dpr_pre_T.groupby('donor_id')['payment_amount'].sum()\n",
    "    total_12 = dpr_12m.groupby('donor_id')['payment_amount'].sum()\n",
    "    \n",
    "    out['pct_amount_monthly_lifetime'] = (\n",
    "        out['monthly_lifetime_amount'] / (total_life + 1e-6)\n",
    "    )\n",
    "    out['pct_amount_monthly_12m'] = (\n",
    "        out.get('monthly_amount_12m', 0) / (total_12 + 1e-6)\n",
    "    )\n",
    "    \n",
    "    # --- Months on program ---\n",
    "    # How long has donor been (or was) subscribed?\n",
    "    def months_on_program_fn(x):\n",
    "        join = x['monthly_subscription_joined_date'].min()\n",
    "        retire = x['monthly_subscription_retired_date'].dropna().min()\n",
    "        # If still active, use T; otherwise use retirement date\n",
    "        end = min(T, retire) if pd.notna(retire) else T\n",
    "        return (end.to_period('M') - join.to_period('M')).n\n",
    "    \n",
    "    # Vectorized date operations\n",
    "    join_dates = md_pre_T.groupby('donor_id')['monthly_subscription_joined_date'].min()\n",
    "    retire_dates = md_pre_T.groupby('donor_id')['monthly_subscription_retired_date'].min()\n",
    "    end_dates = retire_dates.fillna(T).clip(upper=T)\n",
    "    out['months_on_program'] = (end_dates.dt.to_period('M') - join_dates.dt.to_period('M')).apply(lambda x: x.n)\n",
    "\n",
    "    # --- Recency of last charge ---\n",
    "    if 'charge_date' in md_pre_T.columns:\n",
    "        last_charge = md_pre_T.groupby('donor_id')['charge_date'].max()\n",
    "        out['months_since_last_monthly_charge'] = (\n",
    "            (T.to_period('M') - last_charge.dt.to_period('M')).astype('int')\n",
    "        )\n",
    "    \n",
    "    # --- Longest streak ---\n",
    "    # Maximum consecutive months of successful charges\n",
    "    out['monthly_longest_streak_months'] = (\n",
    "        md_pre_T.groupby('donor_id')['monthly_subscription_longest_streak'].max()\n",
    "    )\n",
    "    \n",
    "    # --- Acquisition indicator ---\n",
    "    # Did donor join monthly program BEFORE making first project donation?\n",
    "    first_monthly_join = (\n",
    "        md_pre_T.groupby('donor_id')['monthly_subscription_joined_date'].min()\n",
    "    )\n",
    "    first_donation_date = (\n",
    "        dpr_pre_T.groupby('donor_id')['payment_date'].min()\n",
    "    )\n",
    "\n",
    "    # Align on union of donor_ids\n",
    "    idx_union = first_monthly_join.index.union(first_donation_date.index)\n",
    "    fmj = first_monthly_join.reindex(idx_union)\n",
    "    fdd = first_donation_date.reindex(idx_union)\n",
    "\n",
    "    joined_before = (fmj < fdd)\n",
    "    joined_before = joined_before.fillna(False).astype(int)\n",
    "\n",
    "    out['monthly_joined_before_first_project_gift'] = (\n",
    "        joined_before.reindex(out.index).fillna(0).astype(int)\n",
    "    )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Teacher, School & Content Preferences\n",
    "\n",
    "Loyalty vs diversification patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _teacher_school_features(dpr_pre_T):\n",
    "    \"\"\"\n",
    "    Build features describing donor loyalty vs diversification patterns.\n",
    "    \n",
    "    CORRECTED VERSION with:\n",
    "    - Entropy features set to null/NaN if only one donation\n",
    "    - New features for pct amount to first/last project gifts\n",
    "    \n",
    "    Features measure:\n",
    "    - Concentration: How focused is giving on specific teachers/schools/categories?\n",
    "    - Diversification: How many different entities has donor supported?\n",
    "    - Entropy: Information-theoretic measure of spread\n",
    "    - Teacher quality: Average metrics of teachers supported\n",
    "    - Project position: First/last gift preferences\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dpr_pre_T : pd.DataFrame\n",
    "        Donor Project Records filtered to payment_date < T\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id\n",
    "    \"\"\"\n",
    "    if dpr_pre_T.empty:\n",
    "        return pd.DataFrame(index=pd.Index([], name='donor_id'))\n",
    "    \n",
    "    dpr = dpr_pre_T.copy()\n",
    "    out_index = dpr['donor_id'].unique()\n",
    "    out = pd.DataFrame(index=out_index)\n",
    "    \n",
    "    # --- Count unique entities ---\n",
    "    out['num_unique_teachers'] = dpr.groupby('donor_id')['teacher_id'].nunique()\n",
    "    out['num_unique_schools'] = dpr.groupby('donor_id')['school_id'].nunique()\n",
    "    out['num_unique_categories'] = dpr.groupby('donor_id')['project_category'].nunique()\n",
    "    out['num_unique_grades'] = dpr.groupby('donor_id')['project_grade'].nunique()\n",
    "    \n",
    "    # School ZIP diversity (if available)\n",
    "    if 'school_zip' in dpr.columns:\n",
    "        out['num_unique_school_zips'] = dpr.groupby('donor_id')['school_zip'].nunique()\n",
    "    \n",
    "    # --- Entropy (diversity) measures ---\n",
    "    # CORRECTED: Set to NaN if donor only has one donation\n",
    "    \n",
    "    # Get gift count per donor\n",
    "    gift_counts = dpr.groupby('donor_id').size()\n",
    "    single_gift_donors = gift_counts[gift_counts == 1].index\n",
    "    \n",
    "    # Calculate entropy for each dimension\n",
    "    entropy_teacher = entropy_vectorized(dpr, 'donor_id', 'teacher_id')\n",
    "    entropy_school = entropy_vectorized(dpr, 'donor_id', 'school_id')\n",
    "    entropy_category = entropy_vectorized(dpr, 'donor_id', 'project_category')\n",
    "    entropy_grade = entropy_vectorized(dpr, 'donor_id', 'project_grade')\n",
    "    \n",
    "    # Set to NaN for single-gift donors\n",
    "    out['entropy_teacher'] = entropy_teacher\n",
    "    out.loc[single_gift_donors, 'entropy_teacher'] = np.nan\n",
    "    \n",
    "    out['entropy_school'] = entropy_school\n",
    "    out.loc[single_gift_donors, 'entropy_school'] = np.nan\n",
    "    \n",
    "    out['entropy_category'] = entropy_category\n",
    "    out.loc[single_gift_donors, 'entropy_category'] = np.nan\n",
    "    \n",
    "    out['entropy_grade'] = entropy_grade\n",
    "    out.loc[single_gift_donors, 'entropy_grade'] = np.nan\n",
    "    \n",
    "    if 'school_zip' in dpr.columns:\n",
    "        entropy_zip = entropy_vectorized(dpr, 'donor_id', 'school_zip')\n",
    "        out['entropy_zip'] = entropy_zip\n",
    "        out.loc[single_gift_donors, 'entropy_zip'] = np.nan\n",
    "    \n",
    "    # --- Concentration metrics: % of $ going to top entity ---\n",
    "    \n",
    "    # Top teacher\n",
    "    teacher_amounts = dpr.groupby(['donor_id', 'teacher_id'])['payment_amount'].sum()\n",
    "    top_teacher_amt = teacher_amounts.groupby('donor_id').max()\n",
    "    total_amt = dpr.groupby('donor_id')['payment_amount'].sum()\n",
    "    out['pct_amount_to_top_teacher'] = top_teacher_amt / (total_amt + 1e-9)\n",
    "    \n",
    "    # Top school\n",
    "    school_amounts = dpr.groupby(['donor_id', 'school_id'])['payment_amount'].sum()\n",
    "    top_school_amt = school_amounts.groupby('donor_id').max()\n",
    "    out['pct_amount_to_top_school'] = top_school_amt / (total_amt + 1e-9)\n",
    "    \n",
    "    # Top category\n",
    "    category_amounts = dpr.groupby(['donor_id', 'project_category'])['payment_amount'].sum()\n",
    "    top_category_amt = category_amounts.groupby('donor_id').max()\n",
    "    out['pct_amount_to_top_category'] = top_category_amt / (total_amt + 1e-9)\n",
    "    \n",
    "    # Top grade level\n",
    "    grade_amounts = dpr.groupby(['donor_id', 'project_grade'])['payment_amount'].sum()\n",
    "    top_grade_amt = grade_amounts.groupby('donor_id').max()\n",
    "    out['pct_amount_to_top_grade'] = top_grade_amt / (total_amt + 1e-9)\n",
    "    \n",
    "    # --- Teacher quality metrics ---\n",
    "    # Average lifetime projects fully funded by teachers this donor supports\n",
    "    if 'teacher_lifetime_projects_fully_funded' in dpr.columns:\n",
    "        out['mean_teacher_lifetime_projects_fully_funded'] = (\n",
    "            dpr.groupby('donor_id')['teacher_lifetime_projects_fully_funded'].mean()\n",
    "        )\n",
    "    \n",
    "    # Average lifetime donations received by teachers this donor supports\n",
    "    if 'teacher_lifetime_donations' in dpr.columns:\n",
    "        out['mean_teacher_lifetime_donations'] = (\n",
    "            dpr.groupby('donor_id')['teacher_lifetime_donations'].mean()\n",
    "        )\n",
    "    \n",
    "    # --- NEW: Project position preferences ---\n",
    "    # Percent of lifetime amount given to first gifts (gift_is_projects_first = 1)\n",
    "    if 'gift_is_projects_first' in dpr.columns:\n",
    "        out['pct_gifts_first_project'] = pct_count(dpr, 'gift_is_projects_first')\n",
    "        out['pct_amount_first_project'] = pct_amount(dpr, 'gift_is_projects_first')\n",
    "    \n",
    "    # Percent of lifetime amount given to last gifts (gift_is_projects_last = 1)\n",
    "    if 'gift_is_projects_last' in dpr.columns:\n",
    "        out['pct_gifts_last_project'] = pct_count(dpr, 'gift_is_projects_last')\n",
    "        out['pct_amount_last_project'] = pct_amount(dpr, 'gift_is_projects_last')\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Seasonality Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _seasonality_features(dpr_pre_T):\n",
    "    \"\"\"\n",
    "    Build features capturing temporal patterns in giving behavior.\n",
    "    \n",
    "    CORRECTED VERSION with:\n",
    "    - entropy_gift_month set to null/NaN if only one donation\n",
    "    \n",
    "    Features created:\n",
    "    - first_donation_month/quarter: When did they start?\n",
    "    - first_donation_dow_sin/cos: Day-of-week cyclic encoding\n",
    "    - pct_amount_in_back_to_school: Aug-Sep giving (7-10% of annual budget)\n",
    "    - pct_amount_in_final_week_of_year: Dec 24-31 giving (tax planning)\n",
    "    - pct_amount_on_weekends: Saturday/Sunday behavior\n",
    "    - pct_amount_in_top_month/quarter: Concentration in favorite period\n",
    "    - entropy_gift_month: How spread out is giving across months?\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dpr_pre_T : pd.DataFrame\n",
    "        Donor Project Records filtered to payment_date < T\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id\n",
    "    \"\"\"\n",
    "    if dpr_pre_T.empty:\n",
    "        return pd.DataFrame(index=pd.Index([], name='donor_id'))\n",
    "    \n",
    "    dpr = dpr_pre_T.copy()\n",
    "    out_index = dpr['donor_id'].unique()\n",
    "    out = pd.DataFrame(index=out_index)\n",
    "    \n",
    "    # Extract temporal components\n",
    "    dpr['gift_month'] = dpr['payment_date'].dt.month\n",
    "    dpr['gift_quarter'] = dpr['payment_date'].dt.quarter\n",
    "    dpr['gift_dow'] = dpr['payment_date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "    dpr['gift_day'] = dpr['payment_date'].dt.day\n",
    "    \n",
    "    # --- First donation temporal features ---\n",
    "    first_donation = dpr.sort_values(['donor_id', 'payment_date']).groupby('donor_id').first()\n",
    "    \n",
    "    out['first_donation_month'] = first_donation['gift_month']\n",
    "    out['first_donation_quarter'] = first_donation['gift_quarter']\n",
    "    \n",
    "    # Cyclic encoding of day-of-week (preserves weekend vs weekday similarity)\n",
    "    out['first_donation_dow_sin'] = np.sin(2 * np.pi * first_donation['gift_dow'] / 7)\n",
    "    out['first_donation_dow_cos'] = np.cos(2 * np.pi * first_donation['gift_dow'] / 7)\n",
    "    \n",
    "    # --- Seasonal concentration patterns ---\n",
    "    \n",
    "    # Back-to-school season (August-September)\n",
    "    dpr['is_back_to_school'] = dpr['gift_month'].isin([8, 9])\n",
    "    out['pct_amount_in_back_to_school'] = pct_amount(dpr, 'is_back_to_school')\n",
    "    \n",
    "    # Final week of year (tax planning, year-end giving)\n",
    "    dpr['is_final_week'] = (dpr['gift_month'] == 12) & (dpr['gift_day'] >= 24)\n",
    "    out['pct_amount_in_final_week_of_year'] = pct_amount(dpr, 'is_final_week')\n",
    "    \n",
    "    # Weekend giving (different behavior than weekday)\n",
    "    dpr['is_weekend'] = dpr['gift_dow'].isin([5, 6])  # Saturday=5, Sunday=6\n",
    "    out['pct_amount_on_weekends'] = pct_amount(dpr, 'is_weekend')\n",
    "    \n",
    "    # --- Peak period concentration ---\n",
    "    # What % of giving happens in donor's most active month?\n",
    "    month_amounts = dpr.groupby(['donor_id', 'gift_month'])['payment_amount'].sum()\n",
    "    top_month_amt = month_amounts.groupby('donor_id').max()\n",
    "    total_amt = dpr.groupby('donor_id')['payment_amount'].sum()\n",
    "    out['pct_amount_in_top_month'] = top_month_amt / (total_amt + 1e-9)\n",
    "    \n",
    "    # What % of giving happens in donor's most active quarter?\n",
    "    quarter_amounts = dpr.groupby(['donor_id', 'gift_quarter'])['payment_amount'].sum()\n",
    "    top_quarter_amt = quarter_amounts.groupby('donor_id').max()\n",
    "    out['pct_amount_in_top_quarter'] = top_quarter_amt / (total_amt + 1e-9)\n",
    "    \n",
    "    # --- Entropy of giving across months ---\n",
    "    # CORRECTED: Set to NaN if donor only has one donation\n",
    "    gift_counts = dpr.groupby('donor_id').size()\n",
    "    single_gift_donors = gift_counts[gift_counts == 1].index\n",
    "    \n",
    "    entropy_month = entropy_vectorized(dpr, 'donor_id', 'gift_month')\n",
    "    out['entropy_gift_month'] = entropy_month\n",
    "    out.loc[single_gift_donors, 'entropy_gift_month'] = np.nan\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Email Engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _email_features(email_pre_T, email_3m, email_12m, T):\n",
    "    \"\"\"\n",
    "    Build email engagement features from 12-month email summary data.\n",
    "    \n",
    "    Features created:\n",
    "    - emails_sent/opened/clicked for 3m and 12m windows\n",
    "    - open_rate, click_rate (clicks per email sent)\n",
    "    - email_open_rate_velocity: recent vs longer-term trend\n",
    "    - days_since_last_email_sent: recency\n",
    "    \n",
    "    Note: This uses monthly aggregated data, so recency is approximate\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    email_pre_T : pd.DataFrame\n",
    "        All email events before T\n",
    "    email_3m, email_12m : pd.DataFrame\n",
    "        Email events in respective windows\n",
    "    T : pd.Timestamp\n",
    "        Reference time\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id\n",
    "    \"\"\"\n",
    "    if email_pre_T.empty:\n",
    "        return pd.DataFrame(index=pd.Index([], name='donor_id'))\n",
    "    \n",
    "    def email_agg(df):\n",
    "        \"\"\"Aggregate email metrics for a given window\"\"\"\n",
    "        if df.empty:\n",
    "            idx = email_pre_T['donor_id'].unique()\n",
    "            zero = pd.Series(0, index=idx)\n",
    "            return zero, zero, zero, zero, zero\n",
    "        \n",
    "        by = df.groupby('donor_id')\n",
    "        sent = by['email_sent_count'].sum()\n",
    "        opened = by['email_open_count'].sum()\n",
    "        clicked = by['email_click_count'].sum()\n",
    "        \n",
    "        # Rates: opens/clicks per email sent\n",
    "        open_rate = opened / (sent + 1e-6)\n",
    "        click_rate = clicked / (sent + 1e-6)\n",
    "        \n",
    "        return sent, opened, clicked, open_rate, click_rate\n",
    "    \n",
    "    # Aggregate for both windows\n",
    "    sent_3, open_3, click_3, or_3, cr_3 = email_agg(email_3m)\n",
    "    sent_12, open_12, click_12, or_12, cr_12 = email_agg(email_12m)\n",
    "    \n",
    "    idx = email_pre_T['donor_id'].unique()\n",
    "    out = pd.DataFrame(index=idx)\n",
    "    \n",
    "    # 3-month window\n",
    "    out['emails_sent_3m'] = sent_3\n",
    "    out['emails_opened_3m'] = open_3\n",
    "    out['emails_clicked_3m'] = click_3\n",
    "    out['email_open_rate_3m'] = or_3\n",
    "    out['email_click_rate_3m'] = cr_3\n",
    "    \n",
    "    # 12-month window\n",
    "    out['emails_sent_12m'] = sent_12\n",
    "    out['emails_opened_12m'] = open_12\n",
    "    out['emails_clicked_12m'] = click_12\n",
    "    out['email_open_rate_12m'] = or_12\n",
    "    out['email_click_rate_12m'] = cr_12\n",
    "    \n",
    "    # Velocity: is engagement improving or declining?\n",
    "    # Positive = recent engagement higher than long-term average\n",
    "    out['email_open_rate_velocity_3m_vs_12m'] = or_3 - or_12\n",
    "    \n",
    "    # Recency (approximate, since data is monthly)\n",
    "    last_email_month = email_pre_T.groupby('donor_id')['email_month_start'].max()\n",
    "    out['days_since_last_email_sent'] = (T - last_email_month).dt.days\n",
    "    \n",
    "    # Note: email type mix features would go here if you have\n",
    "    # a mapping from email_type to type_group (appeal, newsletter, etc.)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Site Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _site_features(site_pre_T, site_3m, T):\n",
    "    \"\"\"\n",
    "    Build on-site browsing and engagement features.\n",
    "    \n",
    "    Features created:\n",
    "    - days_with_any_site_activity_3m: Active days count\n",
    "    - avg_sessions_per_active_day_3m: Session frequency\n",
    "    - avg_session_duration_min_3m: Session length\n",
    "    - checkout_intent_min_per_session_3m: Cart engagement\n",
    "    - days_since_last_cart_visit: Browse-to-buy recency (relative to T)\n",
    "    - campaign_session_share_3m: Attribution\n",
    "    - share_*_page_session_pct_3m: Page type mix\n",
    "    - device_share_*_3m: Device usage profile\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    site_pre_T : pd.DataFrame\n",
    "        Site events with activity_date < T\n",
    "    site_3m : pd.DataFrame\n",
    "        Site events with activity_date in [T-3m, T)\n",
    "    T : pd.Timestamp\n",
    "        As-of timestamp\n",
    "    \"\"\"\n",
    "    if site_pre_T.empty:\n",
    "        return pd.DataFrame(index=pd.Index([], name='donor_id'))\n",
    "\n",
    "    idx = site_pre_T['donor_id'].unique()\n",
    "    out = pd.DataFrame(index=idx)\n",
    "\n",
    "    # --- Recent activity metrics (3m window) ---\n",
    "    if not site_3m.empty:\n",
    "        # Days with any activity\n",
    "        activity_by_day = (\n",
    "            site_3m\n",
    "            .assign(any_activity=1)\n",
    "            .groupby(['donor_id', 'activity_date'])['any_activity']\n",
    "            .max()\n",
    "            .reset_index()\n",
    "        )\n",
    "        days_with_any = activity_by_day.groupby('donor_id')['activity_date'].nunique()\n",
    "        \n",
    "        # Session counts\n",
    "        sessions_by_donor = site_3m.groupby('donor_id').size()\n",
    "        \n",
    "        out['days_with_any_site_activity_3m'] = days_with_any\n",
    "        out['avg_sessions_per_active_day_3m'] = (\n",
    "            sessions_by_donor / (days_with_any + 1e-6)\n",
    "        )\n",
    "        \n",
    "        # Session duration (if available)\n",
    "        if 'session_duration_min' in site_3m.columns:\n",
    "            out['avg_session_duration_min_3m'] = (\n",
    "                site_3m.groupby('donor_id')['session_duration_min'].mean()\n",
    "            )\n",
    "        \n",
    "        # Checkout intent: cart visits per session\n",
    "        if 'cart_visits_day' in site_3m.columns:\n",
    "            out['checkout_intent_min_per_session_3m'] = (\n",
    "                site_3m.groupby('donor_id')['cart_visits_day'].sum()\n",
    "                / (sessions_by_donor + 1e-6)\n",
    "            )\n",
    "        \n",
    "        # Campaign attribution\n",
    "        if 'came_from_campaign' in site_3m.columns:\n",
    "            out['campaign_session_share_3m'] = (\n",
    "                site_3m.groupby('donor_id')['came_from_campaign'].mean()\n",
    "            )\n",
    "        \n",
    "        # --- Page type mix ---\n",
    "        # Ensure required columns exist with default 0\n",
    "        for col in ['project_page_visits_day', 'teacher_page_visits_day', 'search_visits_day']:\n",
    "            if col not in site_3m.columns:\n",
    "                site_3m[col] = 0\n",
    "        \n",
    "        page_counts = site_3m.groupby('donor_id').agg({\n",
    "            'project_page_visits_day': 'sum',\n",
    "            'teacher_page_visits_day': 'sum',\n",
    "            'search_visits_day'      : 'sum'\n",
    "        })\n",
    "        total_page_visits = page_counts.sum(axis=1) + 1e-6\n",
    "        \n",
    "        out['share_project_page_session_pct_3m'] = (\n",
    "            page_counts['project_page_visits_day'] / total_page_visits\n",
    "        )\n",
    "        out['share_teacher_page_session_pct_3m'] = (\n",
    "            page_counts['teacher_page_visits_day'] / total_page_visits\n",
    "        )\n",
    "        out['share_search_page_session_pct_3m'] = (\n",
    "            page_counts['search_visits_day'] / total_page_visits\n",
    "        )\n",
    "        \n",
    "        # --- Device profile ---\n",
    "        # Mobile-first, desktop-only, or mixed?\n",
    "        if 'device_type' in site_3m.columns:\n",
    "            # Normalize device_type to lowercase to match ['mobile', 'desktop', 'tablet']\n",
    "            dev_df = site_3m.copy()\n",
    "            dev_df['device_type'] = dev_df['device_type'].astype(str).str.lower()\n",
    "            \n",
    "            device_counts = (\n",
    "                dev_df.groupby(['donor_id', 'device_type'])\n",
    "                .size()\n",
    "                .unstack(fill_value=0)\n",
    "            )\n",
    "            total_device = device_counts.sum(axis=1) + 1e-6\n",
    "            \n",
    "            for dev in ['mobile', 'desktop', 'tablet']:\n",
    "                colname = f'device_share_{dev}_3m'\n",
    "                if dev in device_counts.columns:\n",
    "                    out[colname] = device_counts[dev] / total_device\n",
    "                else:\n",
    "                    out[colname] = 0.0\n",
    "\n",
    "    # --- Cart recency (using full history, relative to T) ---\n",
    "    if 'cart_visits_day' in site_pre_T.columns:\n",
    "        has_cart = site_pre_T[site_pre_T['cart_visits_day'] > 0]\n",
    "        if not has_cart.empty:\n",
    "            last_cart_date = has_cart.groupby('donor_id')['activity_date'].max()\n",
    "            out['days_since_last_cart_visit'] = (\n",
    "                (T - last_cart_date).dt.days\n",
    "            )\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 Share Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _share_features(share_pre_T, share_12m, T):\n",
    "    \"\"\"\n",
    "    Build social sharing behavior features.\n",
    "    \n",
    "    Features created:\n",
    "    - share_events_lifetime, share_events_12m: Volume\n",
    "    - share_active_months_12m: Frequency\n",
    "    - share_gap_mean/cv_days: Sharing rhythm\n",
    "    - share_month_coverage_ratio: Consistency over tenure\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    share_pre_T : pd.DataFrame\n",
    "        All share events before T\n",
    "    share_12m : pd.DataFrame\n",
    "        Share events in last 12 months\n",
    "    T : pd.Timestamp\n",
    "        Reference time\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id\n",
    "    \"\"\"\n",
    "    if share_pre_T.empty:\n",
    "        return pd.DataFrame(index=pd.Index([], name='donor_id'))\n",
    "    \n",
    "    out_index = share_pre_T['donor_id'].unique()\n",
    "    out = pd.DataFrame(index=out_index)\n",
    "    \n",
    "    # --- Volume metrics ---\n",
    "    out['share_events_lifetime'] = (\n",
    "        share_pre_T.groupby('donor_id')['share_event_count'].sum()\n",
    "    )\n",
    "    out['share_events_12m'] = (\n",
    "        share_12m.groupby('donor_id')['share_event_count'].sum()\n",
    "        if not share_12m.empty else 0\n",
    "    )\n",
    "    \n",
    "    # --- Active months (consistency) ---\n",
    "    if not share_12m.empty:\n",
    "        active_months_12m = (\n",
    "            share_12m[share_12m['share_event_count'] > 0]\n",
    "            .groupby('donor_id')['share_month_start']\n",
    "            .nunique()\n",
    "        )\n",
    "        out['share_active_months_12m'] = active_months_12m\n",
    "    \n",
    "    # --- Sharing rhythm: gaps between share months ---\n",
    "    def gap_stats(s):\n",
    "        if s.shape[0] < 2:\n",
    "            return pd.Series({\n",
    "                'share_gap_mean_days': np.nan,\n",
    "                'share_gap_cv_days': np.nan\n",
    "            })\n",
    "        # Sort by time, then diff\n",
    "        gaps = s.sort_values().diff().dropna().dt.days\n",
    "        mean = gaps.mean()\n",
    "        cv = gaps.std() / (mean + 1e-6)\n",
    "        return pd.Series({\n",
    "            'share_gap_mean_days': mean,\n",
    "            'share_gap_cv_days': cv\n",
    "        })\n",
    "\n",
    "    gap_df = (\n",
    "        share_pre_T.groupby('donor_id')['share_month_start']\n",
    "        .apply(gap_stats)\n",
    "        .unstack()          # columns: share_gap_mean_days, share_gap_cv_days\n",
    "    )\n",
    "\n",
    "    out = out.join(gap_df, how='left')\n",
    "\n",
    "    # --- Coverage ratio ---\n",
    "    first_share = share_pre_T.groupby('donor_id')['share_month_start'].min()\n",
    "    last_share = share_pre_T.groupby('donor_id')['share_month_start'].max()\n",
    "    \n",
    "    # Difference of two Periods is a DateOffset (e.g., <MonthEnd>); use .n to get month count\n",
    "    tenure_offsets = last_share.dt.to_period('M') - first_share.dt.to_period('M')\n",
    "    tenure_months = tenure_offsets.apply(lambda x: x.n if pd.notnull(x) else 0)\n",
    "    tenure_months = tenure_months.clip(lower=1)  # at least 1 month of tenure\n",
    "    \n",
    "    out['share_month_coverage_ratio'] = (\n",
    "        out.get('share_active_months_12m', 0) / (tenure_months + 1e-6)\n",
    "    )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.11 Same Schoool & Teacher Available Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _future_opportunity_features(dpr_pre_T, df_project_dates, T, H):\n",
    "    \"\"\"\n",
    "    Future opportunity features based on the donor's TOP (most-funded) school and teacher,\n",
    "    not just their first one.\n",
    "\n",
    "    For each donor:\n",
    "      - Find the school where they have given the most (by payment_amount).\n",
    "      - Find the teacher where they have given the most (by payment_amount).\n",
    "      - Flag whether that school/teacher has ANY project active in [T, T+H].\n",
    "\n",
    "    This approximates \"did the donor's favorite school/teacher have opportunities\n",
    "    to receive more gifts during the horizon\".\n",
    "    \"\"\"\n",
    "    # If we don't have project data or donations, return zeros\n",
    "    if df_project_dates is None or df_project_dates.empty or dpr_pre_T.empty:\n",
    "        idx = dpr_pre_T['donor_id'].unique()\n",
    "        return pd.DataFrame({\n",
    "            'school_still_available_during_range': 0,\n",
    "            'teacher_still_available_during_range': 0\n",
    "        }, index=pd.Index(idx, name='donor_id'))\n",
    "\n",
    "    # Work on copies\n",
    "    proj = df_project_dates.copy()\n",
    "    dpr = dpr_pre_T.copy()\n",
    "\n",
    "    # Ensure project date columns are datetime\n",
    "    for c in ['project_last_posted_date', 'project_funded_date', 'project_expiration_date']:\n",
    "        if c in proj.columns:\n",
    "            proj[c] = pd.to_datetime(proj[c], errors='coerce')\n",
    "\n",
    "    # Project end date = earlier of funded or expired\n",
    "    proj['end_date'] = proj[['project_funded_date', 'project_expiration_date']].min(axis=1)\n",
    "\n",
    "    # Normalize H\n",
    "    if isinstance(H, int):\n",
    "        H = pd.Timedelta(days=H)\n",
    "    elif H is None:\n",
    "        H = pd.Timedelta(days=365)\n",
    "\n",
    "    win_start = T\n",
    "    win_end = T + H\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 1) Identify TOP (most-funded) school and teacher per donor\n",
    "    # ----------------------------------------------------------------------\n",
    "    donor_index = dpr['donor_id'].unique()\n",
    "    out = pd.DataFrame(index=pd.Index(donor_index, name='donor_id'))\n",
    "\n",
    "    # Top school by total payment_amount\n",
    "    if {'school_id', 'payment_amount'}.issubset(dpr.columns):\n",
    "        school_agg = (\n",
    "            dpr.groupby(['donor_id', 'school_id'])['payment_amount']\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "        )\n",
    "        top_school = (\n",
    "            school_agg\n",
    "            .sort_values(['donor_id', 'payment_amount'], ascending=[True, False])\n",
    "            .groupby('donor_id')\n",
    "            .first()\n",
    "            .reset_index()[['donor_id', 'school_id']]\n",
    "        )\n",
    "    else:\n",
    "        top_school = pd.DataFrame(columns=['donor_id', 'school_id'])\n",
    "\n",
    "    # Top teacher by total payment_amount\n",
    "    if {'teacher_id', 'payment_amount'}.issubset(dpr.columns):\n",
    "        teacher_agg = (\n",
    "            dpr.groupby(['donor_id', 'teacher_id'])['payment_amount']\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "        )\n",
    "        top_teacher = (\n",
    "            teacher_agg\n",
    "            .sort_values(['donor_id', 'payment_amount'], ascending=[True, False])\n",
    "            .groupby('donor_id')\n",
    "            .first()\n",
    "            .reset_index()[['donor_id', 'teacher_id']]\n",
    "        )\n",
    "    else:\n",
    "        top_teacher = pd.DataFrame(columns=['donor_id', 'teacher_id'])\n",
    "\n",
    "    # If a donor has only one gift, top == first; so behavior matches what you described.\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 2) Precompute which schools/teachers have projects active in horizon\n",
    "    # ----------------------------------------------------------------------\n",
    "    proj['active_in_horizon'] = (\n",
    "        (proj['project_last_posted_date'] <= win_end) &\n",
    "        (proj['end_date'] >= win_start)\n",
    "    )\n",
    "\n",
    "    # Guard against missing columns, though in your data they should exist\n",
    "    if 'school_id' in proj.columns:\n",
    "        school_active = (\n",
    "            proj.groupby('school_id')['active_in_horizon']\n",
    "            .any()\n",
    "            .astype(int)\n",
    "        )\n",
    "    else:\n",
    "        school_active = pd.Series(dtype=int)\n",
    "\n",
    "    if 'teacher_id' in proj.columns:\n",
    "        teacher_active = (\n",
    "            proj.groupby('teacher_id')['active_in_horizon']\n",
    "            .any()\n",
    "            .astype(int)\n",
    "        )\n",
    "    else:\n",
    "        teacher_active = pd.Series(dtype=int)\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 3) Map top school/teacher to these activity flags\n",
    "    # ----------------------------------------------------------------------\n",
    "    # School: donor -> top school_id -> activity flag\n",
    "    if not top_school.empty:\n",
    "        school_flag = (\n",
    "            top_school\n",
    "            .set_index('donor_id')['school_id']\n",
    "            .map(school_active)\n",
    "            .reindex(donor_index)\n",
    "            .fillna(0)\n",
    "            .astype(int)\n",
    "        )\n",
    "    else:\n",
    "        school_flag = pd.Series(0, index=donor_index)\n",
    "\n",
    "    # Teacher: donor -> top teacher_id -> activity flag\n",
    "    if not top_teacher.empty:\n",
    "        teacher_flag = (\n",
    "            top_teacher\n",
    "            .set_index('donor_id')['teacher_id']\n",
    "            .map(teacher_active)\n",
    "            .reindex(donor_index)\n",
    "            .fillna(0)\n",
    "            .astype(int)\n",
    "        )\n",
    "    else:\n",
    "        teacher_flag = pd.Series(0, index=donor_index)\n",
    "\n",
    "    out['school_still_available_during_range'] = school_flag\n",
    "    out['teacher_still_available_during_range'] = teacher_flag\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.11 Project Outcomes & Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _project_outcome_features(dpr_pre_T):\n",
    "    \"\"\"\n",
    "    Build features describing project success and matching behavior.\n",
    "    \n",
    "    CORRECTED VERSION with:\n",
    "    - mean_match_multiplier: subtract 1 from all values, impute 0 for records with optional_donation_rate\n",
    "    \n",
    "    Features created:\n",
    "    - pct_projects_fully_funded: Success rate of projects supported\n",
    "    - pct_gifts_with_match: How often donations are matched\n",
    "    - mean_match_multiplier: Average EXCESS match (1.5 becomes 0.5), with 0s for optional donations\n",
    "    - mean/median_project_total_cost: Scale of projects supported\n",
    "    - median_donor_to_project_distance_mi: Geographic preference\n",
    "    - pct_gifts_within_15mi: Local giving behavior\n",
    "    - is_local_donor: Predominantly supports nearby schools\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dpr_pre_T : pd.DataFrame\n",
    "        Donor Project Records filtered to payment_date < T\n",
    "    T : pd.Timestamp\n",
    "        Reference time\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id\n",
    "    \"\"\"\n",
    "    if dpr_pre_T.empty:\n",
    "        return pd.DataFrame(index=pd.Index([], name='donor_id'))\n",
    "    \n",
    "    dpr = dpr_pre_T.copy()\n",
    "    out_index = dpr['donor_id'].unique()\n",
    "    out = pd.DataFrame(index=out_index)\n",
    "    \n",
    "    # --- Project success metrics ---\n",
    "    if 'project_got_fully_funded' in dpr.columns:\n",
    "        out['pct_projects_fully_funded'] = (\n",
    "            dpr.groupby('donor_id')['project_got_fully_funded'].mean()\n",
    "        )\n",
    "    elif 'project_fully_funded' in dpr.columns:\n",
    "        out['pct_projects_fully_funded'] = (\n",
    "            dpr.groupby('donor_id')['project_fully_funded'].mean()\n",
    "        )\n",
    "    \n",
    "    # --- Matching behavior ---\n",
    "    # 1. Subtract 1 from all match_xyi_multiplier values (so 1.5 becomes 0.5)\n",
    "    # 2. Impute 0 for records that have a value in optional_donation_rate\n",
    "    \n",
    "    if 'match_xyi_multiplier' in dpr.columns:\n",
    "        # Step 1: Filter to rows with optional_donation_rate present\n",
    "        dpr_with_optional = dpr[dpr['optional_donation_rate'].notna()].copy()\n",
    "        \n",
    "        if not dpr_with_optional.empty:\n",
    "            # Step 2: Calculate match_excess (subtract 1)\n",
    "            dpr_with_optional['match_excess'] = dpr_with_optional['match_xyi_multiplier'] - 1.0\n",
    "            \n",
    "            # Step 3: Fill nulls in match_excess with 0\n",
    "            dpr_with_optional['match_excess'] = dpr_with_optional['match_excess'].fillna(0)\n",
    "            \n",
    "            # Step 4: Calculate mean per donor\n",
    "            out['mean_match_multiplier'] = (\n",
    "                dpr_with_optional.groupby('donor_id')['match_excess'].mean()\n",
    "            )\n",
    "        else:\n",
    "            out['mean_match_multiplier'] = np.nan\n",
    "        \n",
    "        # Percent of gifts that received any match (before adjustments)\n",
    "        had_match = dpr['match_xyi_multiplier'] > 1.0\n",
    "        out['pct_gifts_with_match'] = (\n",
    "            dpr.groupby('donor_id')\n",
    "            .apply(lambda x: had_match.loc[x.index].mean())\n",
    "        )\n",
    "    \n",
    "    # --- Project cost metrics ---\n",
    "    out['mean_project_total_cost'] = dpr.groupby('donor_id')['project_total_cost'].mean()\n",
    "    out['median_project_total_cost'] = dpr.groupby('donor_id')['project_total_cost'].median()\n",
    "    \n",
    "    # --- Geographic patterns ---\n",
    "    if 'distance_mi' in dpr.columns:\n",
    "        out['median_donor_to_project_distance_mi'] = (\n",
    "            dpr.groupby('donor_id')['distance_mi'].median()\n",
    "        )\n",
    "        \n",
    "        # Local giving: within 15 miles\n",
    "        dpr['is_within_15mi'] = dpr['distance_mi'] <= 15\n",
    "        out['pct_gifts_within_15mi'] = (\n",
    "            dpr.groupby('donor_id')['is_within_15mi'].mean()\n",
    "        )\n",
    "        \n",
    "        # Predominantly local donor (>75% of gifts within 15 miles)\n",
    "        out['is_local_donor'] = (out['pct_gifts_within_15mi'] > 0.75).astype(int)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.12 Latest Donation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _latest_donation_features(dpr_pre_T, df_share, T):\n",
    "    \"\"\"\n",
    "    Extract features from each donor's most recent donation before time T.\n",
    "    \n",
    "    This captures the \"state\" of the donor at their last interaction,\n",
    "    which can be highly predictive of near-term behavior.\n",
    "    \n",
    "    Features include:\n",
    "    - Amount split by green vs non-green\n",
    "    - Project characteristics (cost, category, grade, fully funded status)\n",
    "    - Teacher metrics\n",
    "    - Payment type and optional donation behavior\n",
    "    - Geographic distance\n",
    "    - Referral channel (how they arrived)\n",
    "    - Social sharing behavior in the month of latest donation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dpr_pre_T : pd.DataFrame\n",
    "        Donor Project Records filtered to payment_date < T\n",
    "        Expected columns: donor_id, payment_date, payment_amount, \n",
    "        is_green_payment, project_total_cost, project_got_fully_funded,\n",
    "        teacher_lifetime_projects_fully_funded, gift_is_projects_first,\n",
    "        gift_is_projects_last, optional_donation_rate, payment_type,\n",
    "        project_category, project_grade, referral_source, \n",
    "        referral_medium, donor_lat_long, school_lat_long\n",
    "    df_share : pd.DataFrame\n",
    "        Share events with columns: donor_id, share_sent_month\n",
    "        share_sent_month format: \"YYYY-MM\" (e.g., \"2022-07\")\n",
    "    T : pd.Timestamp\n",
    "        Reference time (as-of date)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id with 'latest_*' columns\n",
    "    \"\"\"\n",
    "    \n",
    "    if dpr_pre_T.empty:\n",
    "        return pd.DataFrame(index=pd.Index([], name='donor_id'))\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Get most recent donation per donor\n",
    "    # =========================================================================\n",
    "    \n",
    "    latest = (\n",
    "        dpr_pre_T\n",
    "        .sort_values(['donor_id', 'payment_date'])\n",
    "        .groupby('donor_id', as_index=False)\n",
    "        .last()\n",
    "        .set_index('donor_id')\n",
    "    )\n",
    "    \n",
    "    out = pd.DataFrame(index=latest.index)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Amount features: split by green vs non-green\n",
    "    # =========================================================================\n",
    "    \n",
    "    # is_green_payment is string \"t\" or \"f\"\n",
    "    is_green = latest['is_green_payment'].isin(['t', 'T', True, 1])\n",
    "    \n",
    "    out['latest_gift_amount_green'] = np.where(\n",
    "        is_green, \n",
    "        latest['payment_amount'], \n",
    "        0\n",
    "    )\n",
    "    \n",
    "    out['latest_gift_amount_nongreen'] = np.where(\n",
    "        ~is_green,\n",
    "        latest['payment_amount'],\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Project characteristics\n",
    "    # =========================================================================\n",
    "    \n",
    "    out['latest_match_xyi_multiplier'] = latest.get('match_xyi_multiplier', np.nan)\n",
    "    out['latest_project_total_cost'] = latest['project_total_cost']\n",
    "    out['latest_project_got_fully_funded'] = latest['project_got_fully_funded'].astype(int)\n",
    "    \n",
    "    # Teacher metrics at time of latest donation\n",
    "    out['latest_teacher_lifetime_projects_fully_funded'] = latest.get(\n",
    "        'teacher_lifetime_projects_fully_funded', np.nan\n",
    "    )\n",
    "    \n",
    "    # Position in project funding sequence\n",
    "    out['latest_donation_is_projects_first'] = latest['gift_is_projects_first'].astype(int)\n",
    "    out['latest_donation_is_projects_last'] = latest['gift_is_projects_last'].astype(int)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Payment type and behavior\n",
    "    # =========================================================================\n",
    "    \n",
    "    out['latest_payment_type_is_green'] = is_green.astype(int)\n",
    "    \n",
    "    # Optional donation as percentage of total\n",
    "    out['latest_optional_donation_percent'] = latest.get('optional_donation_rate', 0)\n",
    "    \n",
    "    # Gift card purchase flag\n",
    "    if 'gift_card_purchase' in latest.columns:\n",
    "        out['latest_is_giftcard_purchase'] = (\n",
    "            latest['gift_card_purchase'].fillna(0).astype(int)\n",
    "        )\n",
    "    else:\n",
    "        out['latest_is_giftcard_purchase'] = 0\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Categorical features (for one-hot encoding downstream)\n",
    "    # =========================================================================\n",
    "    \n",
    "    out['latest_project_grade'] = latest['project_grade']\n",
    "    out['latest_project_category'] = latest['project_category']\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Referral channel (same logic as Repeat Donor Behaviors)\n",
    "    # =========================================================================\n",
    "    \n",
    "    valid_media = {\n",
    "        'email', 'directlink', 'facebook', 'nextdoor',\n",
    "        'sharetray', 'mobilesharetray', 'page', 'ig', 'sendfriend'\n",
    "    }\n",
    "    valid_sources = {'dc', 'google'}\n",
    "    \n",
    "    # If referral_medium is in valid_media, use it; otherwise use referral_source\n",
    "    # Treat non-dc/google sources as \"Oth\"\n",
    "    referral_source_clean = latest.get('referral_source', pd.Series(index=latest.index))\n",
    "    referral_source_clean = referral_source_clean.where(\n",
    "        referral_source_clean.isin(valid_sources),\n",
    "        'Oth'  # Replace non-dc/google sources with \"Oth\"\n",
    "    )\n",
    "    \n",
    "    referral_medium = latest.get('referral_medium', pd.Series(index=latest.index))\n",
    "    \n",
    "    out['latest_referral_channel'] = np.where(\n",
    "        referral_medium.isin(valid_media),\n",
    "        referral_medium,\n",
    "        referral_source_clean\n",
    "    )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Distance to school\n",
    "    # =========================================================================\n",
    "    \n",
    "    if 'distance_mi' in latest.columns:\n",
    "        out['latest_distance_mi'] = latest['distance_mi']\n",
    "    else:\n",
    "        out['latest_distance_mi'] = np.nan\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Social sharing in month of latest donation\n",
    "    # =========================================================================\n",
    "    \n",
    "    if df_share is not None and not df_share.empty:\n",
    "        # Extract year-month from latest donation date\n",
    "        latest_month = pd.to_datetime(latest['payment_date']).dt.to_period('M').astype(str)\n",
    "        \n",
    "        # Create a mapping of donor_id -> set of months they shared\n",
    "        share_months = (\n",
    "            df_share\n",
    "            .groupby('donor_id')['share_sent_month']\n",
    "            .apply(set)\n",
    "            .to_dict()\n",
    "        )\n",
    "        \n",
    "        # For each donor, check if they shared in their latest donation month\n",
    "        out['latest_shared_any'] = out.index.map(\n",
    "            lambda donor_id: int(\n",
    "                latest_month.loc[donor_id] in share_months.get(donor_id, set())\n",
    "                if donor_id in latest_month.index\n",
    "                else 0\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        out['latest_shared_any'] = 0\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Label Group Functions\n",
    "\n",
    "This section defines the 50 future-focused donor labels for various prediction tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Core Giving Propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _labels_core_giving_propensity(df_dpr: pd.DataFrame, T: pd.Timestamp) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A. Core Giving Propensity.\n",
    "\n",
    "    Labels:\n",
    "      - label_will_give_next_30d\n",
    "      - label_will_give_next_90d\n",
    "      - label_will_give_next_365d\n",
    "      - label_num_gifts_next_365d\n",
    "      - label_num_green_gifts_next_365d\n",
    "      - label_will_give_2plus_times_next_365d\n",
    "      - label_time_to_next_gift_days\n",
    "      - label_will_make_big_event_gift_next_365d\n",
    "    \"\"\"\n",
    "    df = df_dpr.copy()\n",
    "    df[\"payment_date\"] = pd.to_datetime(df[\"payment_date\"])\n",
    "    donor_index = df[\"donor_id\"].drop_duplicates().sort_values()\n",
    "    out = pd.DataFrame(index=donor_index)\n",
    "\n",
    "    # Future windows\n",
    "    dpr_30  = _future_window(df, \"payment_date\", T, 30)\n",
    "    dpr_90  = _future_window(df, \"payment_date\", T, 90)\n",
    "    dpr_365 = _future_window(df, \"payment_date\", T, 365)\n",
    "\n",
    "    # 1â€“3. Any gift in 30/90/365d\n",
    "    out[\"label_will_give_next_30d\"]  = _any_by_donor(dpr_30)\n",
    "    out[\"label_will_give_next_90d\"]  = _any_by_donor(dpr_90)\n",
    "    out[\"label_will_give_next_365d\"] = _any_by_donor(dpr_365)\n",
    "\n",
    "    # 4. Num_gifts_next_365d\n",
    "    out[\"label_num_gifts_next_365d\"] = _count_by_donor(dpr_365)\n",
    "\n",
    "    # 5. Num_green_gifts_next_365d\n",
    "    if \"is_green_payment\" in df.columns:\n",
    "        green_mask = dpr_365[\"is_green_payment\"].isin([\"t\", \"T\", True, 1, \"1\"])\n",
    "        green_365 = dpr_365[green_mask]\n",
    "    elif \"green_payment_amount\" in df.columns:\n",
    "        green_365 = dpr_365[dpr_365[\"green_payment_amount\"].fillna(0) > 0]\n",
    "    else:\n",
    "        green_365 = dpr_365.iloc[0:0]\n",
    "    out[\"label_num_green_gifts_next_365d\"] = _count_by_donor(green_365)\n",
    "\n",
    "    # 6. Will_give_2plus_times_next_365d\n",
    "    out[\"label_will_give_2plus_times_next_365d\"] = (\n",
    "        out[\"label_num_gifts_next_365d\"] >= 2\n",
    "    ).astype(float)\n",
    "\n",
    "    # 7. Time_to_next_gift_days\n",
    "    future_gifts = (\n",
    "        df[df[\"payment_date\"] >= T]\n",
    "        .sort_values([\"donor_id\", \"payment_date\"])\n",
    "        .groupby(\"donor_id\")[\"payment_date\"]\n",
    "        .min()\n",
    "    )\n",
    "    time_to_next = (future_gifts - T).dt.days.astype(float)\n",
    "    out[\"label_time_to_next_gift_days\"] = time_to_next\n",
    "\n",
    "    # 8. Will_make_big_event_gift_next_365d\n",
    "    if \"payment_on_big_event\" in df.columns:\n",
    "        big_event_365 = dpr_365[dpr_365[\"payment_on_big_event\"] == 1]\n",
    "        out[\"label_will_make_big_event_gift_next_365d\"] = _any_by_donor(big_event_365)\n",
    "    else:\n",
    "        out[\"label_will_make_big_event_gift_next_365d\"] = np.nan\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# B. Revenue & Value (8 labels)\n",
    "# ---------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Revenue & Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _labels_revenue_and_value(df_dpr: pd.DataFrame, df_monthly: pd.DataFrame, T: pd.Timestamp) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    B. Revenue & Value.\n",
    "\n",
    "    Labels:\n",
    "      - label_green_revenue_next_365d\n",
    "      - label_project_revenue_next_365d\n",
    "      - label_monthly_revenue_next_365d\n",
    "      - label_grand_revenue_next_365d\n",
    "      - label_max_single_gift_next_365d\n",
    "      - label_revenue_growth_ratio_next_year\n",
    "      - label_will_cross_midlevel_threshold_next_12m\n",
    "      - label_will_make_major_gift_next_24m\n",
    "    \"\"\"\n",
    "    dpr = df_dpr.copy()\n",
    "    dpr[\"payment_date\"] = pd.to_datetime(dpr[\"payment_date\"])\n",
    "\n",
    "    monthly = df_monthly.copy() if df_monthly is not None else pd.DataFrame()\n",
    "    if not monthly.empty and \"charge_date\" in monthly.columns:\n",
    "        monthly[\"charge_date\"] = pd.to_datetime(monthly[\"charge_date\"])\n",
    "\n",
    "    donor_index = dpr[\"donor_id\"].drop_duplicates().sort_values()\n",
    "    out = pd.DataFrame(index=donor_index)\n",
    "\n",
    "    # Future windows\n",
    "    dpr_365 = _future_window(dpr, \"payment_date\", T, 365)\n",
    "    dpr_24m = _future_window(dpr, \"payment_date\", T, 365 * 2)\n",
    "    if not monthly.empty and \"charge_date\" in monthly.columns:\n",
    "        monthly_365 = _future_window(monthly, \"charge_date\", T, 365)\n",
    "    else:\n",
    "        monthly_365 = pd.DataFrame()\n",
    "\n",
    "    # 9. Green_revenue_next_365d\n",
    "    if \"green_payment_amount\" in dpr.columns:\n",
    "        green_365 = dpr_365.copy()\n",
    "        green_365[\"green_payment_amount\"] = green_365[\"green_payment_amount\"].fillna(0.0)\n",
    "        out[\"label_green_revenue_next_365d\"] = _sum_by_donor(green_365, \"green_payment_amount\")\n",
    "    elif \"is_green_payment\" in dpr.columns:\n",
    "        green_mask = dpr_365[\"is_green_payment\"].isin([\"t\", \"T\", True, 1, \"1\"])\n",
    "        green_365 = dpr_365[green_mask]\n",
    "        out[\"label_green_revenue_next_365d\"] = _sum_by_donor(green_365, \"payment_amount\")\n",
    "    else:\n",
    "        out[\"label_green_revenue_next_365d\"] = np.nan\n",
    "\n",
    "    # 10. Project_revenue_next_365d (project giving dollars in df_dpr)\n",
    "    out[\"label_project_revenue_next_365d\"] = _sum_by_donor(dpr_365, \"payment_amount\")\n",
    "\n",
    "    # 11. Monthly_revenue_next_365d (from monthly charges)\n",
    "    if not monthly_365.empty and \"monthly_subscription_payment_amount\" in monthly_365.columns:\n",
    "        out[\"label_monthly_revenue_next_365d\"] = _sum_by_donor(\n",
    "            monthly_365, \"monthly_subscription_payment_amount\"\n",
    "        )\n",
    "    else:\n",
    "        out[\"label_monthly_revenue_next_365d\"] = np.nan\n",
    "\n",
    "    # 12. Grand_revenue_next_365d = project + monthly\n",
    "    out[\"label_grand_revenue_next_365d\"] = (\n",
    "        out[\"label_project_revenue_next_365d\"].fillna(0.0)\n",
    "        + out[\"label_monthly_revenue_next_365d\"].fillna(0.0)\n",
    "    )\n",
    "\n",
    "    # 13. Max_single_gift_next_365d\n",
    "    out[\"label_max_single_gift_next_365d\"] = _max_by_donor(dpr_365, \"payment_amount\")\n",
    "\n",
    "    # 14. Revenue_growth_ratio_next_year = future 12m / prior 12m\n",
    "    past_365 = dpr[\n",
    "        (dpr[\"payment_date\"] >= (T - pd.Timedelta(days=365)))\n",
    "        & (dpr[\"payment_date\"] < T)\n",
    "    ]\n",
    "    past_sum = _sum_by_donor(past_365, \"payment_amount\")\n",
    "    future_sum = _sum_by_donor(dpr_365, \"payment_amount\")\n",
    "    denom = past_sum.replace({0.0: np.nan})\n",
    "    out[\"label_revenue_growth_ratio_next_year\"] = future_sum / denom\n",
    "\n",
    "    # 15. Will_cross_midlevel_threshold_next_12m (using grand future 12m)\n",
    "    out[\"label_will_cross_midlevel_threshold_next_12m\"] = (\n",
    "        out[\"label_grand_revenue_next_365d\"] >= MIDLEVEL_THRESHOLD\n",
    "    ).astype(float)\n",
    "\n",
    "    # 16. Will_cross_tiptop_threshold_next_12m (using grand future 12m)\n",
    "    out[\"label_will_cross_midlevel_threshold_next_12m\"] = (\n",
    "        out[\"label_grand_revenue_next_365d\"] >= TIPTOP_THRESHOLD\n",
    "    ).astype(float)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# C. Monthly Program (6 labels)\n",
    "# ---------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Monthly Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _labels_monthly_program(df_monthly: pd.DataFrame, T: pd.Timestamp) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    C. Monthly Program.\n",
    "\n",
    "    Labels:\n",
    "      - label_will_start_monthly_next_90d\n",
    "      - label_will_start_monthly_next_365d\n",
    "      - label_will_churn_monthly_next_6m\n",
    "      - label_monthly_amt_next_6m\n",
    "      - label_will_upgrade_monthly_next_6m\n",
    "      - label_will_downgrade_monthly_next_6m\n",
    "    \"\"\"\n",
    "    if df_monthly is None or len(df_monthly) == 0:\n",
    "        return pd.DataFrame(index=pd.Index([], name=\"donor_id\"))\n",
    "\n",
    "    m = df_monthly.copy()\n",
    "    if \"monthly_subscription_joined_date\" in m.columns:\n",
    "        m[\"monthly_subscription_joined_date\"] = pd.to_datetime(\n",
    "            m[\"monthly_subscription_joined_date\"]\n",
    "        )\n",
    "    if \"monthly_subscription_retired_date\" in m.columns:\n",
    "        m[\"monthly_subscription_retired_date\"] = pd.to_datetime(\n",
    "            m[\"monthly_subscription_retired_date\"]\n",
    "        )\n",
    "    if \"charge_date\" in m.columns:\n",
    "        m[\"charge_date\"] = pd.to_datetime(m[\"charge_date\"])\n",
    "\n",
    "    donor_index = m[\"donor_id\"].drop_duplicates().sort_values()\n",
    "    out = pd.DataFrame(index=donor_index)\n",
    "\n",
    "    # Active at T\n",
    "    if {\"monthly_subscription_joined_date\", \"monthly_subscription_retired_date\"} <= set(m.columns):\n",
    "        active_at_T = (\n",
    "            (m[\"monthly_subscription_joined_date\"] <= T)\n",
    "            & (\n",
    "                m[\"monthly_subscription_retired_date\"].isna()\n",
    "                | (m[\"monthly_subscription_retired_date\"] > T)\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        # If subscription dates are missing, we cannot determine activity; return NaNs.\n",
    "        out[\"label_will_start_monthly_next_90d\"] = np.nan\n",
    "        out[\"label_will_start_monthly_next_365d\"] = np.nan\n",
    "        out[\"label_will_churn_monthly_next_6m\"] = np.nan\n",
    "        out[\"label_monthly_amt_next_6m\"] = np.nan\n",
    "        out[\"label_will_upgrade_monthly_next_6m\"] = np.nan\n",
    "        out[\"label_will_downgrade_monthly_next_6m\"] = np.nan\n",
    "        return out\n",
    "\n",
    "    # 17â€“18. Will_start_monthly_next_90d / 365d among non-monthly donors at T\n",
    "    non_active_at_T = ~active_at_T\n",
    "\n",
    "    join_90 = (\n",
    "        (m[\"monthly_subscription_joined_date\"] >= T)\n",
    "        & (m[\"monthly_subscription_joined_date\"] < T + pd.Timedelta(days=90))\n",
    "    )\n",
    "    join_365 = (\n",
    "        (m[\"monthly_subscription_joined_date\"] >= T)\n",
    "        & (m[\"monthly_subscription_joined_date\"] < T + pd.Timedelta(days=365))\n",
    "    )\n",
    "\n",
    "    will_start_90 = m[non_active_at_T & join_90]\n",
    "    will_start_365 = m[non_active_at_T & join_365]\n",
    "\n",
    "    out[\"label_will_start_monthly_next_90d\"] = _any_by_donor(will_start_90)\n",
    "    out[\"label_will_start_monthly_next_365d\"] = _any_by_donor(will_start_365)\n",
    "\n",
    "    # 19. Will_churn_monthly_next_6m (active at T and retire in next 180d)\n",
    "    retire_6m = (\n",
    "        (m[\"monthly_subscription_retired_date\"] >= T)\n",
    "        & (m[\"monthly_subscription_retired_date\"] < T + pd.Timedelta(days=180))\n",
    "    )\n",
    "    churn_candidates = m[active_at_T & retire_6m]\n",
    "    out[\"label_will_churn_monthly_next_6m\"] = _any_by_donor(churn_candidates)\n",
    "\n",
    "    # 20. Monthly_amt_next_6m = total subscription charges in 6m\n",
    "    if \"charge_date\" in m.columns and \"monthly_subscription_payment_amount\" in m.columns:\n",
    "        charges_6m = _future_window(m, \"charge_date\", T, 180)\n",
    "        out[\"label_monthly_amt_next_6m\"] = _sum_by_donor(\n",
    "            charges_6m, \"monthly_subscription_payment_amount\"\n",
    "        )\n",
    "    else:\n",
    "        out[\"label_monthly_amt_next_6m\"] = np.nan\n",
    "\n",
    "    # 21â€“22. Upgrade / downgrade within 6m\n",
    "    if \"charge_date\" in m.columns and \"monthly_subscription_payment_amount\" in m.columns:\n",
    "        past_6m = m[\n",
    "            (m[\"charge_date\"] >= (T - pd.Timedelta(days=180)))\n",
    "            & (m[\"charge_date\"] < T)\n",
    "        ]\n",
    "        future_6m = charges_6m\n",
    "\n",
    "        past_med = past_6m.groupby(\"donor_id\")[\n",
    "            \"monthly_subscription_payment_amount\"\n",
    "        ].median()\n",
    "        fut_med = future_6m.groupby(\"donor_id\")[\n",
    "            \"monthly_subscription_payment_amount\"\n",
    "        ].median()\n",
    "\n",
    "        diff = fut_med - past_med.reindex(fut_med.index)\n",
    "        out[\"label_will_upgrade_monthly_next_6m\"] = (diff > 0).astype(float)\n",
    "        out[\"label_will_downgrade_monthly_next_6m\"] = (diff < 0).astype(float)\n",
    "    else:\n",
    "        out[\"label_will_upgrade_monthly_next_6m\"] = np.nan\n",
    "        out[\"label_will_downgrade_monthly_next_6m\"] = np.nan\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Midlevel / Major / DAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _labels_mid_major_daf(df_dpr: pd.DataFrame, T: pd.Timestamp) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    D. Midlevel / Major / DAF.\n",
    "\n",
    "    Labels:\n",
    "      - label_daf_revenue_next_365d\n",
    "      - label_will_make_daf_gift_next_365d\n",
    "      - label_will_shift_to_daf_heavy_next_12m\n",
    "      - label_will_be_midlevel_grand_next_12m\n",
    "      - label_will_make_large_single_gift_next_365d\n",
    "    \"\"\"\n",
    "    dpr = df_dpr.copy()\n",
    "    dpr[\"payment_date\"] = pd.to_datetime(dpr[\"payment_date\"])\n",
    "\n",
    "    # Ensure daf_payment column exists\n",
    "    if \"daf_payment\" not in dpr.columns:\n",
    "        dpr[\"daf_payment\"] = 0\n",
    "\n",
    "    donor_index = dpr[\"donor_id\"].drop_duplicates().sort_values()\n",
    "    out = pd.DataFrame(index=donor_index)\n",
    "\n",
    "    dpr_365 = _future_window(dpr, \"payment_date\", T, 365)\n",
    "    dpr_12m = dpr_365\n",
    "    dpr_24m = _future_window(dpr, \"payment_date\", T, 365 * 2)\n",
    "\n",
    "    # 23. DAF_revenue_next_365d\n",
    "    daf_365 = dpr_365[dpr_365[\"daf_payment\"] == 1]\n",
    "    out[\"label_daf_revenue_next_365d\"] = _sum_by_donor(daf_365, \"payment_amount\")\n",
    "\n",
    "    # 24. Will_make_DAF_gift_next_365d\n",
    "    out[\"label_will_make_daf_gift_next_365d\"] = _any_by_donor(daf_365)\n",
    "\n",
    "    # 25. Will_shift_to_DAF_heavy_next_12m (>=50% future dollars via DAF)\n",
    "    future_sum = _sum_by_donor(dpr_12m, \"payment_amount\")\n",
    "    daf_sum = _sum_by_donor(daf_365, \"payment_amount\")\n",
    "    share_daf = daf_sum / future_sum.replace({0.0: np.nan})\n",
    "    out[\"label_will_shift_to_daf_heavy_next_12m\"] = (share_daf >= 0.5).astype(float)\n",
    "\n",
    "    # 26. Will_be_midlevel_grand_next_12m\n",
    "    out[\"label_will_be_midlevel_grand_next_12m\"] = (\n",
    "        future_sum >= MIDLEVEL_THRESHOLD\n",
    "    ).astype(float)\n",
    "\n",
    "    # 27. Will_make_large_single_gift_next_365d (>= configurable $X)\n",
    "    large_365 = dpr_365[dpr_365[\"payment_amount\"] >= LARGE_SINGLE_GIFT_THRESHOLD]\n",
    "    out[\"label_will_make_large_single_gift_next_365d\"] = _any_by_donor(large_365)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# E. Email Engagement (5 labels)\n",
    "# ---------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Email Engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _labels_email_engagement(df_email: pd.DataFrame, T: pd.Timestamp) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    E. Email Engagement.\n",
    "\n",
    "    Labels:\n",
    "      - label_email_open_rate_next_90d\n",
    "      - label_email_click_rate_next_90d\n",
    "      - label_will_open_next_campaign_email\n",
    "      - label_will_click_next_campaign_email\n",
    "      - label_will_unsubscribe_next_90d\n",
    "\n",
    "    This implementation assumes df_email is monthly-aggregated email activity\n",
    "    with columns like:\n",
    "      - donor_id\n",
    "      - email_sent_month (or send_datetime)\n",
    "      - email_sent_count\n",
    "      - email_open_count\n",
    "      - email_click_count\n",
    "\n",
    "    Campaign-level and unsubscribe labels are set to NaN unless the relevant\n",
    "    event-level columns are present.\n",
    "    \"\"\"\n",
    "    if df_email is None or len(df_email) == 0:\n",
    "        return pd.DataFrame(index=pd.Index([], name=\"donor_id\"))\n",
    "\n",
    "    email = df_email.copy()\n",
    "    date_col = \"send_datetime\" if \"send_datetime\" in email.columns else \"email_sent_month\"\n",
    "    email[date_col] = pd.to_datetime(email[date_col])\n",
    "\n",
    "    donor_index = email[\"donor_id\"].drop_duplicates().sort_values()\n",
    "    out = pd.DataFrame(index=donor_index)\n",
    "\n",
    "    email_90 = _future_window(email, date_col, T, 90)\n",
    "\n",
    "    # 28â€“29. Open/click rate in next 90d: open_count / sent_count\n",
    "    if {\"email_sent_count\", \"email_open_count\", \"email_click_count\"} <= set(email_90.columns):\n",
    "        sent = email_90.groupby(\"donor_id\")[\"email_sent_count\"].sum()\n",
    "        opened = email_90.groupby(\"donor_id\")[\"email_open_count\"].sum()\n",
    "        clicked = email_90.groupby(\"donor_id\")[\"email_click_count\"].sum()\n",
    "\n",
    "        denom = sent.replace({0.0: np.nan})\n",
    "        out[\"label_email_open_rate_next_90d\"] = (opened / denom).astype(float)\n",
    "        out[\"label_email_click_rate_next_90d\"] = (clicked / denom).astype(float)\n",
    "    else:\n",
    "        out[\"label_email_open_rate_next_90d\"] = np.nan\n",
    "        out[\"label_email_click_rate_next_90d\"] = np.nan\n",
    "\n",
    "    # 30. Will_open_next_campaign_email\n",
    "    if {\"is_campaign_email\", \"opened_flag\"} <= set(email.columns):\n",
    "        campaign = email[email[\"is_campaign_email\"] == 1]\n",
    "        future_campaign = campaign[campaign[date_col] > T]\n",
    "        first_campaign = (\n",
    "            future_campaign\n",
    "            .sort_values([\"donor_id\", date_col])\n",
    "            .groupby(\"donor_id\")\n",
    "            .head(1)\n",
    "        )\n",
    "        opened = first_campaign.set_index(\"donor_id\")[\"opened_flag\"].astype(float)\n",
    "        out[\"label_will_open_next_campaign_email\"] = opened\n",
    "    else:\n",
    "        out[\"label_will_open_next_campaign_email\"] = np.nan\n",
    "\n",
    "    # 31. Will_click_next_campaign_email\n",
    "    if {\"is_campaign_email\", \"clicked_flag\"} <= set(email.columns):\n",
    "        campaign = email[email[\"is_campaign_email\"] == 1]\n",
    "        future_campaign = campaign[campaign[date_col] > T]\n",
    "        first_campaign = (\n",
    "            future_campaign\n",
    "            .sort_values([\"donor_id\", date_col])\n",
    "            .groupby(\"donor_id\")\n",
    "            .head(1)\n",
    "        )\n",
    "        clicked = first_campaign.set_index(\"donor_id\")[\"clicked_flag\"].astype(float)\n",
    "        out[\"label_will_click_next_campaign_email\"] = clicked\n",
    "    else:\n",
    "        out[\"label_will_click_next_campaign_email\"] = np.nan\n",
    "\n",
    "    # 32. Will_unsubscribe_next_90d\n",
    "    if \"event_type\" in email_90.columns:\n",
    "        unsub_90 = email_90[email_90[\"event_type\"] == \"unsubscribe\"]\n",
    "        out[\"label_will_unsubscribe_next_90d\"] = _any_by_donor(unsub_90)\n",
    "    elif \"unsubscribe_datetime\" in email.columns:\n",
    "        email[\"unsubscribe_datetime\"] = pd.to_datetime(email[\"unsubscribe_datetime\"])\n",
    "        unsub_90 = email[\n",
    "            (email[\"unsubscribe_datetime\"] >= T)\n",
    "            & (email[\"unsubscribe_datetime\"] < T + pd.Timedelta(days=90))\n",
    "        ]\n",
    "        out[\"label_will_unsubscribe_next_90d\"] = _any_by_donor(unsub_90)\n",
    "    else:\n",
    "        out[\"label_will_unsubscribe_next_90d\"] = np.nan\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# F. Site Behavior & Activity (5 labels)\n",
    "# ---------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Site Behavior & Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _labels_site_behavior(df_site: pd.DataFrame, df_dpr: pd.DataFrame, T: pd.Timestamp) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    F. Site Behavior & Activity.\n",
    "\n",
    "    Labels:\n",
    "      - label_will_visit_site_next_30d\n",
    "      - label_num_sessions_next_90d\n",
    "      - label_project_page_views_next_90d\n",
    "      - label_will_view_local_projects_next_90d\n",
    "      - label_will_login_next_30d\n",
    "\n",
    "    This implementation expects df_site to contain at least:\n",
    "      - donor_id\n",
    "      - activity_date\n",
    "      - optionally: session_id, project_page_visits_day, is_login_event\n",
    "\n",
    "    The \"local project view\" label is currently left as NaN unless project-\n",
    "    level pageview data with location is available.\n",
    "    \"\"\"\n",
    "    if df_site is None or len(df_site) == 0:\n",
    "        return pd.DataFrame(index=pd.Index([], name=\"donor_id\"))\n",
    "\n",
    "    site = df_site.copy()\n",
    "    if \"activity_date\" not in site.columns:\n",
    "        return pd.DataFrame(index=pd.Index([], name=\"donor_id\"))\n",
    "\n",
    "    site[\"activity_date\"] = pd.to_datetime(site[\"activity_date\"])\n",
    "    donor_index = site[\"donor_id\"].drop_duplicates().sort_values()\n",
    "    out = pd.DataFrame(index=donor_index)\n",
    "\n",
    "    site_30 = _future_window(site, \"activity_date\", T, 30)\n",
    "    site_90 = _future_window(site, \"activity_date\", T, 90)\n",
    "\n",
    "    # 33. Will_visit_site_next_30d\n",
    "    out[\"label_will_visit_site_next_30d\"] = _any_by_donor(site_30)\n",
    "\n",
    "    # 34. Num_sessions_next_90d\n",
    "    if \"session_id\" in site_90.columns:\n",
    "        sessions_90 = site_90.drop_duplicates([\"donor_id\", \"session_id\"])\n",
    "        out[\"label_num_sessions_next_90d\"] = _count_by_donor(sessions_90)\n",
    "    else:\n",
    "        sessions_90 = site_90.drop_duplicates([\"donor_id\", \"activity_date\"])\n",
    "        out[\"label_num_sessions_next_90d\"] = _count_by_donor(sessions_90)\n",
    "\n",
    "    # 35. Project_page_views_next_90d\n",
    "    if \"project_page_visits_day\" in site_90.columns:\n",
    "        pv = site_90.groupby(\"donor_id\")[\n",
    "            \"project_page_visits_day\"\n",
    "        ].sum().astype(float)\n",
    "        out[\"label_project_page_views_next_90d\"] = pv\n",
    "    else:\n",
    "        out[\"label_project_page_views_next_90d\"] = np.nan\n",
    "\n",
    "    # 36. Will_view_local_projects_next_90d\n",
    "    # out[\"label_will_view_local_projects_next_90d\"] = np.nan\n",
    "\n",
    "    # 37. Will_login_next_30d\n",
    "    if \"is_login_event\" in site_30.columns:\n",
    "        login_30 = site_30[site_30[\"is_login_event\"] == 1]\n",
    "        out[\"label_will_login_next_30d\"] = _any_by_donor(login_30)\n",
    "    else:\n",
    "        out[\"label_will_login_next_30d\"] = np.nan\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# G. Product & Project Preference (6 labels)\n",
    "# ---------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Product & Project Preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _labels_product_and_project_preference(df_dpr: pd.DataFrame, T: pd.Timestamp) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    G. Product & Project Preference.\n",
    "\n",
    "    Labels:\n",
    "      - label_next_gift_category\n",
    "      - label_next_gift_grade_band\n",
    "      - label_will_give_local_next_365d\n",
    "      - label_pct_future_dollars_to_top_category_next_365d\n",
    "      - label_will_give_to_teacher_previously_supported_next_365d\n",
    "      - label_will_give_to_new_schools_next_365d\n",
    "    \"\"\"\n",
    "    dpr = df_dpr.copy()\n",
    "    dpr[\"payment_date\"] = pd.to_datetime(dpr[\"payment_date\"])\n",
    "    donor_index = dpr[\"donor_id\"].drop_duplicates().sort_values()\n",
    "    out = pd.DataFrame(index=donor_index)\n",
    "\n",
    "    future_all = dpr[dpr[\"payment_date\"] >= T]\n",
    "    future_365 = _future_window(dpr, \"payment_date\", T, 365)\n",
    "    history = dpr[dpr[\"payment_date\"] < T]\n",
    "\n",
    "    # 38. Next_gift_category: category of first future gift\n",
    "    if \"project_category\" in dpr.columns:\n",
    "        first_future = (\n",
    "            future_all\n",
    "            .sort_values([\"donor_id\", \"payment_date\"])\n",
    "            .groupby(\"donor_id\")\n",
    "            .head(1)\n",
    "        )\n",
    "        out[\"label_next_gift_category\"] = first_future.set_index(\"donor_id\")[\n",
    "            \"project_category\"\n",
    "        ]\n",
    "    else:\n",
    "        out[\"label_next_gift_category\"] = np.nan\n",
    "\n",
    "    # 39. Next_gift_grade_band\n",
    "    if \"project_grade\" in dpr.columns:\n",
    "        if \"project_category\" not in dpr.columns:\n",
    "            first_future = (\n",
    "                future_all\n",
    "                .sort_values([\"donor_id\", \"payment_date\"])\n",
    "                .groupby(\"donor_id\")\n",
    "                .head(1)\n",
    "            )\n",
    "        out[\"label_next_gift_grade_band\"] = first_future.set_index(\"donor_id\")[\n",
    "            \"project_grade\"\n",
    "        ]\n",
    "    else:\n",
    "        out[\"label_next_gift_grade_band\"] = np.nan\n",
    "\n",
    "    # 40. Will_give_local_next_365d (distance_mi <= local_radius)\n",
    "    local_radius_mi = 25.0\n",
    "    if \"distance_mi\" in future_365.columns:\n",
    "        local_365 = future_365[future_365[\"distance_mi\"] <= local_radius_mi]\n",
    "        out[\"label_will_give_local_next_365d\"] = _any_by_donor(local_365)\n",
    "    else:\n",
    "        out[\"label_will_give_local_next_365d\"] = np.nan\n",
    "\n",
    "    # 41. Pct_future_dollars_to_top_category_next_365d\n",
    "    if {\"project_category\", \"payment_amount\"} <= set(future_365.columns):\n",
    "        cat_amount = future_365.groupby([\"donor_id\", \"project_category\"])[\n",
    "            \"payment_amount\"\n",
    "        ].sum()\n",
    "        total_amount = future_365.groupby(\"donor_id\")[\"payment_amount\"].sum()\n",
    "        if not cat_amount.empty:\n",
    "            top_cat = cat_amount.groupby(\"donor_id\").max()\n",
    "            pct_top = top_cat / total_amount.replace({0.0: np.nan})\n",
    "            out[\"label_pct_future_dollars_to_top_category_next_365d\"] = (\n",
    "                pct_top.astype(float)\n",
    "            )\n",
    "        else:\n",
    "            out[\"label_pct_future_dollars_to_top_category_next_365d\"] = np.nan\n",
    "    else:\n",
    "        out[\"label_pct_future_dollars_to_top_category_next_365d\"] = np.nan\n",
    "\n",
    "    # 42. Will_give_to_teacher_previously_supported_next_365d\n",
    "    if \"teacher_id\" in dpr.columns:\n",
    "        prior_teachers = (\n",
    "            history.groupby(\"donor_id\")[\"teacher_id\"].unique().to_dict()\n",
    "        )\n",
    "        future_teachers = (\n",
    "            future_365.groupby(\"donor_id\")[\"teacher_id\"].unique().to_dict()\n",
    "        )\n",
    "\n",
    "        def _teacher_loyalty(d_id):\n",
    "            hist = set(prior_teachers.get(d_id, []))\n",
    "            fut = set(future_teachers.get(d_id, []))\n",
    "            return float(len(hist & fut) > 0)\n",
    "\n",
    "        out[\"label_will_give_to_teacher_previously_supported_next_365d\"] = (\n",
    "            out.index.to_series().map(_teacher_loyalty)\n",
    "        )\n",
    "    else:\n",
    "        out[\"label_will_give_to_teacher_previously_supported_next_365d\"] = np.nan\n",
    "\n",
    "    # 43. Will_give_to_new_schools_next_365d\n",
    "    if \"school_id\" in dpr.columns:\n",
    "        prior_schools = (\n",
    "            history.groupby(\"donor_id\")[\"school_id\"].unique().to_dict()\n",
    "        )\n",
    "        future_schools = (\n",
    "            future_365.groupby(\"donor_id\")[\"school_id\"].unique().to_dict()\n",
    "        )\n",
    "\n",
    "        def _new_school(d_id):\n",
    "            hist = set(prior_schools.get(d_id, []))\n",
    "            fut = set(future_schools.get(d_id, []))\n",
    "            return float(len(fut - hist) > 0)\n",
    "\n",
    "        out[\"label_will_give_to_new_schools_next_365d\"] = (\n",
    "            out.index.to_series().map(_new_school)\n",
    "        )\n",
    "    else:\n",
    "        out[\"label_will_give_to_new_schools_next_365d\"] = np.nan\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# H. Seasonality & Events (4 labels)\n",
    "# ---------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Seasonality & Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _labels_seasonality_and_events(df_dpr: pd.DataFrame, T: pd.Timestamp) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    H. Seasonality & Events.\n",
    "\n",
    "    Labels:\n",
    "      - label_will_give_in_back_to_school_season\n",
    "      - label_will_give_during_eoy\n",
    "      - label_will_be_event_responsive_next_12m\n",
    "      - label_quarter_of_max_future_giving_next_12m\n",
    "    \"\"\"\n",
    "    dpr = df_dpr.copy()\n",
    "    dpr[\"payment_date\"] = pd.to_datetime(dpr[\"payment_date\"])\n",
    "    donor_index = dpr[\"donor_id\"].drop_duplicates().sort_values()\n",
    "    out = pd.DataFrame(index=donor_index)\n",
    "\n",
    "    dpr_12m = _future_window(dpr, \"payment_date\", T, 365)\n",
    "    if len(dpr_12m) == 0:\n",
    "        out[\"label_will_give_in_back_to_school_season\"] = np.nan\n",
    "        out[\"label_will_give_during_eoy\"] = np.nan\n",
    "        out[\"label_will_be_event_responsive_next_12m\"] = np.nan\n",
    "        out[\"label_quarter_of_max_future_giving_next_12m\"] = np.nan\n",
    "        return out\n",
    "\n",
    "    dpr_12m = dpr_12m.copy()\n",
    "    dpr_12m[\"month\"] = dpr_12m[\"payment_date\"].dt.month\n",
    "\n",
    "    # 44. Will_give_in_back_to_school_season (Augâ€“Sep)\n",
    "    bts = dpr_12m[dpr_12m[\"month\"].isin([8, 9])]\n",
    "    out[\"label_will_give_in_back_to_school_season\"] = _any_by_donor(bts)\n",
    "\n",
    "    # 45. Will_give_during_EOY (Dec 24â€“31)\n",
    "    eoy = dpr_12m[\n",
    "        (dpr_12m[\"payment_date\"].dt.month == 12)\n",
    "        & (dpr_12m[\"payment_date\"].dt.day >= 24)\n",
    "    ]\n",
    "    out[\"label_will_give_during_eoy\"] = _any_by_donor(eoy)\n",
    "\n",
    "    # 46. Will_be_event_responsive_next_12m (>= N gifts on defined events)\n",
    "    N = 2\n",
    "    if \"payment_on_big_event\" in dpr_12m.columns:\n",
    "        events = dpr_12m[dpr_12m[\"payment_on_big_event\"] == 1]\n",
    "        counts = _count_by_donor(events)\n",
    "        out[\"label_will_be_event_responsive_next_12m\"] = (counts >= N).astype(float)\n",
    "    else:\n",
    "        out[\"label_will_be_event_responsive_next_12m\"] = np.nan\n",
    "\n",
    "    # 47. Quarter_of_max_future_giving_next_12m (rolling quarters from T)\n",
    "    if \"payment_amount\" in dpr_12m.columns:\n",
    "        dpr_12m[\"days_since_T\"] = (dpr_12m[\"payment_date\"] - T).dt.days\n",
    "        dpr_12m[\"quarter\"] = pd.cut(\n",
    "            dpr_12m[\"days_since_T\"],\n",
    "            bins=[-1, 89, 179, 269, 365],\n",
    "            labels=[\"Q1\", \"Q2\", \"Q3\", \"Q4\"],\n",
    "        )\n",
    "        amount_by_q = dpr_12m.groupby([\"donor_id\", \"quarter\"])[\"payment_amount\"].sum()\n",
    "        if not amount_by_q.empty:\n",
    "            q_sum = amount_by_q.unstack(fill_value=0.0)\n",
    "            quarter_max = q_sum.idxmax(axis=1)\n",
    "            out[\"label_quarter_of_max_future_giving_next_12m\"] = quarter_max\n",
    "        else:\n",
    "            out[\"label_quarter_of_max_future_giving_next_12m\"] = np.nan\n",
    "    else:\n",
    "        out[\"label_quarter_of_max_future_giving_next_12m\"] = np.nan\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# I. Operational / Mechanism Behavior (3 labels)\n",
    "# ---------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 Operational / Mechanism Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _labels_operational_mechanism(df_dpr: pd.DataFrame, T: pd.Timestamp) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    I. Operational / Mechanism Behavior.\n",
    "\n",
    "    Labels:\n",
    "      - label_will_use_account_credit_next_90d\n",
    "      - label_optional_donation_rate_on_next_gift\n",
    "      - label_will_make_gift_card_purchase_next_12m\n",
    "    \"\"\"\n",
    "    dpr = df_dpr.copy()\n",
    "    dpr[\"payment_date\"] = pd.to_datetime(dpr[\"payment_date\"])\n",
    "    donor_index = dpr[\"donor_id\"].drop_duplicates().sort_values()\n",
    "    out = pd.DataFrame(index=donor_index)\n",
    "\n",
    "    dpr_90 = _future_window(dpr, \"payment_date\", T, 90)\n",
    "    dpr_12m = _future_window(dpr, \"payment_date\", T, 365)\n",
    "\n",
    "    # 48. Will_use_account_credit_next_90d\n",
    "    if \"account_credit_amount\" in dpr_90.columns:\n",
    "        credit_90 = dpr_90[dpr_90[\"account_credit_amount\"] > 0]\n",
    "        out[\"label_will_use_account_credit_next_90d\"] = _any_by_donor(credit_90)\n",
    "    else:\n",
    "        out[\"label_will_use_account_credit_next_90d\"] = np.nan\n",
    "\n",
    "    # 49. Optional_donation_rate_on_next_gift\n",
    "    next_future = (\n",
    "        dpr[dpr[\"payment_date\"] >= T]\n",
    "        .sort_values([\"donor_id\", \"payment_date\"])\n",
    "        .groupby(\"donor_id\")\n",
    "        .head(1)\n",
    "    )\n",
    "    if \"optional_donation_rate\" in next_future.columns:\n",
    "        rate = next_future.set_index(\"donor_id\")[\n",
    "            \"optional_donation_rate\"\n",
    "        ].astype(float)\n",
    "        out[\"label_optional_donation_rate_on_next_gift\"] = rate\n",
    "    else:\n",
    "        out[\"label_optional_donation_rate_on_next_gift\"] = np.nan\n",
    "\n",
    "    # 50. Will_make_gift_card_purchase_next_12m\n",
    "    if \"gift_card_purchase\" in dpr_12m.columns:\n",
    "        gc_12m = dpr_12m[dpr_12m[\"gift_card_purchase\"] == 1]\n",
    "        out[\"label_will_make_gift_card_purchase_next_12m\"] = _any_by_donor(gc_12m)\n",
    "    else:\n",
    "        out[\"label_will_make_gift_card_purchase_next_12m\"] = np.nan\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Main Construction Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Build Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _build_labels(\n",
    "    df_dpr: pd.DataFrame,\n",
    "    df_monthly: pd.DataFrame,\n",
    "    df_share: pd.DataFrame,\n",
    "    df_email: pd.DataFrame,\n",
    "    df_site: pd.DataFrame,\n",
    "    T,\n",
    "    H=None,\n",
    "    donor_index=None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build future-focused labels for multiple horizons and behaviors.\n",
    "\n",
    "    If donor_index is provided, it will be used as the row universe for labels\n",
    "    (e.g., the same as the feature frame index). Otherwise, donors present in\n",
    "    df_dpr are used.\n",
    "    \"\"\"\n",
    "    T = pd.to_datetime(T)\n",
    "    _validate_dpr_for_labels(df_dpr)\n",
    "\n",
    "    if donor_index is None:\n",
    "        donor_index = (\n",
    "            df_dpr[\"donor_id\"]\n",
    "            .drop_duplicates()\n",
    "            .sort_values()\n",
    "        )\n",
    "    else:\n",
    "        # Ensure it's a clean, sorted Index\n",
    "        donor_index = (\n",
    "            pd.Index(donor_index)\n",
    "            .drop_duplicates()\n",
    "            .sort_values()\n",
    "        )\n",
    "\n",
    "    labels = pd.DataFrame(index=donor_index)\n",
    "\n",
    "    # A. Core Giving Propensity\n",
    "    labels = labels.join(\n",
    "        _labels_core_giving_propensity(df_dpr, T),\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # B. Revenue & Value\n",
    "    labels = labels.join(\n",
    "        _labels_revenue_and_value(df_dpr, df_monthly, T),\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # C. Monthly Program\n",
    "    labels = labels.join(\n",
    "        _labels_monthly_program(df_monthly, T),\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # D. Midlevel / Major / DAF\n",
    "    labels = labels.join(\n",
    "        _labels_mid_major_daf(df_dpr, T),\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # E. Email Engagement\n",
    "    labels = labels.join(\n",
    "        _labels_email_engagement(df_email, T),\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # F. Site Behavior & Activity\n",
    "    labels = labels.join(\n",
    "        _labels_site_behavior(df_site, df_dpr, T),\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # G. Product & Project Preference\n",
    "    labels = labels.join(\n",
    "        _labels_product_and_project_preference(df_dpr, T),\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # H. Seasonality & Events\n",
    "    labels = labels.join(\n",
    "        _labels_seasonality_and_events(df_dpr, T),\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # I. Operational / Mechanism Behavior\n",
    "    labels = labels.join(\n",
    "        _labels_operational_mechanism(df_dpr, T),\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Impute Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _apply_label_imputation(features: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply label-specific imputations in place, returning the modified DataFrame.\n",
    "\n",
    "    This expects label columns to be prefixed with 'label_' and uses the\n",
    "    imputation rules agreed in the label design (binary -> 0, counts -> 0,\n",
    "    amounts -> 0, rates -> 0, ratio -> 1.0, time-to-event -> sentinel,\n",
    "    categorical -> 'NONE').\n",
    "    \"\"\"\n",
    "    if features is None or features.empty:\n",
    "        return features\n",
    "\n",
    "    features = features.copy()\n",
    "\n",
    "    # Binary 0/1 labels\n",
    "    binary_labels = [\n",
    "        \"label_will_give_next_30d\",\n",
    "        \"label_will_give_next_90d\",\n",
    "        \"label_will_give_next_365d\",\n",
    "        \"label_will_give_2plus_times_next_365d\",\n",
    "        \"label_will_make_big_event_gift_next_365d\",\n",
    "        \"label_will_cross_midlevel_threshold_next_12m\",\n",
    "        \"label_will_make_major_gift_next_24m\",\n",
    "        \"label_will_start_monthly_next_90d\",\n",
    "        \"label_will_start_monthly_next_365d\",\n",
    "        \"label_will_churn_monthly_next_6m\",\n",
    "        \"label_will_upgrade_monthly_next_6m\",\n",
    "        \"label_will_downgrade_monthly_next_6m\",\n",
    "        \"label_will_make_daf_gift_next_365d\",\n",
    "        \"label_will_shift_to_daf_heavy_next_12m\",\n",
    "        \"label_will_be_midlevel_grand_next_12m\",\n",
    "        \"label_will_make_large_single_gift_next_365d\",\n",
    "        \"label_will_open_next_campaign_email\",\n",
    "        \"label_will_click_next_campaign_email\",\n",
    "        \"label_will_unsubscribe_next_90d\",\n",
    "        \"label_will_visit_site_next_30d\",\n",
    "        \"label_will_view_local_projects_next_90d\",\n",
    "        \"label_will_login_next_30d\",\n",
    "        \"label_will_give_local_next_365d\",\n",
    "        \"label_will_give_to_teacher_previously_supported_next_365d\",\n",
    "        \"label_will_give_to_new_schools_next_365d\",\n",
    "        \"label_will_give_in_back_to_school_season\",\n",
    "        \"label_will_give_during_eoy\",\n",
    "        \"label_will_be_event_responsive_next_12m\",\n",
    "        \"label_will_use_account_credit_next_90d\",\n",
    "        \"label_will_make_gift_card_purchase_next_12m\",\n",
    "    ]\n",
    "\n",
    "    # Count labels\n",
    "    count_labels = [\n",
    "        \"label_num_gifts_next_365d\",\n",
    "        \"label_num_green_gifts_next_365d\",\n",
    "        \"label_num_sessions_next_90d\",\n",
    "        \"label_project_page_views_next_90d\",\n",
    "    ]\n",
    "\n",
    "    # Dollar amount labels\n",
    "    amount_labels = [\n",
    "        \"label_green_revenue_next_365d\",\n",
    "        \"label_project_revenue_next_365d\",\n",
    "        \"label_monthly_revenue_next_365d\",\n",
    "        \"label_grand_revenue_next_365d\",\n",
    "        \"label_max_single_gift_next_365d\",\n",
    "        \"label_monthly_amt_next_6m\",\n",
    "        \"label_daf_revenue_next_365d\",\n",
    "    ]\n",
    "\n",
    "    # Rate/fraction labels (0â€“1)\n",
    "    rate_labels = [\n",
    "        \"label_email_open_rate_next_90d\",\n",
    "        \"label_email_click_rate_next_90d\",\n",
    "        \"label_pct_future_dollars_to_top_category_next_365d\",\n",
    "        \"label_optional_donation_rate_on_next_gift\",\n",
    "    ]\n",
    "\n",
    "    # Ratio labels where 1.0 = \"no change\"\n",
    "    ratio_labels = [\n",
    "        \"label_revenue_growth_ratio_next_year\",\n",
    "    ]\n",
    "\n",
    "    # Time-to-event labels\n",
    "    time_to_event_labels = [\n",
    "        \"label_time_to_next_gift_days\",\n",
    "    ]\n",
    "\n",
    "    # Categorical labels\n",
    "    categorical_labels = [\n",
    "        \"label_next_gift_category\",\n",
    "        \"label_next_gift_grade_band\",\n",
    "        \"label_quarter_of_max_future_giving_next_12m\",\n",
    "    ]\n",
    "\n",
    "    # Apply imputations\n",
    "    for col in binary_labels:\n",
    "        if col in features.columns:\n",
    "            features[col] = features[col].fillna(0.0).astype(float)\n",
    "\n",
    "    for col in count_labels:\n",
    "        if col in features.columns:\n",
    "            features[col] = features[col].fillna(0.0).astype(float)\n",
    "\n",
    "    for col in amount_labels:\n",
    "        if col in features.columns:\n",
    "            features[col] = features[col].fillna(0.0).astype(float)\n",
    "\n",
    "    for col in rate_labels:\n",
    "        if col in features.columns:\n",
    "            features[col] = features[col].fillna(0.0).astype(float)\n",
    "\n",
    "    for col in ratio_labels:\n",
    "        if col in features.columns:\n",
    "            features[col] = features[col].fillna(1.0).astype(float)\n",
    "\n",
    "    for col in time_to_event_labels:\n",
    "        if col in features.columns:\n",
    "            features[col] = features[col].fillna(TIME_TO_NEXT_GIFT_CENSOR_DAYS).astype(float)\n",
    "\n",
    "    for col in categorical_labels:\n",
    "        if col in features.columns:\n",
    "            features[col] = features[col].astype(object).fillna(\"NONE\").astype(str)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Build Features & Merge Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def build_features(\n",
    "    df_dpr,\n",
    "    df_email,\n",
    "    df_site,\n",
    "    df_monthly,\n",
    "    df_share,\n",
    "    df_zip_acs,\n",
    "    df_project_dates,\n",
    "    E,\n",
    "    T,\n",
    "    H\n",
    "):\n",
    "    \"\"\"\n",
    "    Build complete donor-level feature matrix as of time T.\n",
    "    \n",
    "    This is the main entry point for feature engineering. It:\n",
    "    1. Normalizes all timestamps\n",
    "    2. Filters data to events before T\n",
    "    3. Creates windowed subsets (3m, 12m, 36m)\n",
    "    4. Calls helper functions for each feature group\n",
    "    5. Optionally builds labels for horizon H\n",
    "    \n",
    "    IMPORTANT: This does NOT do final imputation or encoding.\n",
    "    You should call finalize_features() after this to handle:\n",
    "    - Missing value imputation\n",
    "    - Categorical encoding\n",
    "    - Feature scaling (if desired)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_dpr : pd.DataFrame\n",
    "        Donor Project Records with columns:\n",
    "        - donor_id, payment_date, payment_amount, donation_n\n",
    "        - donor_zip, is_teacher, is_teacher_referred\n",
    "        - teacher_id, school_id, project_id, project_category, etc.\n",
    "    df_email : pd.DataFrame\n",
    "        Email Events 12mo with columns:\n",
    "        - donor_id, email_sent_month\n",
    "        - email_sent_count, email_open_count, email_click_count\n",
    "    df_site : pd.DataFrame\n",
    "        Site Events with columns:\n",
    "        - donor_id, activity_date\n",
    "        - device_type, came_from_campaign\n",
    "        - project_page_visits_day, teacher_page_visits_day, etc.\n",
    "    df_monthly : pd.DataFrame\n",
    "        Monthly DonationLevel with columns:\n",
    "        - donor_id, monthly_subscription_joined_date\n",
    "        - monthly_subscription_retired_date\n",
    "        - monthly_subscription_payment_amount, charge_date\n",
    "    df_share : pd.DataFrame\n",
    "        Share Events with columns:\n",
    "        - donor_id, share_sent_month, share_event_count\n",
    "    df_zip_acs : pd.DataFrame\n",
    "        ZIP-level ACS demographics with column:\n",
    "        - ZIP5 (index), pct_households_with_children, unemployment_rate, etc.\n",
    "    T : pd.Timestamp or str\n",
    "        Reference time (as-of date) for feature computation\n",
    "        All features use only data strictly before this timestamp\n",
    "    H : pd.Timedelta, int, or None\n",
    "        Label horizon (e.g., pd.Timedelta(days=365) or 365)\n",
    "        If provided, labels will be computed for window [T, T+H)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Donor-level feature matrix indexed by donor_id\n",
    "        Contains ~150 columns across 11 feature groups\n",
    "        May contain NaN values that should be imputed\n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "    >>> T = pd.Timestamp('2024-01-01')\n",
    "    >>> H = pd.Timedelta(days=365)  # 12-month prediction\n",
    "    >>> features = build_features(\n",
    "    ...     df_dpr, df_email, df_site, df_monthly, df_share, df_zip_acs,\n",
    "    ...     T=T, H=H\n",
    "    ... )\n",
    "    >>> print(features.shape)\n",
    "    (100000, 152)  # 100k donors, 152 features\n",
    "    \"\"\"\n",
    "    # =====================================================================\n",
    "    # SETUP: Convert dates and normalize T\n",
    "    # =====================================================================\n",
    "    \n",
    "    T = pd.to_datetime(T)\n",
    "    \n",
    "    # Convert all date columns upfront (before eligibility filtering)\n",
    "    df_dpr = df_dpr.copy()\n",
    "    df_dpr['payment_date'] = pd.to_datetime(df_dpr['payment_date'])\n",
    "    \n",
    "    df_monthly = df_monthly.copy()\n",
    "    df_monthly['monthly_subscription_joined_date'] = pd.to_datetime(\n",
    "        df_monthly['monthly_subscription_joined_date']\n",
    "    )\n",
    "    df_monthly['monthly_subscription_retired_date'] = pd.to_datetime(\n",
    "        df_monthly['monthly_subscription_retired_date']\n",
    "    )\n",
    "    if 'charge_date' in df_monthly.columns:\n",
    "        df_monthly['charge_date'] = pd.to_datetime(df_monthly['charge_date'])\n",
    "    \n",
    "    # =====================================================================\n",
    "    # ELIGIBILITY FILTERING (if requested)\n",
    "    # =====================================================================\n",
    "    \n",
    "    if E is not None:\n",
    "        eligibility_start = T - pd.DateOffset(months=E)\n",
    "        \n",
    "        # Donors with project donations in eligibility window\n",
    "        active_project_donors = df_dpr[\n",
    "            (df_dpr['payment_date'] >= eligibility_start) &\n",
    "            (df_dpr['payment_date'] < T)\n",
    "        ]['donor_id'].unique()\n",
    "        \n",
    "        # Donors active in monthly program during eligibility window\n",
    "        active_monthly_donors = df_monthly[\n",
    "            (df_monthly['monthly_subscription_joined_date'] < T) &\n",
    "            (df_monthly['monthly_subscription_retired_date'].isna() | \n",
    "             (df_monthly['monthly_subscription_retired_date'] >= eligibility_start))\n",
    "        ]['donor_id'].unique()\n",
    "        \n",
    "        # Union of active donors\n",
    "        base_donor_ids = pd.Index(\n",
    "            pd.unique(\n",
    "                pd.concat([\n",
    "                    pd.Series(active_project_donors),\n",
    "                    pd.Series(active_monthly_donors)\n",
    "                ], ignore_index=True)\n",
    "            ),\n",
    "            name='donor_id'\n",
    "        )        \n",
    "\n",
    "    else:\n",
    "        # Original behavior: all donors from both sources\n",
    "        base_donor_ids = pd.Index(\n",
    "            pd.unique(\n",
    "                pd.concat([\n",
    "                    df_dpr['donor_id'],\n",
    "                    df_monthly['donor_id']\n",
    "                ], ignore_index=True)\n",
    "            ),\n",
    "            name='donor_id'\n",
    "        )\n",
    "    \n",
    "    # Create master feature dataframe\n",
    "    features = pd.DataFrame(index=base_donor_ids)\n",
    "    \n",
    "    # Restrict all event tables to the base donor universe\n",
    "    df_dpr = df_dpr[df_dpr['donor_id'].isin(base_donor_ids)].copy()\n",
    "    df_email = df_email[df_email['donor_id'].isin(base_donor_ids)].copy()\n",
    "    df_site = df_site[df_site['donor_id'].isin(base_donor_ids)].copy()\n",
    "    df_monthly = df_monthly[df_monthly['donor_id'].isin(base_donor_ids)].copy()\n",
    "    df_share = df_share[df_share['donor_id'].isin(base_donor_ids)].copy()\n",
    "\n",
    "    # =====================================================================\n",
    "    # NORMALIZE DATES & FILTER PRE-T\n",
    "    # =====================================================================\n",
    "    \n",
    "    # DPR: main donation records\n",
    "    df_dpr = df_dpr.copy()\n",
    "    df_dpr['payment_date'] = pd.to_datetime(df_dpr['payment_date'])\n",
    "    dpr_pre_T = df_dpr[df_dpr['payment_date'] < T].copy()\n",
    "\n",
    "\n",
    "    # Precompute distances once using direct lat/lon â†’ miles\n",
    "    if {'donor_lat_long', 'school_lat_long'}.issubset(dpr_pre_T.columns):\n",
    "\n",
    "        # Parse lat/long strings into numeric columns\n",
    "        dpr_pre_T['donor_lat_long'] = dpr_pre_T['donor_lat_long'].astype(str)\n",
    "        dpr_pre_T['school_lat_long'] = dpr_pre_T['school_lat_long'].astype(str)\n",
    "\n",
    "        donor_lat_lon = dpr_pre_T['donor_lat_long'].str.split(',', expand=True)\n",
    "        school_lat_lon = dpr_pre_T['school_lat_long'].str.split(',', expand=True)\n",
    "\n",
    "        dpr_pre_T['donor_lat'] = donor_lat_lon[0].astype(float)\n",
    "        dpr_pre_T['donor_lon'] = donor_lat_lon[1].astype(float)\n",
    "        dpr_pre_T['school_lat'] = school_lat_lon[0].astype(float)\n",
    "        dpr_pre_T['school_lon'] = school_lat_lon[1].astype(float)\n",
    "\n",
    "        # Direct haversine distance from donor to project\n",
    "        dpr_pre_T['distance_mi'] = haversine_miles(\n",
    "            dpr_pre_T['donor_lat'],\n",
    "            dpr_pre_T['donor_lon'],\n",
    "            dpr_pre_T['school_lat'],\n",
    "            dpr_pre_T['school_lon'],\n",
    "        )\n",
    "    else:\n",
    "        dpr_pre_T['distance_mi'] = np.nan\n",
    "    \n",
    "    # Site events\n",
    "    df_site = df_site.copy()\n",
    "    df_site['activity_date'] = pd.to_datetime(df_site['activity_date'])\n",
    "    site_pre_T = df_site[df_site['activity_date'] < T].copy()\n",
    "    \n",
    "    # Share events (monthly aggregates)\n",
    "    df_share = df_share.copy()\n",
    "    df_share['share_month_start'] = pd.to_datetime(\n",
    "        df_share['share_sent_month']\n",
    "    ).dt.to_period('M').dt.to_timestamp()\n",
    "    share_pre_T = df_share[df_share['share_month_start'] < T].copy()\n",
    "    \n",
    "    # Email events (monthly aggregates)\n",
    "    df_email = df_email.copy()\n",
    "    df_email['email_month_start'] = pd.to_datetime(\n",
    "        df_email['email_sent_month']\n",
    "    ).dt.to_period('M').dt.to_timestamp()\n",
    "    email_pre_T = df_email[df_email['email_month_start'] < T].copy()\n",
    "    \n",
    "    # Monthly subscriptions\n",
    "    df_monthly = df_monthly.copy()\n",
    "    df_monthly['monthly_subscription_joined_date'] = pd.to_datetime(\n",
    "        df_monthly['monthly_subscription_joined_date']\n",
    "    )\n",
    "    df_monthly['monthly_subscription_retired_date'] = pd.to_datetime(\n",
    "        df_monthly['monthly_subscription_retired_date']\n",
    "    )\n",
    "    if 'charge_date' in df_monthly.columns:\n",
    "        df_monthly['charge_date'] = pd.to_datetime(df_monthly['charge_date'])\n",
    "    \n",
    "    md_pre_T = df_monthly[\n",
    "        df_monthly['monthly_subscription_joined_date'] < T\n",
    "    ].copy()\n",
    "    \n",
    "    # =====================================================================\n",
    "    # WINDOW BOUNDARIES\n",
    "    # =====================================================================\n",
    "    # These define our lookback periods for windowed features\n",
    "    \n",
    "    W_short_start = T - pd.DateOffset(months=3)   # [T-3m, T)\n",
    "    W_mid_start = T - pd.DateOffset(months=12)    # [T-12m, T)\n",
    "    W_long_start = T - pd.DateOffset(months=36)   # [T-36m, T)\n",
    "    \n",
    "    # Create windowed DPR subsets for counts, amounts, velocities\n",
    "    dpr_3m = dpr_pre_T[dpr_pre_T['payment_date'] >= W_short_start]\n",
    "    dpr_12m = dpr_pre_T[dpr_pre_T['payment_date'] >= W_mid_start]\n",
    "    dpr_36m = dpr_pre_T[dpr_pre_T['payment_date'] >= W_long_start]\n",
    "    \n",
    "    # Intermediate periods for velocity calculations\n",
    "    dpr_3to12m = dpr_pre_T[\n",
    "        (dpr_pre_T['payment_date'] >= W_mid_start) &\n",
    "        (dpr_pre_T['payment_date'] < W_short_start)\n",
    "    ]\n",
    "    dpr_12to36m = dpr_pre_T[\n",
    "        (dpr_pre_T['payment_date'] >= W_long_start) &\n",
    "        (dpr_pre_T['payment_date'] < W_mid_start)\n",
    "    ]\n",
    "    \n",
    "    # Email and site windows\n",
    "    email_12m = email_pre_T[email_pre_T['email_month_start'] >= W_mid_start]\n",
    "    email_3m = email_pre_T[email_pre_T['email_month_start'] >= W_short_start]\n",
    "    site_3m = site_pre_T[site_pre_T['activity_date'] >= W_short_start]\n",
    "    share_12m = share_pre_T[share_pre_T['share_month_start'] >= W_mid_start]\n",
    "    \n",
    "    # =====================================================================\n",
    "    # BUILD FEATURE GROUPS\n",
    "    # =====================================================================\n",
    "    # Each join adds a group of related features\n",
    "    # Using left joins to preserve all donor_ids\n",
    "    \n",
    "    # 1. Identity & ZIP / ACS demographics\n",
    "    features = features.join(\n",
    "        _identity_and_zip_features(dpr_pre_T, df_zip_acs, md_pre_T),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 2. Lifetime giving behavior & tenure\n",
    "    features = features.join(\n",
    "        _lifetime_giving_features(dpr_pre_T, T),  # Now includes T\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 3. Windowed giving & velocity trends\n",
    "    features = features.join(\n",
    "        _windowed_giving_features(\n",
    "            dpr_pre_T, dpr_3m, dpr_12m, dpr_36m, dpr_3to12m, dpr_12to36m, T\n",
    "        ),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 4. Channel/payment type mix\n",
    "    features = features.join(\n",
    "        _channel_mix_features(dpr_pre_T, dpr_12m),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 5. Monthly subscription program\n",
    "    features = features.join(\n",
    "        _monthly_features(md_pre_T, dpr_pre_T, dpr_12m, T),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 6. Teacher/school/content preferences\n",
    "    features = features.join(\n",
    "        _teacher_school_features(dpr_pre_T),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 7. Seasonality & rhythm patterns\n",
    "    features = features.join(\n",
    "        _seasonality_features(dpr_pre_T),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 8. Email engagement\n",
    "    features = features.join(\n",
    "        _email_features(email_pre_T, email_3m, email_12m, T),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 9. Site behavior\n",
    "    features = features.join(\n",
    "        _site_features(site_pre_T, site_3m, T),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 10. Share events\n",
    "    features = features.join(\n",
    "        _share_features(share_pre_T, share_12m, T),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 11. Project outcomes & matching\n",
    "    features = features.join(\n",
    "        _project_outcome_features(dpr_pre_T),\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # 12) School/teacher availability\n",
    "    if df_project_dates is not None and not df_project_dates.empty:\n",
    "        horizon = H if H is not None else pd.Timedelta(days=365)\n",
    "        features = features.join(\n",
    "            _future_opportunity_features(dpr_pre_T, df_project_dates, T, horizon),\n",
    "            how='left'\n",
    "        )\n",
    "    else:\n",
    "        features['school_still_available_during_range'] = 0\n",
    "        features['teacher_still_available_during_range'] = 0\n",
    "\n",
    "    # 13) Latest donation\n",
    "    f_latest = _latest_donation_features(\n",
    "        dpr_pre_T=dpr_pre_T,\n",
    "        df_share=df_share,\n",
    "        T=T\n",
    "    )\n",
    "    features = features.join(f_latest, how='left')\n",
    "    \n",
    "    # =====================================================================\n",
    "    # BUILD LABELS\n",
    "    # =====================================================================\n",
    "    \n",
    "    labels = _build_labels(\n",
    "        df_dpr=df_dpr,\n",
    "        df_monthly=df_monthly,\n",
    "        df_share=df_share,\n",
    "        df_email=df_email,\n",
    "        df_site=df_site,\n",
    "        T=T,\n",
    "        donor_index=features.index\n",
    "    )\n",
    "    features = features.join(labels, how=\"left\")\n",
    "    features = _apply_label_imputation(features)\n",
    "\n",
    "    # Drop raw ZIP column\n",
    "    features = features.drop(columns=[\"donor_zip5\"])\n",
    "\n",
    "    # Add donor_id as an explicit column\n",
    "    features = features.copy()\n",
    "    features.insert(0, \"donor_id\", features.index)\n",
    "    features = features.reset_index(drop=True)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Building & Cohort Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load your data\n",
    "# DonorProjectRecords_251118 is for the MLG+Loyal group, all history\n",
    "# DonorProjectRecords_251121 is for all donors' first 3 donations, only from the last 4 years\n",
    "df_dpr = pd.read_csv('/Users/matt.fritz/Desktop/DonorProjectRecords_251118.csv')\n",
    "df_email = pd.read_csv('/Users/matt.fritz/Desktop/Email Events 36mo.csv')\n",
    "df_site = pd.read_csv('/Users/matt.fritz/Desktop/Site Events FY25-26.csv')\n",
    "df_monthly = pd.read_csv('/Users/matt.fritz/Desktop/Monthly Donation Data All Time.csv')\n",
    "df_share = pd.read_csv('/Users/matt.fritz/Desktop/Share Events All Time.csv')\n",
    "df_project_dates = pd.read_csv('/Users/matt.fritz/Desktop/Project Dates FY22-26.csv')\n",
    "df_zip_acs = pd.read_csv('/Users/matt.fritz/Desktop/Merged_Zip_ACS_Demographics.csv')\n",
    "\n",
    "# 2. Define reference time, horizon, and eligibility window\n",
    "E = 12                              # Only donors who gave in E months prior to T are eligible\n",
    "T = pd.Timestamp('2023-07-01')      # Training features end date \n",
    "O = pd.Timedelta(days=365)          # Out-of-time lag to apply to T\n",
    "H = pd.Timedelta(days=365)\n",
    "'''\n",
    "                                    ELIGIBILITY\n",
    "                              T-E | ----------- | T\n",
    "                                  \n",
    "                              TRAINING FEATURES       TRAINING LABEL\n",
    "  | ALL HISTORY ------------------------------- | T | -------------- | T+H\n",
    "                                                      \n",
    "                                                      OOT LAG\n",
    "                                                  T | -- O -- |\n",
    "                                                    \n",
    "                                                 OOT FEATURES           OOT LABEL\n",
    "  | ALL HISTORY --------------------------------------------- | T+O | -------------- | T+O+H\n",
    "'''\n",
    "# 3. Build features\n",
    "train_features = build_features(\n",
    "    df_dpr=df_dpr,\n",
    "    df_email=df_email,\n",
    "    df_site=df_site,\n",
    "    df_monthly=df_monthly,\n",
    "    df_share=df_share,\n",
    "    df_project_dates=df_project_dates,\n",
    "    df_zip_acs=df_zip_acs,\n",
    "    E=E,\n",
    "    T=T,\n",
    "    H=H\n",
    ")\n",
    "oot_features = build_features(\n",
    "    df_dpr=df_dpr,\n",
    "    df_email=df_email,\n",
    "    df_site=df_site,\n",
    "    df_monthly=df_monthly,\n",
    "    df_share=df_share,\n",
    "    df_project_dates=df_project_dates,\n",
    "    df_zip_acs=df_zip_acs,\n",
    "    E=E,\n",
    "    T=T+O,\n",
    "    H=H\n",
    ")\n",
    "\n",
    "train_features.to_csv('/Users/matt.fritz/Desktop/train_features_251124.csv', index=False)\n",
    "oot_features.to_csv('/Users/matt.fritz/Desktop/oot_features_251124.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Inventory\n",
    "\n",
    "## Features (174 total)\n",
    "\n",
    "### Identity & Demographics (21 features)\n",
    "Core donor attributes and ZIP-level demographics from ACS data:\n",
    "- **Identity**: `donor_zip5`, `is_teacher`, `is_teacher_referred`, `is_marketing_subscribed`, `is_major_gift_donor`\n",
    "- **Account**: `ever_used_account_credit`, `current_account_credit_balance`\n",
    "- **Donor type flags**: `has_project_history`, `has_monthly_history`, `is_project_only_donor`, `is_monthly_only_donor`, `is_hybrid_donor`\n",
    "- **ZIP demographics** (9): `zip_log_total_population`, `zip_median_age`, `zip_avg_household_size`, `zip_median_home_value`, `zip_pct_minority`, `zip_pct_households_with_children`, `zip_pct_single_parent`, `zip_pct_in_labor_force`, `zip_unemployment_rate`\n",
    "\n",
    "---\n",
    "\n",
    "### Lifetime Giving Behavior (14 features)\n",
    "Cumulative metrics through time T:\n",
    "- **Time features**: `first_donation_date`, `last_donation_date`, `tenure_days`, `tenure_years`, `tenure_bucket`\n",
    "- **Volume**: `lifetime_gift_count`, `lifetime_amount`, `max_donation_sequence_number`\n",
    "- **Distribution**: `lifetime_median_gift_amount`, `lifetime_max_gift_amount`, `lifetime_cv_gift_amount`\n",
    "- **Timing patterns**: `mean_gap_between_gifts_days_last2yr`, `cv_gap_between_gifts_days_last2yr`\n",
    "- **Early behavior**: `pct_early_gifts_in_lifetime`\n",
    "\n",
    "---\n",
    "\n",
    "### Windowed Giving & Velocity (26 features)\n",
    "Time-windowed aggregations (3m, 12m, 36m) and velocity ratios:\n",
    "- **Counts by window**: `gift_count_3m`, `gift_count_12m`, `gift_count_36m`\n",
    "- **Green/non-green counts**: `gift_count_green_3m/12m/36m`, `gift_count_nongreen_3m/12m/36m`\n",
    "- **Amounts by window**: `gift_amount_3m`, `gift_amount_12m`, `gift_amount_36m`\n",
    "- **Green/non-green amounts**: `gift_amount_green_3m/12m/36m`, `gift_amount_nongreen_3m/12m/36m`\n",
    "- **Medians**: `median_gift_amount_3m`, `median_gift_amount_12m`, `median_gift_amount_36m`\n",
    "- **Recency**: `days_since_last_gift`, `days_since_second_to_last_gift`\n",
    "- **Velocity ratios**: `amount_velocity_0to3_vs_3to12`, `amount_velocity_0to12_vs_12to36`, `count_velocity_0to12_vs_12to36`\n",
    "\n",
    "---\n",
    "\n",
    "### Channel & Payment Type Mix (22 features)\n",
    "Payment channel preferences and special gift types (lifetime and 12m):\n",
    "- **DAF**: `pct_amount_daf_lifetime/12m`, `pct_count_daf_lifetime/12m`\n",
    "- **Green payment**: `pct_amount_green_lifetime/12m`, `pct_count_green_lifetime/12m`\n",
    "- **Gift cards**: `pct_gifts_gift_card_lifetime/12m`, `pct_amount_gift_card_lifetime/12m`\n",
    "- **Big events**: `pct_amount_big_event_lifetime/12m`, `pct_count_big_event_lifetime/12m`\n",
    "- **Optional donations**: `avg_optional_donation_rate_lifetime`, `avg_optional_donation_rate_12m`\n",
    "- **Anonymous**: `pct_gifts_anonymous_lifetime/12m`\n",
    "- **Classroom essentials**: `pct_amount_classroom_essentials_lifetime/12m`\n",
    "\n",
    "---\n",
    "\n",
    "### Monthly Giving Program (10 features)\n",
    "Monthly subscription behavior:\n",
    "- **Status**: `is_monthly_donor_current`\n",
    "- **Volume**: `monthly_lifetime_amount`, `monthly_amount_12m`, `monthly_median_gift_amount`\n",
    "- **Mix**: `pct_amount_monthly_lifetime`, `pct_amount_monthly_12m`\n",
    "- **Tenure**: `months_on_program`, `months_since_last_monthly_charge`, `monthly_longest_streak_months`\n",
    "- **Timing**: `monthly_joined_before_first_project_gift`\n",
    "\n",
    "---\n",
    "\n",
    "### Teacher, School & Content Preferences (20 features)\n",
    "Diversity and concentration in giving targets:\n",
    "- **Entropy**: `entropy_teacher`, `entropy_school`, `entropy_zip`, `entropy_category`, `entropy_grade`\n",
    "- **Unique counts**: `num_unique_teachers`, `num_unique_schools`, `num_unique_school_zips`, `num_unique_categories`, `num_unique_grades`\n",
    "- **Top concentration**: `pct_amount_to_top_teacher`, `pct_amount_to_top_school`, `pct_amount_to_top_category`, `pct_amount_to_top_grade`\n",
    "- **First/last project loyalty**: `pct_gifts_first_project`, `pct_gifts_last_project`, `pct_amount_first_project`, `pct_amount_last_project`\n",
    "- **Teacher quality**: `mean_teacher_lifetime_projects_fully_funded`, `mean_teacher_lifetime_donations`\n",
    "\n",
    "---\n",
    "\n",
    "### Seasonality Features (10 features)\n",
    "Temporal patterns in giving:\n",
    "- **Calendar patterns**: `pct_amount_in_back_to_school`, `pct_amount_in_final_week_of_year`, `pct_amount_on_weekends`\n",
    "- **Month diversity**: `entropy_gift_month`\n",
    "- **Peak periods**: `pct_amount_in_top_month`, `pct_amount_in_top_quarter`\n",
    "- **First gift timing**: `first_donation_month`, `first_donation_quarter`, `first_donation_dow_sin`, `first_donation_dow_cos`\n",
    "\n",
    "---\n",
    "\n",
    "### Email Engagement (12 features)\n",
    "Email behavior and responsiveness (3m and 12m windows):\n",
    "- **Volume**: `emails_sent_3m/12m`, `emails_opened_3m/12m`, `emails_clicked_3m/12m`\n",
    "- **Rates**: `email_open_rate_3m/12m`, `email_click_rate_3m/12m`\n",
    "- **Velocity**: `email_open_rate_velocity_3m_vs_12m`\n",
    "- **Recency**: `days_since_last_email_sent`\n",
    "\n",
    "---\n",
    "\n",
    "### Site Behavior (9 features)\n",
    "Website activity patterns (3m window):\n",
    "- **Activity level**: `days_with_any_site_activity_3m`, `avg_sessions_per_active_day_3m`\n",
    "- **Engagement depth**: `avg_session_duration_min_3m`, `checkout_intent_min_per_session_3m`\n",
    "- **Recency**: `days_since_last_cart_visit`\n",
    "- **Content focus**: `campaign_session_share_3m`, `share_project_page_session_pct_3m`, `share_search_page_session_pct_3m`, `share_teacher_page_session_pct_3m`\n",
    "\n",
    "---\n",
    "\n",
    "### Share Events (4 features)\n",
    "Social sharing behavior:\n",
    "- **Volume**: `share_events_lifetime`, `share_events_12m`\n",
    "- **Consistency**: `share_active_months_12m`, `share_month_coverage_ratio`\n",
    "\n",
    "---\n",
    "\n",
    "### Same School & Teacher Flags (2 features)\n",
    "Availability indicators for longitudinal targeting:\n",
    "- `teacher_still_available_during_range`\n",
    "- `school_still_available_during_range`\n",
    "\n",
    "---\n",
    "\n",
    "### Project Outcomes & Matching (8 features)\n",
    "Project characteristics and outcomes:\n",
    "- **Geography**: `median_donor_to_project_distance_mi`, `pct_gifts_within_15mi`, `is_local_donor`\n",
    "- **Project size**: `mean_project_total_cost`, `median_project_total_cost`\n",
    "- **Outcomes**: `pct_projects_fully_funded`\n",
    "- **Matching**: `mean_match_multiplier`, `pct_gifts_with_match`\n",
    "\n",
    "---\n",
    "\n",
    "### Latest Donation (16 features)\n",
    "Characteristics of most recent gift as of time T:\n",
    "- **Geography**: `latest_distance_mi`\n",
    "- **Amounts**: `latest_gift_amount_green`, `latest_gift_amount_nongreen`\n",
    "- **Project details**: `latest_project_category`, `latest_project_grade`, `latest_project_total_cost`, `latest_project_got_fully_funded`\n",
    "- **Gift characteristics**: `latest_payment_type_is_green`, `latest_is_giftcard_purchase`, `latest_optional_donation_percent`, `latest_match_xyi_multiplier`\n",
    "- **Behavior**: `latest_shared_any`, `latest_referral_channel`\n",
    "- **Project position**: `latest_donation_is_projects_first`, `latest_donation_is_projects_last`\n",
    "- **Teacher quality**: `latest_teacher_lifetime_projects_fully_funded`\n",
    "\n",
    "---\n",
    "\n",
    "## Labels (50 total, if H provided)\n",
    "\n",
    "All labels predict future behavior from time T forward. Horizons are fixed per label (not controlled by H parameter).\n",
    "\n",
    "### Core Giving Propensity (8 labels)\n",
    "Binary and count predictions for general giving behavior:\n",
    "- **Binary propensity**: `label_will_give_next_30d`, `label_will_give_next_90d`, `label_will_give_next_365d`\n",
    "- **Frequency**: `label_num_gifts_next_365d`, `label_will_give_2plus_times_next_365d`\n",
    "- **Green giving**: `label_num_green_gifts_next_365d`\n",
    "- **Time-to-event**: `label_time_to_next_gift_days` (censored at 366 days)\n",
    "- **Special events**: `label_will_make_big_event_gift_next_365d`\n",
    "\n",
    "---\n",
    "\n",
    "### Revenue & Value (8 labels)\n",
    "Dollar amount predictions and revenue growth:\n",
    "- **Revenue by type**: `label_green_revenue_next_365d`, `label_project_revenue_next_365d`, `label_monthly_revenue_next_365d`, `label_grand_revenue_next_365d`\n",
    "- **Large gifts**: `label_max_single_gift_next_365d`\n",
    "- **Growth**: `label_revenue_growth_ratio_next_year` (ratio: future 12m / prior 12m)\n",
    "- **Thresholds**: `label_will_cross_midlevel_threshold_next_12m` (â‰¥$1,000 grand revenue)\n",
    "- **Major gifts**: `label_will_make_major_gift_next_24m` (single gift â‰¥$5,000)\n",
    "\n",
    "---\n",
    "\n",
    "### Monthly Program (6 labels)\n",
    "Monthly subscription lifecycle predictions:\n",
    "- **Acquisition**: `label_will_start_monthly_next_90d`, `label_will_start_monthly_next_365d`\n",
    "- **Churn**: `label_will_churn_monthly_next_6m`\n",
    "- **Changes**: `label_will_upgrade_monthly_next_6m`, `label_will_downgrade_monthly_next_6m`\n",
    "- **Revenue**: `label_monthly_amt_next_6m`\n",
    "\n",
    "---\n",
    "\n",
    "### Midlevel / Major / DAF (5 labels)\n",
    "High-value donor predictions:\n",
    "- **DAF**: `label_daf_revenue_next_365d`, `label_will_make_daf_gift_next_365d`, `label_will_shift_to_daf_heavy_next_12m` (â‰¥50% via DAF)\n",
    "- **Midlevel**: `label_will_be_midlevel_grand_next_12m` (â‰¥$1,000 grand revenue)\n",
    "- **Large single gifts**: `label_will_make_large_single_gift_next_365d` (â‰¥$500)\n",
    "\n",
    "---\n",
    "\n",
    "### Email Engagement (5 labels)\n",
    "Email response predictions:\n",
    "- **Aggregate rates**: `label_email_open_rate_next_90d`, `label_email_click_rate_next_90d`\n",
    "- **Next campaign**: `label_will_open_next_campaign_email`, `label_will_click_next_campaign_email`\n",
    "- **Unsubscribe**: `label_will_unsubscribe_next_90d`\n",
    "\n",
    "---\n",
    "\n",
    "### Site Behavior & Activity (5 labels)\n",
    "Website engagement predictions:\n",
    "- **Visit**: `label_will_visit_site_next_30d`\n",
    "- **Activity level**: `label_num_sessions_next_90d`, `label_project_page_views_next_90d`\n",
    "- **Special behavior**: `label_will_view_local_projects_next_90d`, `label_will_login_next_30d`\n",
    "\n",
    "---\n",
    "\n",
    "### Product & Project Preference (6 labels)\n",
    "Giving target predictions:\n",
    "- **Next gift attributes**: `label_next_gift_category`, `label_next_gift_grade_band` (categorical)\n",
    "- **Geography**: `label_will_give_local_next_365d` (within 25 miles)\n",
    "- **Concentration**: `label_pct_future_dollars_to_top_category_next_365d`\n",
    "- **Teacher/school loyalty**: `label_will_give_to_teacher_previously_supported_next_365d`, `label_will_give_to_new_schools_next_365d`\n",
    "\n",
    "---\n",
    "\n",
    "### Seasonality & Events (4 labels)\n",
    "Temporal giving patterns:\n",
    "- **Seasonal**: `label_will_give_in_back_to_school_season` (Aug-Sep), `label_will_give_during_eoy` (Dec 24-31)\n",
    "- **Event responsive**: `label_will_be_event_responsive_next_12m` (â‰¥2 gifts on defined events)\n",
    "- **Peak period**: `label_quarter_of_max_future_giving_next_12m` (Q1/Q2/Q3/Q4, rolling quarters from T)\n",
    "\n",
    "---\n",
    "\n",
    "### Operational / Mechanism Behavior (3 labels)\n",
    "Gift mechanics and special features:\n",
    "- **Account credit**: `label_will_use_account_credit_next_90d`\n",
    "- **Optional support**: `label_optional_donation_rate_on_next_gift`\n",
    "- **Gift cards**: `label_will_make_gift_card_purchase_next_12m`\n",
    "\n",
    "---\n",
    "\n",
    "## Summary Statistics\n",
    "\n",
    "| Category | Count |\n",
    "|----------|-------|\n",
    "| **Features** | **174** |\n",
    "| Identity & Demographics | 21 |\n",
    "| Lifetime Giving | 14 |\n",
    "| Windowed Giving | 26 |\n",
    "| Channel Mix | 22 |\n",
    "| Monthly Program | 10 |\n",
    "| Teacher/School Preferences | 20 |\n",
    "| Seasonality | 10 |\n",
    "| Email Engagement | 12 |\n",
    "| Site Behavior | 9 |\n",
    "| Share Events | 4 |\n",
    "| Same School/Teacher Flags | 2 |\n",
    "| Project Outcomes | 8 |\n",
    "| Latest Donation | 16 |\n",
    "| **Labels** | **50** |\n",
    "| Core Giving Propensity | 8 |\n",
    "| Revenue & Value | 8 |\n",
    "| Monthly Program | 6 |\n",
    "| Midlevel / DAF | 5 |\n",
    "| Email Engagement | 5 |\n",
    "| Site Behavior | 5 |\n",
    "| Product Preference | 6 |\n",
    "| Seasonality & Events | 4 |\n",
    "| Operational | 3 |\n",
    "| **TOTAL** | **224** |\n",
    "\n",
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "### Time Scopes\n",
    "- **STATIC**: ZIP demographics, some identity flags\n",
    "- **LIFETIME**: Cumulative through T (e.g., `lifetime_amount`, `tenure_days`)\n",
    "- **WINDOWED**: Specific lookbacks (3m, 12m, 36m relative to T)\n",
    "- **LABELS**: Future periods with fixed horizons (30d, 90d, 365d, 24m from T)\n",
    "\n",
    "### Label Imputation Rules\n",
    "Applied by `_apply_label_imputation()`:\n",
    "- **Binary** â†’ 0.0\n",
    "- **Count** â†’ 0.0\n",
    "- **Amount** â†’ 0.0\n",
    "- **Rate** â†’ 0.0\n",
    "- **Ratio** â†’ 1.0 (no change baseline)\n",
    "- **Time-to-event** â†’ 366 (censored)\n",
    "- **Categorical** â†’ \"NONE\"\n",
    "\n",
    "### Label Horizons\n",
    "Unlike the old 4-label implementation, horizons are now **fixed per label**:\n",
    "- 30d: Next-month propensity\n",
    "- 90d: Quarterly targets\n",
    "- 180d (6m): Monthly program changes\n",
    "- 365d: Annual revenue and behavior\n",
    "- 730d (24m): Major gifts\n",
    "\n",
    "The `H` parameter is retained for backward compatibility but does not control label horizons.\n",
    "\n",
    "### Categorical Features\n",
    "Several features have categorical values that may require encoding:\n",
    "- `tenure_bucket` (ordinal: \"0-3m\", \"3m-1y\", \"1y-3y\", \"3y+\")\n",
    "- `latest_project_category`, `latest_project_grade`, `latest_referral_channel` (nominal)\n",
    "- `label_next_gift_category`, `label_next_gift_grade_band`, `label_quarter_of_max_future_giving_next_12m` (nominal)\n",
    "\n",
    "**Encoding impact**: After one-hot encoding categorical features, the final feature space can expand to 200+ columns depending on category cardinality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Notes & Best Practices\n",
    "\n",
    "### Time Scope Summary\n",
    "\n",
    "- **STATIC**: Does not depend on T\n",
    "  - ZIP/ACS features\n",
    "  - Some \"once ever\" flags (is_major_gift_donor, etc.)\n",
    "  - First donation seasonality\n",
    "\n",
    "- **AS_OF_T**: Cumulative through time T\n",
    "  - Lifetime giving metrics\n",
    "  - Distance/locality\n",
    "  - Channel mix (lifetime)\n",
    "  - Teacher/school concentration\n",
    "  - Overall seasonality patterns\n",
    "\n",
    "- **WINDOWED**: Specific lookback relative to T\n",
    "  - 3m/12m/36m counts & amounts\n",
    "  - Velocity metrics\n",
    "  - Email engagement (3m/12m)\n",
    "  - Site behavior (3m)\n",
    "  - Share activity (12m)\n",
    "\n",
    "- **LABEL**: Future horizon [T, T+H)\n",
    "  - Repeat giving targets\n",
    "  - Monthly program changes\n",
    "  - Upgrade/downgrade indicators\n",
    "\n",
    "### Key Design Decisions\n",
    "\n",
    "1. **No duplicate concepts**: Single distance metric, single velocity pattern\n",
    "2. **Consistent windows**: 3m (short), 12m (mid), 36m (long)\n",
    "3. **Defensive epsilon**: Small values (1e-6) prevent division by zero\n",
    "4. **Separation of concerns**: Feature engineering â‰  imputation\n",
    "5. **Time-relative**: All features parameterized by T\n",
    "\n",
    "### Recommended Workflow\n",
    "\n",
    "1. **Build features** for each training example at different T values\n",
    "2. **Finalize features** with consistent imputation strategy\n",
    "3. **Feature selection** based on importance/correlation\n",
    "4. **Model training** with cross-validation\n",
    "5. **Production scoring** with latest T value\n",
    "\n",
    "### Common Pitfalls to Avoid\n",
    "\n",
    "- **Leakage**: Don't use features from [T, T+H) for predictions\n",
    "- **Inconsistent windows**: Always use same T-relative boundaries\n",
    "- **Missing joins**: Ensure all tables have donor_id\n",
    "- **Scale mismatch**: Consider feature scaling for some models\n",
    "- **Category explosion**: Monitor one-hot encoding dimension\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "- For large datasets, consider building features in chunks\n",
    "- Cache intermediate results (windowed subsets)\n",
    "- Use categorical dtypes to save memory\n",
    "- Consider feature hashing for high-cardinality categoricals\n",
    "- Profile your code to identify bottlenecks\n",
    "\n",
    "### Extensions\n",
    "\n",
    "This schema can be extended with:\n",
    "- Interaction features (e.g., tenure Ã— amount)\n",
    "- Polynomial features for non-linear patterns\n",
    "- Embedding features from text (project descriptions)\n",
    "- Time-series features (rolling statistics)\n",
    "- Graph features (donor networks)\n",
    "- External data (economic indicators, events)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
