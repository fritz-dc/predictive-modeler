{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Donor Feature Schema for DonorsChoose\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements a comprehensive, reusable donor feature engineering pipeline that:\n",
    "\n",
    "1. **Re-uses existing feature engineering work** while consolidating near-duplicate concepts\n",
    "2. **Separates features by time scope**:\n",
    "   - `STATIC`: Does not depend on reference time T (or treated as fixed once per donor)\n",
    "   - `AS_OF_T`: Uses cumulative data up to time T\n",
    "   - `WINDOWED`: Uses specific lookback windows relative to T\n",
    "   - `LABEL`: Natural target variables for various use cases\n",
    "\n",
    "3. **Pulls from 5 main data sources**:\n",
    "   - Donor Project Records (gifts/donations)\n",
    "   - Email Events (12-month summary)\n",
    "   - Site Events (FY25-26 activity)\n",
    "   - Monthly Donation Program (all-time)\n",
    "   - Share Events (all-time)\n",
    "   - Plus: ZIP-level ACS demographics\n",
    "\n",
    "## Feature Categories\n",
    "\n",
    "The schema includes approximately 150+ features across these domains:\n",
    "\n",
    "1. **Identity & Demographics** (ZIP-based ACS)\n",
    "2. **Lifetime Giving Behavior** (tenure, amounts, patterns)\n",
    "3. **Windowed Giving** (3m, 12m, 36m activity + velocity)\n",
    "4. **Channel/Payment Mix** (DAF, green, gift cards, etc.)\n",
    "5. **Monthly Program Dynamics** (subscription behavior)\n",
    "6. **Teacher/School/Content Preferences** (loyalty vs diversification)\n",
    "7. **Seasonality** (back-to-school, year-end, etc.)\n",
    "8. **Email Engagement** (opens, clicks, velocity)\n",
    "9. **Site Behavior** (sessions, pages, devices)\n",
    "10. **Share Activity** (social sharing patterns)\n",
    "11. **Project Outcomes** (fully-funded rates, matching)\n",
    "12. **Labels** (optional, for various prediction tasks)\n",
    "\n",
    "## Key Design Principles\n",
    "\n",
    "- **No duplicate concepts**: Single distance metric, single velocity calculation pattern\n",
    "- **Consistent windowing**: 3-month (short), 12-month (mid), 36-month (long)\n",
    "- **Defensive coding**: Small epsilon values prevent division by zero\n",
    "- **Separation of concerns**: Feature building â‰  imputation/encoding\n",
    "- **Time-relative**: All features parameterized by reference time T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyproj import Geod\n",
    "from typing import Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Helper Functions\n",
    "\n",
    "These utility functions support the main feature engineering pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def haversine_miles(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Compute great-circle distance between two points in miles using Haversine formula.\n",
    "    \n",
    "    All arguments can be scalars or pandas Series (for vectorized computation).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lat1, lon1 : float or pd.Series\n",
    "        Latitude and longitude of first point(s) in decimal degrees\n",
    "    lat2, lon2 : float or pd.Series\n",
    "        Latitude and longitude of second point(s) in decimal degrees\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    distance : float or pd.Series\n",
    "        Great-circle distance in miles\n",
    "    \"\"\"\n",
    "    # Earth's radius in miles\n",
    "    R = 3958.8\n",
    "    \n",
    "    # Convert all coordinates from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    # Calculate differences\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    # Haversine formula\n",
    "    a = np.sin(dlat / 2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    \n",
    "    return R * c\n",
    "\n",
    "def entropy_vectorized(df, group_col, cat_col):\n",
    "    \"\"\"\n",
    "    Calculate Shannon entropy in a fully vectorized way.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing the data\n",
    "    group_col : str\n",
    "        Column to group by (e.g., 'donor_id')\n",
    "    cat_col : str\n",
    "        Categorical column to calculate entropy for (e.g., 'teacher_id')\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    entropy : pd.Series\n",
    "        Entropy value for each group, indexed by group_col\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return pd.Series(dtype=float, name='entropy')\n",
    "    \n",
    "    # Count occurrences of each category within each group\n",
    "    counts = df.groupby([group_col, cat_col]).size()\n",
    "    \n",
    "    # Calculate probabilities (normalize within each group)\n",
    "    probs = counts.groupby(level=0).transform(lambda x: x / x.sum())\n",
    "    \n",
    "    # Calculate entropy: -sum(p * log(p)) for each group\n",
    "    entropy = -(probs * np.log(probs + 1e-9)).groupby(level=0).sum()\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "\n",
    "def pct_amount(df, flag_col, amount_col='payment_amount'):\n",
    "    \"\"\"\n",
    "    Calculate the fraction of total donation amount coming from flagged rows.\n",
    "    \n",
    "    Example: If flag_col='daf_payment', returns what % of each donor's\n",
    "    total giving came through DAF donations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Donation records with donor_id column\n",
    "    flag_col : str\n",
    "        Name of binary indicator column (1 = flagged, 0 = not flagged)\n",
    "    amount_col : str, default='payment_amount'\n",
    "        Name of amount column to aggregate\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pct : pd.Series\n",
    "        Fraction of amount from flagged rows, indexed by donor_id\n",
    "    \"\"\"\n",
    "\n",
    "    if df.empty:\n",
    "        return pd.Series(dtype=float)\n",
    "    \n",
    "    # Filter THEN group (vectorized, no lambda)\n",
    "    flagged_df = df[df[flag_col] == 1]\n",
    "    amt_flag = flagged_df.groupby('donor_id')[amount_col].sum()\n",
    "    amt_total = df.groupby('donor_id')[amount_col].sum()\n",
    "    amt_flag = amt_flag.reindex(amt_total.index, fill_value=0)\n",
    "    \n",
    "    # Return fraction (with small epsilon to avoid division by zero)\n",
    "    return amt_flag / (amt_total + 1e-6)\n",
    "\n",
    "\n",
    "def pct_count(df, flag_col):\n",
    "    \"\"\"\n",
    "    Calculate the fraction of total gift count coming from flagged rows.\n",
    "    \n",
    "    Example: If flag_col='gift_card_purchase', returns what % of each donor's\n",
    "    gifts were gift card purchases.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Donation records with donor_id column\n",
    "    flag_col : str\n",
    "        Name of binary indicator column\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pct : pd.Series\n",
    "        Fraction of gifts that are flagged, indexed by donor_id\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return pd.Series(dtype=float)\n",
    "        \n",
    "    # Filter THEN group (vectorized)\n",
    "    flagged_df = df[df[flag_col] == 1]\n",
    "    cnt_flag = flagged_df.groupby('donor_id').size()\n",
    "    cnt_total = df.groupby('donor_id').size()\n",
    "    cnt_flag = cnt_flag.reindex(cnt_total.index, fill_value=0)\n",
    "    \n",
    "    return cnt_flag / (cnt_total + 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Group Functions\n",
    "\n",
    "Each function builds a logical group of related features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Identity & Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _identity_and_zip_features(dpr_pre_T, df_zip_acs, md_pre_T=None):\n",
    "    \"\"\"\n",
    "    Build identity features and ZIP-level demographics.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dpr_pre_T : pd.DataFrame\n",
    "        Donation records before T\n",
    "    df_zip_acs : pd.DataFrame\n",
    "        ZIP-level ACS demographics\n",
    "    md_pre_T : pd.DataFrame, optional\n",
    "        Monthly donation data (for ZIP fallback for monthly-only donors)\n",
    "    \"\"\"\n",
    "    # Create base index from all possible donors\n",
    "    all_donor_ids = dpr_pre_T['donor_id'].unique()\n",
    "    if md_pre_T is not None:\n",
    "        all_donor_ids = pd.Index(\n",
    "            pd.unique(\n",
    "                pd.concat([\n",
    "                    pd.Series(dpr_pre_T['donor_id'].unique()),\n",
    "                    pd.Series(md_pre_T['donor_id'].unique())\n",
    "                ])\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    if dpr_pre_T.empty and (md_pre_T is None or md_pre_T.empty):\n",
    "        return pd.DataFrame(index=pd.Index([], name='donor_id'))\n",
    "\n",
    "    # Get ZIP from PROJECT donations (if available)\n",
    "    if not dpr_pre_T.empty:\n",
    "        donor_zip5_from_dpr = (\n",
    "            dpr_pre_T\n",
    "            .sort_values('payment_date')\n",
    "            .groupby('donor_id')['donor_zip']\n",
    "            .first()\n",
    "        )\n",
    "    else:\n",
    "        donor_zip5_from_dpr = pd.Series(dtype=object, name='donor_zip')\n",
    "    \n",
    "    # Get ZIP from MONTHLY data as fallback\n",
    "    if md_pre_T is not None and not md_pre_T.empty and 'donor_zip' in md_pre_T.columns:\n",
    "        donor_zip5_from_monthly = (\n",
    "            md_pre_T\n",
    "            .sort_values('monthly_subscription_joined_date')\n",
    "            .groupby('donor_id')['donor_zip']\n",
    "            .first()\n",
    "        )\n",
    "        # Combine: use dpr ZIP if available, otherwise monthly ZIP\n",
    "        donor_zip5_raw = donor_zip5_from_dpr.combine_first(donor_zip5_from_monthly)\n",
    "    else:\n",
    "        donor_zip5_raw = donor_zip5_from_dpr\n",
    "\n",
    "    # Binary status flags (from dpr_pre_T)\n",
    "    if not dpr_pre_T.empty:\n",
    "        is_teacher = dpr_pre_T.groupby('donor_id')['is_teacher'].max()\n",
    "        is_teacher_referred = dpr_pre_T.groupby('donor_id')['is_teacher_referred'].max()\n",
    "        is_marketing_subscribed = dpr_pre_T.groupby('donor_id')['subscribed_to_marketing_emails'].max()\n",
    "        is_major_gift_donor = dpr_pre_T.groupby('donor_id')['major_gift_donor'].max()\n",
    "        \n",
    "        # Account credit\n",
    "        ever_used_account_credit = (\n",
    "            dpr_pre_T.groupby('donor_id')['account_credit_balance']\n",
    "            .max()\n",
    "            .gt(0)\n",
    "            .astype(int)\n",
    "        )\n",
    "        current_account_credit_balance = (\n",
    "            dpr_pre_T\n",
    "            .sort_values('payment_date')\n",
    "            .groupby('donor_id')['account_credit_balance']\n",
    "            .last()\n",
    "        )\n",
    "    else:\n",
    "        # Create empty series if no dpr data\n",
    "        is_teacher = pd.Series(dtype=float)\n",
    "        is_teacher_referred = pd.Series(dtype=float)\n",
    "        is_marketing_subscribed = pd.Series(dtype=float)\n",
    "        is_major_gift_donor = pd.Series(dtype=float)\n",
    "        ever_used_account_credit = pd.Series(dtype=int)\n",
    "        current_account_credit_balance = pd.Series(dtype=float)\n",
    "\n",
    "    # --- Donor Type Flags (always create for all donors) ---\n",
    "    # Determine which donors appear in each data source\n",
    "    project_donor_ids = set(dpr_pre_T['donor_id'].unique()) if not dpr_pre_T.empty else set()\n",
    "    monthly_donor_ids = set(md_pre_T['donor_id'].unique()) if md_pre_T is not None and not md_pre_T.empty else set()\n",
    "    \n",
    "    # Create flags for all donors in our universe\n",
    "    has_project_history = pd.Series([d in project_donor_ids for d in all_donor_ids], index=all_donor_ids, dtype=int)\n",
    "    has_monthly_history = pd.Series([d in monthly_donor_ids for d in all_donor_ids], index=all_donor_ids, dtype=int)\n",
    "    \n",
    "    # Composite flags for donor segmentation\n",
    "    is_monthly_only_donor = ((has_monthly_history == 1) & (has_project_history == 0)).astype(int)\n",
    "    is_project_only_donor = ((has_project_history == 1) & (has_monthly_history == 0)).astype(int)\n",
    "    is_hybrid_donor = ((has_project_history == 1) & (has_monthly_history == 1)).astype(int)\n",
    "\n",
    "    # --- ZIP / ACS JOIN (dtype-safe) ------------------------------------\n",
    "    donor_zip5 = pd.to_numeric(donor_zip5_raw, errors=\"coerce\")\n",
    "\n",
    "    df_zip_acs = df_zip_acs.copy()\n",
    "    if 'ZIP5' in df_zip_acs.columns:\n",
    "        df_zip_acs = df_zip_acs.set_index('ZIP5')\n",
    "    df_zip_acs.index = pd.to_numeric(df_zip_acs.index, errors=\"coerce\")\n",
    "\n",
    "    acs = donor_zip5.to_frame('donor_zip5').join(\n",
    "        df_zip_acs,\n",
    "        on='donor_zip5',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Assemble output\n",
    "    out = pd.DataFrame(index=donor_zip5.index)\n",
    "    out['donor_zip5'] = donor_zip5\n",
    "    out['has_project_history'] = has_project_history\n",
    "    out['has_monthly_history'] = has_monthly_history\n",
    "    out['is_monthly_only_donor'] = is_monthly_only_donor\n",
    "    out['is_project_only_donor'] = is_project_only_donor\n",
    "    out['is_hybrid_donor'] = is_hybrid_donor\n",
    "    out['is_teacher'] = is_teacher\n",
    "    out['is_teacher_referred'] = is_teacher_referred\n",
    "    out['is_marketing_subscribed'] = is_marketing_subscribed\n",
    "    out['is_major_gift_donor'] = is_major_gift_donor\n",
    "    out['ever_used_account_credit'] = ever_used_account_credit\n",
    "    out['current_account_credit_balance'] = current_account_credit_balance\n",
    "\n",
    "    # ACS features\n",
    "    out['zip_pct_households_with_children'] = acs['pct_households_with_children']\n",
    "    out['zip_pct_in_labor_force'] = acs['pct_in_labor_force']\n",
    "    out['zip_unemployment_rate'] = acs['unemployment_rate']\n",
    "    out['zip_pct_single_parent'] = acs['pct_single_parent']\n",
    "    out['zip_pct_minority'] = acs['pct_minority']\n",
    "    out['zip_avg_household_size'] = acs['avg_household_size']\n",
    "    out['zip_median_age'] = acs['median_age']\n",
    "    out['zip_median_home_value'] = acs['median_home_value']\n",
    "    \n",
    "    if 'total_population' in acs.columns:\n",
    "        out['zip_log_total_population'] = np.log1p(acs['total_population'])\n",
    "    elif 'log_total_population' in acs.columns:\n",
    "        out['zip_log_total_population'] = acs['log_total_population']\n",
    "    else:\n",
    "        out['zip_log_total_population'] = np.nan\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Lifetime Giving Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _lifetime_giving_features(dpr_pre_T, T):\n",
    "    \"\"\"\n",
    "    Build cumulative giving features using all donations before T.\n",
    "    \n",
    "    CORRECTED VERSION with:\n",
    "    - Tenure relative to T (not last_donation_date)\n",
    "    - Gap calculations only for last 730 days\n",
    "    \n",
    "    Features created:\n",
    "    - first_donation_date, last_donation_date: Temporal boundaries\n",
    "    - tenure_days, tenure_years, tenure_bucket: How long donor has been active (relative to T)\n",
    "    - lifetime_gift_count, lifetime_amount: Total volume\n",
    "    - lifetime_median/max/cv_gift_amount: Distribution of gift sizes\n",
    "    - mean/cv_gap_between_gifts_days: Giving rhythm/consistency (last 730 days only)\n",
    "    - max_donation_sequence_number: How many gifts total\n",
    "    - pct_early_gifts_in_lifetime: Concentration in first 3 gifts\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dpr_pre_T : pd.DataFrame\n",
    "        Donor Project Records filtered to payment_date < T\n",
    "    T : pd.Timestamp\n",
    "        Reference time (end of training period)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id\n",
    "    \"\"\"\n",
    "    if dpr_pre_T.empty:\n",
    "        return pd.DataFrame(index=pd.Index([], name='donor_id'))\n",
    "    \n",
    "    dpr = dpr_pre_T.copy()\n",
    "    dpr = dpr.sort_values(['donor_id', 'payment_date'])\n",
    "    \n",
    "    # --- Temporal boundaries ---\n",
    "    first_donation_date = dpr.groupby('donor_id')['payment_date'].min()\n",
    "    last_donation_date = dpr.groupby('donor_id')['payment_date'].max()\n",
    "    \n",
    "    # CORRECTED: Tenure relative to T (end of training period), not last donation\n",
    "    tenure_days = (T - first_donation_date).dt.days\n",
    "    tenure_years = tenure_days / 365.25\n",
    "    \n",
    "    # Bucket tenure for non-linear patterns (categorical)\n",
    "    tenure_bucket_cat = pd.cut(\n",
    "        tenure_years,\n",
    "        bins=[0, 1, 3, 5, 100],\n",
    "        labels=['<1y', '1-3y', '3-5y', '5y+'],\n",
    "        right=False\n",
    "    )\n",
    "    \n",
    "    # Map bucket to lower-bound in YEARS as float64\n",
    "    tenure_bucket = tenure_bucket_cat.map({\n",
    "        '<1y': 0.0,\n",
    "        '1-3y': 1.0,\n",
    "        '3-5y': 3.0,\n",
    "        '5y+': 5.0,\n",
    "    }).astype(float)\n",
    "    \n",
    "    # --- Volume metrics ---\n",
    "    lifetime_gift_count = dpr.groupby('donor_id')['payment_amount'].size()\n",
    "    lifetime_amount = dpr.groupby('donor_id')['payment_amount'].sum()\n",
    "    \n",
    "    # --- Distribution of gift sizes ---\n",
    "    gifts_by_donor = dpr.groupby('donor_id')['payment_amount']\n",
    "    med = gifts_by_donor.median()\n",
    "    mx = gifts_by_donor.max()\n",
    "    mean = gifts_by_donor.mean()\n",
    "    std = gifts_by_donor.std()\n",
    "    # Coefficient of variation: std/mean\n",
    "    # High CV = erratic giving amounts, Low CV = consistent amounts\n",
    "    cv = std / (mean + 1e-9)\n",
    "    \n",
    "    # --- Inter-gift timing patterns (LAST 730 DAYS ONLY) ---\n",
    "    # CORRECTED: Only use donations in last 730 days for gap calculations\n",
    "    cutoff_730 = T - pd.Timedelta(days=730)\n",
    "    dpr_730 = dpr[dpr['payment_date'] >= cutoff_730].copy()\n",
    "    \n",
    "    if not dpr_730.empty:\n",
    "        # Calculate days between consecutive gifts\n",
    "        dpr_730['prev_payment_date'] = dpr_730.groupby('donor_id')['payment_date'].shift(1)\n",
    "        dpr_730['gap_days'] = (dpr_730['payment_date'] - dpr_730['prev_payment_date']).dt.days\n",
    "        \n",
    "        gap_by_donor = dpr_730.groupby('donor_id')['gap_days']\n",
    "        gap_mean = gap_by_donor.mean()\n",
    "        gap_std = gap_by_donor.std()\n",
    "        # CV of gaps: High = irregular giving, Low = regular/predictable\n",
    "        cv_gap = gap_std / (gap_mean + 1e-9)\n",
    "    else:\n",
    "        # No donations in last 730 days\n",
    "        gap_mean = pd.Series(dtype=float)\n",
    "        cv_gap = pd.Series(dtype=float)\n",
    "    \n",
    "    # --- Gift sequence metrics ---\n",
    "    # donation_n = sequential gift number for this donor\n",
    "    max_donation_sequence_number = dpr.groupby('donor_id')['donation_n'].max()\n",
    "    \n",
    "    # What fraction of gifts were in the \"early stage\" (first 3 gifts)?\n",
    "    # High concentration here might indicate acquisition success but poor retention\n",
    "    dpr['is_early_gift'] = dpr['donation_n'] <= 3\n",
    "    pct_early_gifts = dpr.groupby('donor_id')['is_early_gift'].mean()\n",
    "    \n",
    "    # --- Assemble output ---\n",
    "    out = pd.DataFrame(index=lifetime_amount.index)\n",
    "    \n",
    "    out['first_donation_date'] = first_donation_date\n",
    "    out['last_donation_date'] = last_donation_date\n",
    "    out['tenure_days'] = tenure_days\n",
    "    out['tenure_years'] = tenure_years\n",
    "    out['tenure_bucket'] = tenure_bucket\n",
    "    \n",
    "    out['lifetime_gift_count'] = lifetime_gift_count\n",
    "    out['lifetime_amount'] = lifetime_amount\n",
    "    out['lifetime_median_gift_amount'] = med\n",
    "    out['lifetime_max_gift_amount'] = mx\n",
    "    out['lifetime_cv_gift_amount'] = cv\n",
    "    \n",
    "    out['mean_gap_between_gifts_days_last2yr'] = gap_mean\n",
    "    out['cv_gap_between_gifts_days_last2yr'] = cv_gap\n",
    "    \n",
    "    out['max_donation_sequence_number'] = max_donation_sequence_number\n",
    "    out['pct_early_gifts_in_lifetime'] = pct_early_gifts\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Windowed Giving & Velocity\n",
    "\n",
    "These features capture recent activity and trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _windowed_giving_features(dpr_pre_T, dpr_3m, dpr_12m, dpr_36m, dpr_3to12m, dpr_12to36m, T):\n",
    "    \"\"\"\n",
    "    Build windowed giving features and velocity metrics.\n",
    "    \n",
    "    Features created:\n",
    "    - gift_count/amount/median_amount for 3m, 12m, 36m windows\n",
    "    - days_since_last_gift, days_since_second_to_last_gift: Recency\n",
    "    - amount_velocity_0to3_vs_3to12: Is giving accelerating or decelerating?\n",
    "    - amount_velocity_0to12_vs_12to36: Longer-term trend\n",
    "    - count_velocity_0to12_vs_12to36: Frequency trend\n",
    "    \n",
    "    Velocity > 1 indicates acceleration (more recent activity)\n",
    "    Velocity < 1 indicates deceleration (declining activity)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dpr_pre_T : pd.DataFrame\n",
    "        All donations before T\n",
    "    dpr_3m, dpr_12m, dpr_36m : pd.DataFrame\n",
    "        Donations in respective windows\n",
    "    dpr_3to12m, dpr_12to36m : pd.DataFrame\n",
    "        Intermediate periods for velocity calculations\n",
    "    T : pd.Timestamp\n",
    "        Reference time\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id\n",
    "    \"\"\"\n",
    "    out_index = dpr_pre_T['donor_id'].unique()\n",
    "    out = pd.DataFrame(index=out_index)\n",
    "    \n",
    "    # --- 3-month window (recent/short-term) ---\n",
    "    if not dpr_3m.empty:\n",
    "        by_3m = dpr_3m.groupby('donor_id')['payment_amount']\n",
    "        out['gift_count_3m'] = by_3m.size()\n",
    "        out['gift_amount_3m'] = by_3m.sum()\n",
    "        out['median_gift_amount_3m'] = by_3m.median()\n",
    "\n",
    "        # Split by green vs non-green payments\n",
    "        if 'is_green_payment' in dpr_3m.columns:\n",
    "            # Handle 't'/'f' as well as 1/0/True/False\n",
    "            green_mask_3m = dpr_3m['is_green_payment'].isin(['t', 'T', True, 1])\n",
    "            nongreen_mask_3m = dpr_3m['is_green_payment'].isin(['f', 'F', False, 0])\n",
    "\n",
    "            dpr_3m_green = dpr_3m[green_mask_3m]\n",
    "            dpr_3m_nongreen = dpr_3m[nongreen_mask_3m]\n",
    "\n",
    "            by_3m_green = dpr_3m_green.groupby('donor_id')['payment_amount']\n",
    "            by_3m_nongreen = dpr_3m_nongreen.groupby('donor_id')['payment_amount']\n",
    "\n",
    "            out['gift_count_green_3m'] = by_3m_green.size()\n",
    "            out['gift_amount_green_3m'] = by_3m_green.sum()\n",
    "            out['gift_count_nongreen_3m'] = by_3m_nongreen.size()\n",
    "            out['gift_amount_nongreen_3m'] = by_3m_nongreen.sum()\n",
    "    \n",
    "    # --- 12-month window (mid-term) ---\n",
    "    if not dpr_12m.empty:\n",
    "        by_12m = dpr_12m.groupby('donor_id')['payment_amount']\n",
    "        out['gift_count_12m'] = by_12m.size()\n",
    "        out['gift_amount_12m'] = by_12m.sum()\n",
    "        out['median_gift_amount_12m'] = by_12m.median()\n",
    "\n",
    "        if 'is_green_payment' in dpr_12m.columns:\n",
    "            green_mask_12m = dpr_12m['is_green_payment'].isin(['t', 'T', True, 1])\n",
    "            nongreen_mask_12m = dpr_12m['is_green_payment'].isin(['f', 'F', False, 0])\n",
    "\n",
    "            dpr_12m_green = dpr_12m[green_mask_12m]\n",
    "            dpr_12m_nongreen = dpr_12m[nongreen_mask_12m]\n",
    "\n",
    "            by_12m_green = dpr_12m_green.groupby('donor_id')['payment_amount']\n",
    "            by_12m_nongreen = dpr_12m_nongreen.groupby('donor_id')['payment_amount']\n",
    "\n",
    "            out['gift_count_green_12m'] = by_12m_green.size()\n",
    "            out['gift_amount_green_12m'] = by_12m_green.sum()\n",
    "            out['gift_count_nongreen_12m'] = by_12m_nongreen.size()\n",
    "            out['gift_amount_nongreen_12m'] = by_12m_nongreen.sum()\n",
    "    \n",
    "    # --- 36-month window (long-term) ---\n",
    "    if not dpr_36m.empty:\n",
    "        by_36m = dpr_36m.groupby('donor_id')['payment_amount']\n",
    "        out['gift_count_36m'] = by_36m.size()\n",
    "        out['gift_amount_36m'] = by_36m.sum()\n",
    "        out['median_gift_amount_36m'] = by_36m.median()\n",
    "\n",
    "        if 'is_green_payment' in dpr_36m.columns:\n",
    "            green_mask_36m = dpr_36m['is_green_payment'].isin(['t', 'T', True, 1])\n",
    "            nongreen_mask_36m = dpr_36m['is_green_payment'].isin(['f', 'F', False, 0])\n",
    "\n",
    "            dpr_36m_green = dpr_36m[green_mask_36m]\n",
    "            dpr_36m_nongreen = dpr_36m[nongreen_mask_36m]\n",
    "\n",
    "            by_36m_green = dpr_36m_green.groupby('donor_id')['payment_amount']\n",
    "            by_36m_nongreen = dpr_36m_nongreen.groupby('donor_id')['payment_amount']\n",
    "\n",
    "            out['gift_count_green_36m'] = by_36m_green.size()\n",
    "            out['gift_amount_green_36m'] = by_36m_green.sum()\n",
    "            out['gift_count_nongreen_36m'] = by_36m_nongreen.size()\n",
    "            out['gift_amount_nongreen_36m'] = by_36m_nongreen.sum()\n",
    "    \n",
    "    # --- Recency: days since last activity ---\n",
    "    last_gift_date = dpr_pre_T.groupby('donor_id')['payment_date'].max()\n",
    "    out['days_since_last_gift'] = (T - last_gift_date).dt.days\n",
    "    \n",
    "    # Second-to-last gift: helps detect if donor is becoming less frequent\n",
    "    # Sort by payment_date descending and use groupby.nth(1)\n",
    "    second_last = (\n",
    "        dpr_pre_T\n",
    "        .sort_values(['donor_id', 'payment_date'], ascending=[True, False])\n",
    "        .groupby('donor_id')['payment_date']\n",
    "        .nth(1)  # second row per donor, or NaT if fewer than 2\n",
    "    )\n",
    "    \n",
    "    out['days_since_second_to_last_gift'] = (T - second_last).dt.days\n",
    "    \n",
    "    # --- Velocity metrics: are donations accelerating or decelerating? ---\n",
    "    \n",
    "    # Recent 3m vs prior 9m (months 3-12)\n",
    "    amt_0_3 = out.get('gift_amount_3m', pd.Series(0, index=out.index))\n",
    "    amt_3_12 = (\n",
    "        dpr_3to12m.groupby('donor_id')['payment_amount'].sum()\n",
    "        if not dpr_3to12m.empty\n",
    "        else pd.Series(0, index=out.index)\n",
    "    )\n",
    "    # Ratio > 1 means recent giving exceeds prior period\n",
    "    out['amount_velocity_0to3_vs_3to12'] = amt_0_3 / (amt_3_12 + 1e-6)\n",
    "    \n",
    "    # Recent 12m vs prior 24m (months 12-36)\n",
    "    amt_0_12 = out.get('gift_amount_12m', pd.Series(0, index=out.index))\n",
    "    amt_12_36 = (\n",
    "        dpr_12to36m.groupby('donor_id')['payment_amount'].sum()\n",
    "        if not dpr_12to36m.empty\n",
    "        else pd.Series(0, index=out.index)\n",
    "    )\n",
    "    out['amount_velocity_0to12_vs_12to36'] = amt_0_12 / (amt_12_36 + 1e-6)\n",
    "    \n",
    "    # Gift frequency velocity (count-based)\n",
    "    cnt_0_12 = out.get('gift_count_12m', pd.Series(0, index=out.index))\n",
    "    cnt_12_36 = (\n",
    "        dpr_12to36m.groupby('donor_id')['payment_amount'].size()\n",
    "        if not dpr_12to36m.empty\n",
    "        else pd.Series(0, index=out.index)\n",
    "    )\n",
    "    out['count_velocity_0to12_vs_12to36'] = cnt_0_12 / (cnt_12_36 + 1e-6)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Channel & Payment Type Mix\n",
    "\n",
    "How donors give: DAF, green payments, gift cards, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _channel_mix_features(dpr_pre_T, dpr_12m):\n",
    "    \"\"\"\n",
    "    Build features describing how donors give (payment methods, channels).\n",
    "    \n",
    "    For each channel, we compute both lifetime and 12-month versions:\n",
    "    - pct_amount_*: What fraction of $ came through this channel?\n",
    "    - pct_count_*: What fraction of gifts came through this channel?\n",
    "    \n",
    "    Channels covered:\n",
    "    - DAF (Donor Advised Fund) payments\n",
    "    - Green payments (environmental offset donations)\n",
    "    - Gift card purchases\n",
    "    - Big event donations (e.g., giving days)\n",
    "    - Optional donation behavior\n",
    "    - Anonymous gifts\n",
    "    - Classroom essentials projects\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dpr_pre_T : pd.DataFrame\n",
    "        All donations before T (for lifetime metrics)\n",
    "    dpr_12m : pd.DataFrame\n",
    "        Donations in last 12 months (for recent behavior)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id\n",
    "    \"\"\"\n",
    "    out_index = dpr_pre_T['donor_id'].unique()\n",
    "    out = pd.DataFrame(index=out_index)\n",
    "    \n",
    "    # --- DAF donations ---\n",
    "    # DAF = Donor Advised Fund, typically indicates sophisticated/high-capacity donors\n",
    "    out['pct_amount_daf_lifetime'] = pct_amount(dpr_pre_T, 'daf_payment')\n",
    "    out['pct_count_daf_lifetime'] = pct_count(dpr_pre_T, 'daf_payment')\n",
    "    out['pct_amount_daf_12m'] = pct_amount(dpr_12m, 'daf_payment')\n",
    "    out['pct_count_daf_12m'] = pct_count(dpr_12m, 'daf_payment')\n",
    "    \n",
    "    # --- Green payments ---\n",
    "    # Optional environmental offset donations\n",
    "    if 'green_payment_amount' in dpr_pre_T.columns:\n",
    "        by_life = dpr_pre_T.groupby('donor_id')\n",
    "        by_12 = dpr_12m.groupby('donor_id')\n",
    "        \n",
    "        out['pct_amount_green_lifetime'] = (\n",
    "            by_life['green_payment_amount'].sum()\n",
    "            / (by_life['payment_amount'].sum() + 1e-6)\n",
    "        )\n",
    "        out['pct_amount_green_12m'] = (\n",
    "            by_12['green_payment_amount'].sum()\n",
    "            / (by_12['payment_amount'].sum() + 1e-6)\n",
    "        )\n",
    "        out['pct_count_green_lifetime'] = pct_count(dpr_pre_T, 'is_green_payment')\n",
    "        out['pct_count_green_12m'] = pct_count(dpr_12m, 'is_green_payment')\n",
    "    \n",
    "    # --- Gift card purchases ---\n",
    "    # Donors buying gift cards to give to others\n",
    "    out['pct_gifts_gift_card_lifetime'] = pct_count(dpr_pre_T, 'gift_card_purchase')\n",
    "    out['pct_amount_gift_card_lifetime'] = pct_amount(dpr_pre_T, 'gift_card_purchase')\n",
    "    out['pct_gifts_gift_card_12m'] = pct_count(dpr_12m, 'gift_card_purchase')\n",
    "    out['pct_amount_gift_card_12m'] = pct_amount(dpr_12m, 'gift_card_purchase')\n",
    "    \n",
    "    # --- Big event donations ---\n",
    "    # Giving days, campaigns, etc.\n",
    "    out['pct_amount_big_event_lifetime'] = pct_amount(dpr_pre_T, 'payment_on_big_event')\n",
    "    out['pct_count_big_event_lifetime'] = pct_count(dpr_pre_T, 'payment_on_big_event')\n",
    "    out['pct_amount_big_event_12m'] = pct_amount(dpr_12m, 'payment_on_big_event')\n",
    "    out['pct_count_big_event_12m'] = pct_count(dpr_12m, 'payment_on_big_event')\n",
    "    \n",
    "    # --- Optional donation rate ---\n",
    "    # When donors can add optional amounts (e.g., to cover fees)\n",
    "    out['avg_optional_donation_rate_lifetime'] = (\n",
    "        dpr_pre_T.groupby('donor_id')['optional_donation_rate'].mean()\n",
    "    )\n",
    "    out['avg_optional_donation_rate_12m'] = (\n",
    "        dpr_12m.groupby('donor_id')['optional_donation_rate'].mean()\n",
    "    )\n",
    "    \n",
    "    # --- Anonymous donations ---\n",
    "    # Privacy-conscious or humble donors\n",
    "    out['pct_gifts_anonymous_lifetime'] = pct_count(dpr_pre_T, 'donation_is_anonymous')\n",
    "    out['pct_gifts_anonymous_12m'] = pct_count(dpr_12m, 'donation_is_anonymous')\n",
    "    \n",
    "    # --- Classroom essentials ---\n",
    "    # Donations to specific project type (basic supplies)\n",
    "    out['pct_amount_classroom_essentials_lifetime'] = pct_amount(\n",
    "        dpr_pre_T, 'is_classroom_essentials_list'\n",
    "    )\n",
    "    out['pct_amount_classroom_essentials_12m'] = pct_amount(\n",
    "        dpr_12m, 'is_classroom_essentials_list'\n",
    "    )\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Monthly Giving Program\n",
    "\n",
    "Subscription/recurring donation features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _monthly_features(md_pre_T, dpr_pre_T, dpr_12m, T):\n",
    "    \"\"\"\n",
    "    Build monthly subscription program features.\n",
    "    \n",
    "    Features created:\n",
    "    - is_monthly_donor_current: Currently subscribed?\n",
    "    - monthly_lifetime_amount, monthly_amount_12m: How much via subscription\n",
    "    - monthly_median_gift_amount: Typical subscription size\n",
    "    - pct_amount_monthly_*: What fraction of total giving is subscription\n",
    "    - months_on_program, months_since_last_monthly_charge: Tenure metrics\n",
    "    - monthly_longest_streak_months: Longest uninterrupted run\n",
    "    - monthly_joined_before_first_project_gift: Acquisition source indicator\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    md_pre_T : pd.DataFrame\n",
    "        Monthly subscription records where join date < T\n",
    "    dpr_pre_T : pd.DataFrame\n",
    "        All donations before T (for computing fractions)\n",
    "    dpr_12m : pd.DataFrame\n",
    "        Donations in last 12 months\n",
    "    T : pd.Timestamp\n",
    "        Reference time\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id\n",
    "    \"\"\"\n",
    "    if md_pre_T.empty:\n",
    "        return pd.DataFrame(index=dpr_pre_T['donor_id'].unique())\n",
    "    \n",
    "    out_index = pd.Index(md_pre_T['donor_id'].unique(), name='donor_id')\n",
    "    out = pd.DataFrame(index=out_index)\n",
    "    \n",
    "    # --- Current subscription status ---\n",
    "    def is_active(row):\n",
    "        \"\"\"Check if subscription is active at time T\"\"\"\n",
    "        retired = row['monthly_subscription_retired_date']\n",
    "        return (\n",
    "            (row['monthly_subscription_joined_date'] <= T) and\n",
    "            (pd.isna(retired) or (retired > T))\n",
    "        )\n",
    "    \n",
    "    # Vectorized boolean operations (processes all rows at once)\n",
    "    md_pre_T['is_active'] = (\n",
    "        (md_pre_T['monthly_subscription_joined_date'] <= T) &\n",
    "        (md_pre_T['monthly_subscription_retired_date'].isna() | \n",
    "         (md_pre_T['monthly_subscription_retired_date'] > T))\n",
    "    )\n",
    "    \n",
    "    out['is_monthly_donor_current'] = md_pre_T.groupby('donor_id')['is_active'].max().astype(float)\n",
    "    \n",
    "    # --- Lifetime monthly amounts ---\n",
    "    by_life = md_pre_T.groupby('donor_id')\n",
    "    out['monthly_lifetime_amount'] = by_life['monthly_subscription_payment_amount'].sum()\n",
    "    out['monthly_median_gift_amount'] = by_life['monthly_subscription_payment_amount'].median()\n",
    "    \n",
    "    # --- 12-month window ---\n",
    "    if 'charge_date' in md_pre_T.columns:\n",
    "        md_12m = md_pre_T[\n",
    "            (md_pre_T['charge_date'] >= T - pd.DateOffset(months=12)) &\n",
    "            (md_pre_T['charge_date'] < T)\n",
    "        ]\n",
    "        out['monthly_amount_12m'] = (\n",
    "            md_12m.groupby('donor_id')['monthly_subscription_payment_amount'].sum()\n",
    "        )\n",
    "    \n",
    "    # --- Fraction of total giving that's monthly ---\n",
    "    # This shows how dependent a donor is on subscription vs one-time gifts\n",
    "    total_life = dpr_pre_T.groupby('donor_id')['payment_amount'].sum()\n",
    "    total_12 = dpr_12m.groupby('donor_id')['payment_amount'].sum()\n",
    "    \n",
    "    out['pct_amount_monthly_lifetime'] = (\n",
    "        out['monthly_lifetime_amount'] / (total_life + 1e-6)\n",
    "    )\n",
    "    out['pct_amount_monthly_12m'] = (\n",
    "        out.get('monthly_amount_12m', 0) / (total_12 + 1e-6)\n",
    "    )\n",
    "    \n",
    "    # --- Months on program ---\n",
    "    # How long has donor been (or was) subscribed?\n",
    "    def months_on_program_fn(x):\n",
    "        join = x['monthly_subscription_joined_date'].min()\n",
    "        retire = x['monthly_subscription_retired_date'].dropna().min()\n",
    "        # If still active, use T; otherwise use retirement date\n",
    "        end = min(T, retire) if pd.notna(retire) else T\n",
    "        return (end.to_period('M') - join.to_period('M')).n\n",
    "    \n",
    "    # Vectorized date operations\n",
    "    join_dates = md_pre_T.groupby('donor_id')['monthly_subscription_joined_date'].min()\n",
    "    retire_dates = md_pre_T.groupby('donor_id')['monthly_subscription_retired_date'].min()\n",
    "    end_dates = retire_dates.fillna(T).clip(upper=T)\n",
    "    out['months_on_program'] = (end_dates.dt.to_period('M') - join_dates.dt.to_period('M')).apply(lambda x: x.n)\n",
    "\n",
    "    # --- Recency of last charge ---\n",
    "    if 'charge_date' in md_pre_T.columns:\n",
    "        last_charge = md_pre_T.groupby('donor_id')['charge_date'].max()\n",
    "        out['months_since_last_monthly_charge'] = (\n",
    "            (T.to_period('M') - last_charge.dt.to_period('M')).astype('int')\n",
    "        )\n",
    "    \n",
    "    # --- Longest streak ---\n",
    "    # Maximum consecutive months of successful charges\n",
    "    out['monthly_longest_streak_months'] = (\n",
    "        md_pre_T.groupby('donor_id')['monthly_subscription_longest_streak'].max()\n",
    "    )\n",
    "    \n",
    "    # --- Acquisition indicator ---\n",
    "    # Did donor join monthly program BEFORE making first project donation?\n",
    "    first_monthly_join = (\n",
    "        md_pre_T.groupby('donor_id')['monthly_subscription_joined_date'].min()\n",
    "    )\n",
    "    first_donation_date = (\n",
    "        dpr_pre_T.groupby('donor_id')['payment_date'].min()\n",
    "    )\n",
    "\n",
    "    # Align on union of donor_ids\n",
    "    idx_union = first_monthly_join.index.union(first_donation_date.index)\n",
    "    fmj = first_monthly_join.reindex(idx_union)\n",
    "    fdd = first_donation_date.reindex(idx_union)\n",
    "\n",
    "    joined_before = (fmj < fdd)\n",
    "    joined_before = joined_before.fillna(False).astype(int)\n",
    "\n",
    "    out['monthly_joined_before_first_project_gift'] = (\n",
    "        joined_before.reindex(out.index).fillna(0).astype(int)\n",
    "    )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Teacher, School & Content Preferences\n",
    "\n",
    "Loyalty vs diversification patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _teacher_school_features(dpr_pre_T):\n",
    "    \"\"\"\n",
    "    Build features describing donor loyalty vs diversification patterns.\n",
    "    \n",
    "    CORRECTED VERSION with:\n",
    "    - Entropy features set to null/NaN if only one donation\n",
    "    - New features for pct amount to first/last project gifts\n",
    "    \n",
    "    Features measure:\n",
    "    - Concentration: How focused is giving on specific teachers/schools/categories?\n",
    "    - Diversification: How many different entities has donor supported?\n",
    "    - Entropy: Information-theoretic measure of spread\n",
    "    - Teacher quality: Average metrics of teachers supported\n",
    "    - Project position: First/last gift preferences\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dpr_pre_T : pd.DataFrame\n",
    "        Donor Project Records filtered to payment_date < T\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id\n",
    "    \"\"\"\n",
    "    if dpr_pre_T.empty:\n",
    "        return pd.DataFrame(index=pd.Index([], name='donor_id'))\n",
    "    \n",
    "    dpr = dpr_pre_T.copy()\n",
    "    out_index = dpr['donor_id'].unique()\n",
    "    out = pd.DataFrame(index=out_index)\n",
    "    \n",
    "    # --- Count unique entities ---\n",
    "    out['num_unique_teachers'] = dpr.groupby('donor_id')['teacher_id'].nunique()\n",
    "    out['num_unique_schools'] = dpr.groupby('donor_id')['school_id'].nunique()\n",
    "    out['num_unique_categories'] = dpr.groupby('donor_id')['project_category'].nunique()\n",
    "    out['num_unique_grades'] = dpr.groupby('donor_id')['project_grade'].nunique()\n",
    "    \n",
    "    # School ZIP diversity (if available)\n",
    "    if 'school_zip' in dpr.columns:\n",
    "        out['num_unique_school_zips'] = dpr.groupby('donor_id')['school_zip'].nunique()\n",
    "    \n",
    "    # --- Entropy (diversity) measures ---\n",
    "    # CORRECTED: Set to NaN if donor only has one donation\n",
    "    \n",
    "    # Get gift count per donor\n",
    "    gift_counts = dpr.groupby('donor_id').size()\n",
    "    single_gift_donors = gift_counts[gift_counts == 1].index\n",
    "    \n",
    "    # Calculate entropy for each dimension\n",
    "    entropy_teacher = entropy_vectorized(dpr, 'donor_id', 'teacher_id')\n",
    "    entropy_school = entropy_vectorized(dpr, 'donor_id', 'school_id')\n",
    "    entropy_category = entropy_vectorized(dpr, 'donor_id', 'project_category')\n",
    "    entropy_grade = entropy_vectorized(dpr, 'donor_id', 'project_grade')\n",
    "    \n",
    "    # Set to NaN for single-gift donors\n",
    "    out['entropy_teacher'] = entropy_teacher\n",
    "    out.loc[single_gift_donors, 'entropy_teacher'] = np.nan\n",
    "    \n",
    "    out['entropy_school'] = entropy_school\n",
    "    out.loc[single_gift_donors, 'entropy_school'] = np.nan\n",
    "    \n",
    "    out['entropy_category'] = entropy_category\n",
    "    out.loc[single_gift_donors, 'entropy_category'] = np.nan\n",
    "    \n",
    "    out['entropy_grade'] = entropy_grade\n",
    "    out.loc[single_gift_donors, 'entropy_grade'] = np.nan\n",
    "    \n",
    "    if 'school_zip' in dpr.columns:\n",
    "        entropy_zip = entropy_vectorized(dpr, 'donor_id', 'school_zip')\n",
    "        out['entropy_zip'] = entropy_zip\n",
    "        out.loc[single_gift_donors, 'entropy_zip'] = np.nan\n",
    "    \n",
    "    # --- Concentration metrics: % of $ going to top entity ---\n",
    "    \n",
    "    # Top teacher\n",
    "    teacher_amounts = dpr.groupby(['donor_id', 'teacher_id'])['payment_amount'].sum()\n",
    "    top_teacher_amt = teacher_amounts.groupby('donor_id').max()\n",
    "    total_amt = dpr.groupby('donor_id')['payment_amount'].sum()\n",
    "    out['pct_amount_to_top_teacher'] = top_teacher_amt / (total_amt + 1e-9)\n",
    "    \n",
    "    # Top school\n",
    "    school_amounts = dpr.groupby(['donor_id', 'school_id'])['payment_amount'].sum()\n",
    "    top_school_amt = school_amounts.groupby('donor_id').max()\n",
    "    out['pct_amount_to_top_school'] = top_school_amt / (total_amt + 1e-9)\n",
    "    \n",
    "    # Top category\n",
    "    category_amounts = dpr.groupby(['donor_id', 'project_category'])['payment_amount'].sum()\n",
    "    top_category_amt = category_amounts.groupby('donor_id').max()\n",
    "    out['pct_amount_to_top_category'] = top_category_amt / (total_amt + 1e-9)\n",
    "    \n",
    "    # Top grade level\n",
    "    grade_amounts = dpr.groupby(['donor_id', 'project_grade'])['payment_amount'].sum()\n",
    "    top_grade_amt = grade_amounts.groupby('donor_id').max()\n",
    "    out['pct_amount_to_top_grade'] = top_grade_amt / (total_amt + 1e-9)\n",
    "    \n",
    "    # --- Teacher quality metrics ---\n",
    "    # Average lifetime projects fully funded by teachers this donor supports\n",
    "    if 'teacher_lifetime_projects_fully_funded' in dpr.columns:\n",
    "        out['mean_teacher_lifetime_projects_fully_funded'] = (\n",
    "            dpr.groupby('donor_id')['teacher_lifetime_projects_fully_funded'].mean()\n",
    "        )\n",
    "    \n",
    "    # Average lifetime donations received by teachers this donor supports\n",
    "    if 'teacher_lifetime_donations' in dpr.columns:\n",
    "        out['mean_teacher_lifetime_donations'] = (\n",
    "            dpr.groupby('donor_id')['teacher_lifetime_donations'].mean()\n",
    "        )\n",
    "    \n",
    "    # --- NEW: Project position preferences ---\n",
    "    # Percent of lifetime amount given to first gifts (gift_is_projects_first = 1)\n",
    "    if 'gift_is_projects_first' in dpr.columns:\n",
    "        out['pct_gifts_first_project'] = pct_count(dpr, 'gift_is_projects_first')\n",
    "        out['pct_amount_first_project'] = pct_amount(dpr, 'gift_is_projects_first')\n",
    "    \n",
    "    # Percent of lifetime amount given to last gifts (gift_is_projects_last = 1)\n",
    "    if 'gift_is_projects_last' in dpr.columns:\n",
    "        out['pct_gifts_last_project'] = pct_count(dpr, 'gift_is_projects_last')\n",
    "        out['pct_amount_last_project'] = pct_amount(dpr, 'gift_is_projects_last')\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Seasonality Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _seasonality_features(dpr_pre_T):\n",
    "    \"\"\"\n",
    "    Build features capturing temporal patterns in giving behavior.\n",
    "    \n",
    "    CORRECTED VERSION with:\n",
    "    - entropy_gift_month set to null/NaN if only one donation\n",
    "    \n",
    "    Features created:\n",
    "    - first_donation_month/quarter: When did they start?\n",
    "    - first_donation_dow_sin/cos: Day-of-week cyclic encoding\n",
    "    - pct_amount_in_back_to_school: Aug-Sep giving (7-10% of annual budget)\n",
    "    - pct_amount_in_final_week_of_year: Dec 24-31 giving (tax planning)\n",
    "    - pct_amount_on_weekends: Saturday/Sunday behavior\n",
    "    - pct_amount_in_top_month/quarter: Concentration in favorite period\n",
    "    - entropy_gift_month: How spread out is giving across months?\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dpr_pre_T : pd.DataFrame\n",
    "        Donor Project Records filtered to payment_date < T\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id\n",
    "    \"\"\"\n",
    "    if dpr_pre_T.empty:\n",
    "        return pd.DataFrame(index=pd.Index([], name='donor_id'))\n",
    "    \n",
    "    dpr = dpr_pre_T.copy()\n",
    "    out_index = dpr['donor_id'].unique()\n",
    "    out = pd.DataFrame(index=out_index)\n",
    "    \n",
    "    # Extract temporal components\n",
    "    dpr['gift_month'] = dpr['payment_date'].dt.month\n",
    "    dpr['gift_quarter'] = dpr['payment_date'].dt.quarter\n",
    "    dpr['gift_dow'] = dpr['payment_date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "    dpr['gift_day'] = dpr['payment_date'].dt.day\n",
    "    \n",
    "    # --- First donation temporal features ---\n",
    "    first_donation = dpr.sort_values(['donor_id', 'payment_date']).groupby('donor_id').first()\n",
    "    \n",
    "    out['first_donation_month'] = first_donation['gift_month']\n",
    "    out['first_donation_quarter'] = first_donation['gift_quarter']\n",
    "    \n",
    "    # Cyclic encoding of day-of-week (preserves weekend vs weekday similarity)\n",
    "    out['first_donation_dow_sin'] = np.sin(2 * np.pi * first_donation['gift_dow'] / 7)\n",
    "    out['first_donation_dow_cos'] = np.cos(2 * np.pi * first_donation['gift_dow'] / 7)\n",
    "    \n",
    "    # --- Seasonal concentration patterns ---\n",
    "    \n",
    "    # Back-to-school season (August-September)\n",
    "    dpr['is_back_to_school'] = dpr['gift_month'].isin([8, 9])\n",
    "    out['pct_amount_in_back_to_school'] = pct_amount(dpr, 'is_back_to_school')\n",
    "    \n",
    "    # Final week of year (tax planning, year-end giving)\n",
    "    dpr['is_final_week'] = (dpr['gift_month'] == 12) & (dpr['gift_day'] >= 24)\n",
    "    out['pct_amount_in_final_week_of_year'] = pct_amount(dpr, 'is_final_week')\n",
    "    \n",
    "    # Weekend giving (different behavior than weekday)\n",
    "    dpr['is_weekend'] = dpr['gift_dow'].isin([5, 6])  # Saturday=5, Sunday=6\n",
    "    out['pct_amount_on_weekends'] = pct_amount(dpr, 'is_weekend')\n",
    "    \n",
    "    # --- Peak period concentration ---\n",
    "    # What % of giving happens in donor's most active month?\n",
    "    month_amounts = dpr.groupby(['donor_id', 'gift_month'])['payment_amount'].sum()\n",
    "    top_month_amt = month_amounts.groupby('donor_id').max()\n",
    "    total_amt = dpr.groupby('donor_id')['payment_amount'].sum()\n",
    "    out['pct_amount_in_top_month'] = top_month_amt / (total_amt + 1e-9)\n",
    "    \n",
    "    # What % of giving happens in donor's most active quarter?\n",
    "    quarter_amounts = dpr.groupby(['donor_id', 'gift_quarter'])['payment_amount'].sum()\n",
    "    top_quarter_amt = quarter_amounts.groupby('donor_id').max()\n",
    "    out['pct_amount_in_top_quarter'] = top_quarter_amt / (total_amt + 1e-9)\n",
    "    \n",
    "    # --- Entropy of giving across months ---\n",
    "    # CORRECTED: Set to NaN if donor only has one donation\n",
    "    gift_counts = dpr.groupby('donor_id').size()\n",
    "    single_gift_donors = gift_counts[gift_counts == 1].index\n",
    "    \n",
    "    entropy_month = entropy_vectorized(dpr, 'donor_id', 'gift_month')\n",
    "    out['entropy_gift_month'] = entropy_month\n",
    "    out.loc[single_gift_donors, 'entropy_gift_month'] = np.nan\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Email Engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _email_features(email_pre_T, email_3m, email_12m, T):\n",
    "    \"\"\"\n",
    "    Build email engagement features from 12-month email summary data.\n",
    "    \n",
    "    Features created:\n",
    "    - emails_sent/opened/clicked for 3m and 12m windows\n",
    "    - open_rate, click_rate (clicks per email sent)\n",
    "    - email_open_rate_velocity: recent vs longer-term trend\n",
    "    - days_since_last_email_sent: recency\n",
    "    \n",
    "    Note: This uses monthly aggregated data, so recency is approximate\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    email_pre_T : pd.DataFrame\n",
    "        All email events before T\n",
    "    email_3m, email_12m : pd.DataFrame\n",
    "        Email events in respective windows\n",
    "    T : pd.Timestamp\n",
    "        Reference time\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id\n",
    "    \"\"\"\n",
    "    if email_pre_T.empty:\n",
    "        return pd.DataFrame(index=pd.Index([], name='donor_id'))\n",
    "    \n",
    "    def email_agg(df):\n",
    "        \"\"\"Aggregate email metrics for a given window\"\"\"\n",
    "        if df.empty:\n",
    "            idx = email_pre_T['donor_id'].unique()\n",
    "            zero = pd.Series(0, index=idx)\n",
    "            return zero, zero, zero, zero, zero\n",
    "        \n",
    "        by = df.groupby('donor_id')\n",
    "        sent = by['email_sent_count'].sum()\n",
    "        opened = by['email_open_count'].sum()\n",
    "        clicked = by['email_click_count'].sum()\n",
    "        \n",
    "        # Rates: opens/clicks per email sent\n",
    "        open_rate = opened / (sent + 1e-6)\n",
    "        click_rate = clicked / (sent + 1e-6)\n",
    "        \n",
    "        return sent, opened, clicked, open_rate, click_rate\n",
    "    \n",
    "    # Aggregate for both windows\n",
    "    sent_3, open_3, click_3, or_3, cr_3 = email_agg(email_3m)\n",
    "    sent_12, open_12, click_12, or_12, cr_12 = email_agg(email_12m)\n",
    "    \n",
    "    idx = email_pre_T['donor_id'].unique()\n",
    "    out = pd.DataFrame(index=idx)\n",
    "    \n",
    "    # 3-month window\n",
    "    out['emails_sent_3m'] = sent_3\n",
    "    out['emails_opened_3m'] = open_3\n",
    "    out['emails_clicked_3m'] = click_3\n",
    "    out['email_open_rate_3m'] = or_3\n",
    "    out['email_click_rate_3m'] = cr_3\n",
    "    \n",
    "    # 12-month window\n",
    "    out['emails_sent_12m'] = sent_12\n",
    "    out['emails_opened_12m'] = open_12\n",
    "    out['emails_clicked_12m'] = click_12\n",
    "    out['email_open_rate_12m'] = or_12\n",
    "    out['email_click_rate_12m'] = cr_12\n",
    "    \n",
    "    # Velocity: is engagement improving or declining?\n",
    "    # Positive = recent engagement higher than long-term average\n",
    "    out['email_open_rate_velocity_3m_vs_12m'] = or_3 - or_12\n",
    "    \n",
    "    # Recency (approximate, since data is monthly)\n",
    "    last_email_month = email_pre_T.groupby('donor_id')['email_month_start'].max()\n",
    "    out['days_since_last_email_sent'] = (T - last_email_month).dt.days\n",
    "    \n",
    "    # Note: email type mix features would go here if you have\n",
    "    # a mapping from email_type to type_group (appeal, newsletter, etc.)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Site Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _site_features(site_pre_T, site_3m, T):\n",
    "    \"\"\"\n",
    "    Build on-site browsing and engagement features.\n",
    "    \n",
    "    Features created:\n",
    "    - days_with_any_site_activity_3m: Active days count\n",
    "    - avg_sessions_per_active_day_3m: Session frequency\n",
    "    - avg_session_duration_min_3m: Session length\n",
    "    - checkout_intent_min_per_session_3m: Cart engagement\n",
    "    - days_since_last_cart_visit: Browse-to-buy recency (relative to T)\n",
    "    - campaign_session_share_3m: Attribution\n",
    "    - share_*_page_session_pct_3m: Page type mix\n",
    "    - device_share_*_3m: Device usage profile\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    site_pre_T : pd.DataFrame\n",
    "        Site events with activity_date < T\n",
    "    site_3m : pd.DataFrame\n",
    "        Site events with activity_date in [T-3m, T)\n",
    "    T : pd.Timestamp\n",
    "        As-of timestamp\n",
    "    \"\"\"\n",
    "    if site_pre_T.empty:\n",
    "        return pd.DataFrame(index=pd.Index([], name='donor_id'))\n",
    "\n",
    "    idx = site_pre_T['donor_id'].unique()\n",
    "    out = pd.DataFrame(index=idx)\n",
    "\n",
    "    # --- Recent activity metrics (3m window) ---\n",
    "    if not site_3m.empty:\n",
    "        # Days with any activity\n",
    "        activity_by_day = (\n",
    "            site_3m\n",
    "            .assign(any_activity=1)\n",
    "            .groupby(['donor_id', 'activity_date'])['any_activity']\n",
    "            .max()\n",
    "            .reset_index()\n",
    "        )\n",
    "        days_with_any = activity_by_day.groupby('donor_id')['activity_date'].nunique()\n",
    "        \n",
    "        # Session counts\n",
    "        sessions_by_donor = site_3m.groupby('donor_id').size()\n",
    "        \n",
    "        out['days_with_any_site_activity_3m'] = days_with_any\n",
    "        out['avg_sessions_per_active_day_3m'] = (\n",
    "            sessions_by_donor / (days_with_any + 1e-6)\n",
    "        )\n",
    "        \n",
    "        # Session duration (if available)\n",
    "        if 'session_duration_min' in site_3m.columns:\n",
    "            out['avg_session_duration_min_3m'] = (\n",
    "                site_3m.groupby('donor_id')['session_duration_min'].mean()\n",
    "            )\n",
    "        \n",
    "        # Checkout intent: cart visits per session\n",
    "        if 'cart_visits_day' in site_3m.columns:\n",
    "            out['checkout_intent_min_per_session_3m'] = (\n",
    "                site_3m.groupby('donor_id')['cart_visits_day'].sum()\n",
    "                / (sessions_by_donor + 1e-6)\n",
    "            )\n",
    "        \n",
    "        # Campaign attribution\n",
    "        if 'came_from_campaign' in site_3m.columns:\n",
    "            out['campaign_session_share_3m'] = (\n",
    "                site_3m.groupby('donor_id')['came_from_campaign'].mean()\n",
    "            )\n",
    "        \n",
    "        # --- Page type mix ---\n",
    "        # Ensure required columns exist with default 0\n",
    "        for col in ['project_page_visits_day', 'teacher_page_visits_day', 'search_visits_day']:\n",
    "            if col not in site_3m.columns:\n",
    "                site_3m[col] = 0\n",
    "        \n",
    "        page_counts = site_3m.groupby('donor_id').agg({\n",
    "            'project_page_visits_day': 'sum',\n",
    "            'teacher_page_visits_day': 'sum',\n",
    "            'search_visits_day'      : 'sum'\n",
    "        })\n",
    "        total_page_visits = page_counts.sum(axis=1) + 1e-6\n",
    "        \n",
    "        out['share_project_page_session_pct_3m'] = (\n",
    "            page_counts['project_page_visits_day'] / total_page_visits\n",
    "        )\n",
    "        out['share_teacher_page_session_pct_3m'] = (\n",
    "            page_counts['teacher_page_visits_day'] / total_page_visits\n",
    "        )\n",
    "        out['share_search_page_session_pct_3m'] = (\n",
    "            page_counts['search_visits_day'] / total_page_visits\n",
    "        )\n",
    "        \n",
    "        # --- Device profile ---\n",
    "        # Mobile-first, desktop-only, or mixed?\n",
    "        if 'device_type' in site_3m.columns:\n",
    "            # Normalize device_type to lowercase to match ['mobile', 'desktop', 'tablet']\n",
    "            dev_df = site_3m.copy()\n",
    "            dev_df['device_type'] = dev_df['device_type'].astype(str).str.lower()\n",
    "            \n",
    "            device_counts = (\n",
    "                dev_df.groupby(['donor_id', 'device_type'])\n",
    "                .size()\n",
    "                .unstack(fill_value=0)\n",
    "            )\n",
    "            total_device = device_counts.sum(axis=1) + 1e-6\n",
    "            \n",
    "            for dev in ['mobile', 'desktop', 'tablet']:\n",
    "                colname = f'device_share_{dev}_3m'\n",
    "                if dev in device_counts.columns:\n",
    "                    out[colname] = device_counts[dev] / total_device\n",
    "                else:\n",
    "                    out[colname] = 0.0\n",
    "\n",
    "    # --- Cart recency (using full history, relative to T) ---\n",
    "    if 'cart_visits_day' in site_pre_T.columns:\n",
    "        has_cart = site_pre_T[site_pre_T['cart_visits_day'] > 0]\n",
    "        if not has_cart.empty:\n",
    "            last_cart_date = has_cart.groupby('donor_id')['activity_date'].max()\n",
    "            out['days_since_last_cart_visit'] = (\n",
    "                (T - last_cart_date).dt.days\n",
    "            )\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 Share Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _share_features(share_pre_T, share_12m, T):\n",
    "    \"\"\"\n",
    "    Build social sharing behavior features.\n",
    "    \n",
    "    Features created:\n",
    "    - share_events_lifetime, share_events_12m: Volume\n",
    "    - share_active_months_12m: Frequency\n",
    "    - share_gap_mean/cv_days: Sharing rhythm\n",
    "    - share_month_coverage_ratio: Consistency over tenure\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    share_pre_T : pd.DataFrame\n",
    "        All share events before T\n",
    "    share_12m : pd.DataFrame\n",
    "        Share events in last 12 months\n",
    "    T : pd.Timestamp\n",
    "        Reference time\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id\n",
    "    \"\"\"\n",
    "    if share_pre_T.empty:\n",
    "        return pd.DataFrame(index=pd.Index([], name='donor_id'))\n",
    "    \n",
    "    out_index = share_pre_T['donor_id'].unique()\n",
    "    out = pd.DataFrame(index=out_index)\n",
    "    \n",
    "    # --- Volume metrics ---\n",
    "    out['share_events_lifetime'] = (\n",
    "        share_pre_T.groupby('donor_id')['share_event_count'].sum()\n",
    "    )\n",
    "    out['share_events_12m'] = (\n",
    "        share_12m.groupby('donor_id')['share_event_count'].sum()\n",
    "        if not share_12m.empty else 0\n",
    "    )\n",
    "    \n",
    "    # --- Active months (consistency) ---\n",
    "    if not share_12m.empty:\n",
    "        active_months_12m = (\n",
    "            share_12m[share_12m['share_event_count'] > 0]\n",
    "            .groupby('donor_id')['share_month_start']\n",
    "            .nunique()\n",
    "        )\n",
    "        out['share_active_months_12m'] = active_months_12m\n",
    "    \n",
    "    # --- Sharing rhythm: gaps between share months ---\n",
    "    def gap_stats(s):\n",
    "        if s.shape[0] < 2:\n",
    "            return pd.Series({\n",
    "                'share_gap_mean_days': np.nan,\n",
    "                'share_gap_cv_days': np.nan\n",
    "            })\n",
    "        # Sort by time, then diff\n",
    "        gaps = s.sort_values().diff().dropna().dt.days\n",
    "        mean = gaps.mean()\n",
    "        cv = gaps.std() / (mean + 1e-6)\n",
    "        return pd.Series({\n",
    "            'share_gap_mean_days': mean,\n",
    "            'share_gap_cv_days': cv\n",
    "        })\n",
    "\n",
    "    gap_df = (\n",
    "        share_pre_T.groupby('donor_id')['share_month_start']\n",
    "        .apply(gap_stats)\n",
    "        .unstack()          # columns: share_gap_mean_days, share_gap_cv_days\n",
    "    )\n",
    "\n",
    "    out = out.join(gap_df, how='left')\n",
    "\n",
    "    # --- Coverage ratio ---\n",
    "    first_share = share_pre_T.groupby('donor_id')['share_month_start'].min()\n",
    "    last_share = share_pre_T.groupby('donor_id')['share_month_start'].max()\n",
    "    \n",
    "    # Difference of two Periods is a DateOffset (e.g., <MonthEnd>); use .n to get month count\n",
    "    tenure_offsets = last_share.dt.to_period('M') - first_share.dt.to_period('M')\n",
    "    tenure_months = tenure_offsets.apply(lambda x: x.n if pd.notnull(x) else 0)\n",
    "    tenure_months = tenure_months.clip(lower=1)  # at least 1 month of tenure\n",
    "    \n",
    "    out['share_month_coverage_ratio'] = (\n",
    "        out.get('share_active_months_12m', 0) / (tenure_months + 1e-6)\n",
    "    )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.11 Same Schoool & Teacher Available Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _future_opportunity_features(dpr_pre_T, df_project_dates, T, H):\n",
    "    \"\"\"\n",
    "    Future opportunity features based on the donor's TOP (most-funded) school and teacher,\n",
    "    not just their first one.\n",
    "\n",
    "    For each donor:\n",
    "      - Find the school where they have given the most (by payment_amount).\n",
    "      - Find the teacher where they have given the most (by payment_amount).\n",
    "      - Flag whether that school/teacher has ANY project active in [T, T+H].\n",
    "\n",
    "    This approximates \"did the donor's favorite school/teacher have opportunities\n",
    "    to receive more gifts during the horizon\".\n",
    "    \"\"\"\n",
    "    # If we don't have project data or donations, return zeros\n",
    "    if df_project_dates is None or df_project_dates.empty or dpr_pre_T.empty:\n",
    "        idx = dpr_pre_T['donor_id'].unique()\n",
    "        return pd.DataFrame({\n",
    "            'school_still_available_during_range': 0,\n",
    "            'teacher_still_available_during_range': 0\n",
    "        }, index=pd.Index(idx, name='donor_id'))\n",
    "\n",
    "    # Work on copies\n",
    "    proj = df_project_dates.copy()\n",
    "    dpr = dpr_pre_T.copy()\n",
    "\n",
    "    # Ensure project date columns are datetime\n",
    "    for c in ['project_last_posted_date', 'project_funded_date', 'project_expiration_date']:\n",
    "        if c in proj.columns:\n",
    "            proj[c] = pd.to_datetime(proj[c], errors='coerce')\n",
    "\n",
    "    # Project end date = earlier of funded or expired\n",
    "    proj['end_date'] = proj[['project_funded_date', 'project_expiration_date']].min(axis=1)\n",
    "\n",
    "    # Normalize H\n",
    "    if isinstance(H, int):\n",
    "        H = pd.Timedelta(days=H)\n",
    "    elif H is None:\n",
    "        H = pd.Timedelta(days=365)\n",
    "\n",
    "    win_start = T\n",
    "    win_end = T + H\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 1) Identify TOP (most-funded) school and teacher per donor\n",
    "    # ----------------------------------------------------------------------\n",
    "    donor_index = dpr['donor_id'].unique()\n",
    "    out = pd.DataFrame(index=pd.Index(donor_index, name='donor_id'))\n",
    "\n",
    "    # Top school by total payment_amount\n",
    "    if {'school_id', 'payment_amount'}.issubset(dpr.columns):\n",
    "        school_agg = (\n",
    "            dpr.groupby(['donor_id', 'school_id'])['payment_amount']\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "        )\n",
    "        top_school = (\n",
    "            school_agg\n",
    "            .sort_values(['donor_id', 'payment_amount'], ascending=[True, False])\n",
    "            .groupby('donor_id')\n",
    "            .first()\n",
    "            .reset_index()[['donor_id', 'school_id']]\n",
    "        )\n",
    "    else:\n",
    "        top_school = pd.DataFrame(columns=['donor_id', 'school_id'])\n",
    "\n",
    "    # Top teacher by total payment_amount\n",
    "    if {'teacher_id', 'payment_amount'}.issubset(dpr.columns):\n",
    "        teacher_agg = (\n",
    "            dpr.groupby(['donor_id', 'teacher_id'])['payment_amount']\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "        )\n",
    "        top_teacher = (\n",
    "            teacher_agg\n",
    "            .sort_values(['donor_id', 'payment_amount'], ascending=[True, False])\n",
    "            .groupby('donor_id')\n",
    "            .first()\n",
    "            .reset_index()[['donor_id', 'teacher_id']]\n",
    "        )\n",
    "    else:\n",
    "        top_teacher = pd.DataFrame(columns=['donor_id', 'teacher_id'])\n",
    "\n",
    "    # If a donor has only one gift, top == first; so behavior matches what you described.\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 2) Precompute which schools/teachers have projects active in horizon\n",
    "    # ----------------------------------------------------------------------\n",
    "    proj['active_in_horizon'] = (\n",
    "        (proj['project_last_posted_date'] <= win_end) &\n",
    "        (proj['end_date'] >= win_start)\n",
    "    )\n",
    "\n",
    "    # Guard against missing columns, though in your data they should exist\n",
    "    if 'school_id' in proj.columns:\n",
    "        school_active = (\n",
    "            proj.groupby('school_id')['active_in_horizon']\n",
    "            .any()\n",
    "            .astype(int)\n",
    "        )\n",
    "    else:\n",
    "        school_active = pd.Series(dtype=int)\n",
    "\n",
    "    if 'teacher_id' in proj.columns:\n",
    "        teacher_active = (\n",
    "            proj.groupby('teacher_id')['active_in_horizon']\n",
    "            .any()\n",
    "            .astype(int)\n",
    "        )\n",
    "    else:\n",
    "        teacher_active = pd.Series(dtype=int)\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 3) Map top school/teacher to these activity flags\n",
    "    # ----------------------------------------------------------------------\n",
    "    # School: donor -> top school_id -> activity flag\n",
    "    if not top_school.empty:\n",
    "        school_flag = (\n",
    "            top_school\n",
    "            .set_index('donor_id')['school_id']\n",
    "            .map(school_active)\n",
    "            .reindex(donor_index)\n",
    "            .fillna(0)\n",
    "            .astype(int)\n",
    "        )\n",
    "    else:\n",
    "        school_flag = pd.Series(0, index=donor_index)\n",
    "\n",
    "    # Teacher: donor -> top teacher_id -> activity flag\n",
    "    if not top_teacher.empty:\n",
    "        teacher_flag = (\n",
    "            top_teacher\n",
    "            .set_index('donor_id')['teacher_id']\n",
    "            .map(teacher_active)\n",
    "            .reindex(donor_index)\n",
    "            .fillna(0)\n",
    "            .astype(int)\n",
    "        )\n",
    "    else:\n",
    "        teacher_flag = pd.Series(0, index=donor_index)\n",
    "\n",
    "    out['school_still_available_during_range'] = school_flag\n",
    "    out['teacher_still_available_during_range'] = teacher_flag\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.11 Project Outcomes & Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _project_outcome_features(dpr_pre_T):\n",
    "    \"\"\"\n",
    "    Build features describing project success and matching behavior.\n",
    "    \n",
    "    CORRECTED VERSION with:\n",
    "    - mean_match_multiplier: subtract 1 from all values, impute 0 for records with optional_donation_rate\n",
    "    \n",
    "    Features created:\n",
    "    - pct_projects_fully_funded: Success rate of projects supported\n",
    "    - pct_gifts_with_match: How often donations are matched\n",
    "    - mean_match_multiplier: Average EXCESS match (1.5 becomes 0.5), with 0s for optional donations\n",
    "    - mean/median_project_total_cost: Scale of projects supported\n",
    "    - median_donor_to_project_distance_mi: Geographic preference\n",
    "    - pct_gifts_within_15mi: Local giving behavior\n",
    "    - is_local_donor: Predominantly supports nearby schools\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dpr_pre_T : pd.DataFrame\n",
    "        Donor Project Records filtered to payment_date < T\n",
    "    T : pd.Timestamp\n",
    "        Reference time\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id\n",
    "    \"\"\"\n",
    "    if dpr_pre_T.empty:\n",
    "        return pd.DataFrame(index=pd.Index([], name='donor_id'))\n",
    "    \n",
    "    dpr = dpr_pre_T.copy()\n",
    "    out_index = dpr['donor_id'].unique()\n",
    "    out = pd.DataFrame(index=out_index)\n",
    "    \n",
    "    # --- Project success metrics ---\n",
    "    if 'project_got_fully_funded' in dpr.columns:\n",
    "        out['pct_projects_fully_funded'] = (\n",
    "            dpr.groupby('donor_id')['project_got_fully_funded'].mean()\n",
    "        )\n",
    "    elif 'project_fully_funded' in dpr.columns:\n",
    "        out['pct_projects_fully_funded'] = (\n",
    "            dpr.groupby('donor_id')['project_fully_funded'].mean()\n",
    "        )\n",
    "    \n",
    "    # --- Matching behavior ---\n",
    "    # 1. Subtract 1 from all match_xyi_multiplier values (so 1.5 becomes 0.5)\n",
    "    # 2. Impute 0 for records that have a value in optional_donation_rate\n",
    "    \n",
    "    if 'match_xyi_multiplier' in dpr.columns:\n",
    "        # Step 1: Filter to rows with optional_donation_rate present\n",
    "        dpr_with_optional = dpr[dpr['optional_donation_rate'].notna()].copy()\n",
    "        \n",
    "        if not dpr_with_optional.empty:\n",
    "            # Step 2: Calculate match_excess (subtract 1)\n",
    "            dpr_with_optional['match_excess'] = dpr_with_optional['match_xyi_multiplier'] - 1.0\n",
    "            \n",
    "            # Step 3: Fill nulls in match_excess with 0\n",
    "            dpr_with_optional['match_excess'] = dpr_with_optional['match_excess'].fillna(0)\n",
    "            \n",
    "            # Step 4: Calculate mean per donor\n",
    "            out['mean_match_multiplier'] = (\n",
    "                dpr_with_optional.groupby('donor_id')['match_excess'].mean()\n",
    "            )\n",
    "        else:\n",
    "            out['mean_match_multiplier'] = np.nan\n",
    "        \n",
    "        # Percent of gifts that received any match (before adjustments)\n",
    "        had_match = dpr['match_xyi_multiplier'] > 1.0\n",
    "        out['pct_gifts_with_match'] = (\n",
    "            dpr.groupby('donor_id')\n",
    "            .apply(lambda x: had_match.loc[x.index].mean())\n",
    "        )\n",
    "    \n",
    "    # --- Project cost metrics ---\n",
    "    out['mean_project_total_cost'] = dpr.groupby('donor_id')['project_total_cost'].mean()\n",
    "    out['median_project_total_cost'] = dpr.groupby('donor_id')['project_total_cost'].median()\n",
    "    \n",
    "    # --- Geographic patterns ---\n",
    "    if 'distance_mi' in dpr.columns:\n",
    "        out['median_donor_to_project_distance_mi'] = (\n",
    "            dpr.groupby('donor_id')['distance_mi'].median()\n",
    "        )\n",
    "        \n",
    "        # Local giving: within 15 miles\n",
    "        dpr['is_within_15mi'] = dpr['distance_mi'] <= 15\n",
    "        out['pct_gifts_within_15mi'] = (\n",
    "            dpr.groupby('donor_id')['is_within_15mi'].mean()\n",
    "        )\n",
    "        \n",
    "        # Predominantly local donor (>75% of gifts within 15 miles)\n",
    "        out['is_local_donor'] = (out['pct_gifts_within_15mi'] > 0.75).astype(int)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.12 Latest Donation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _latest_donation_features(dpr_pre_T, df_share, T):\n",
    "    \"\"\"\n",
    "    Extract features from each donor's most recent donation before time T.\n",
    "    \n",
    "    This captures the \"state\" of the donor at their last interaction,\n",
    "    which can be highly predictive of near-term behavior.\n",
    "    \n",
    "    Features include:\n",
    "    - Amount split by green vs non-green\n",
    "    - Project characteristics (cost, category, grade, fully funded status)\n",
    "    - Teacher metrics\n",
    "    - Payment type and optional donation behavior\n",
    "    - Geographic distance\n",
    "    - Referral channel (how they arrived)\n",
    "    - Social sharing behavior in the month of latest donation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dpr_pre_T : pd.DataFrame\n",
    "        Donor Project Records filtered to payment_date < T\n",
    "        Expected columns: donor_id, payment_date, payment_amount, \n",
    "        is_green_payment, project_total_cost, project_got_fully_funded,\n",
    "        teacher_lifetime_projects_fully_funded, gift_is_projects_first,\n",
    "        gift_is_projects_last, optional_donation_rate, payment_type,\n",
    "        project_category, project_grade, referral_source, \n",
    "        referral_medium, donor_lat_long, school_lat_long\n",
    "    df_share : pd.DataFrame\n",
    "        Share events with columns: donor_id, share_sent_month\n",
    "        share_sent_month format: \"YYYY-MM\" (e.g., \"2022-07\")\n",
    "    T : pd.Timestamp\n",
    "        Reference time (as-of date)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix indexed by donor_id with 'latest_*' columns\n",
    "    \"\"\"\n",
    "    \n",
    "    if dpr_pre_T.empty:\n",
    "        return pd.DataFrame(index=pd.Index([], name='donor_id'))\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Get most recent donation per donor\n",
    "    # =========================================================================\n",
    "    \n",
    "    latest = (\n",
    "        dpr_pre_T\n",
    "        .sort_values(['donor_id', 'payment_date'])\n",
    "        .groupby('donor_id', as_index=False)\n",
    "        .last()\n",
    "        .set_index('donor_id')\n",
    "    )\n",
    "    \n",
    "    out = pd.DataFrame(index=latest.index)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Amount features: split by green vs non-green\n",
    "    # =========================================================================\n",
    "    \n",
    "    # is_green_payment is string \"t\" or \"f\"\n",
    "    is_green = latest['is_green_payment'].isin(['t', 'T', True, 1])\n",
    "    \n",
    "    out['latest_gift_amount_green'] = np.where(\n",
    "        is_green, \n",
    "        latest['payment_amount'], \n",
    "        0\n",
    "    )\n",
    "    \n",
    "    out['latest_gift_amount_nongreen'] = np.where(\n",
    "        ~is_green,\n",
    "        latest['payment_amount'],\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Project characteristics\n",
    "    # =========================================================================\n",
    "    \n",
    "    out['latest_match_xyi_multiplier'] = latest.get('match_xyi_multiplier', np.nan)\n",
    "    out['latest_project_total_cost'] = latest['project_total_cost']\n",
    "    out['latest_project_got_fully_funded'] = latest['project_got_fully_funded'].astype(int)\n",
    "    \n",
    "    # Teacher metrics at time of latest donation\n",
    "    out['latest_teacher_lifetime_projects_fully_funded'] = latest.get(\n",
    "        'teacher_lifetime_projects_fully_funded', np.nan\n",
    "    )\n",
    "    \n",
    "    # Position in project funding sequence\n",
    "    out['latest_donation_is_projects_first'] = latest['gift_is_projects_first'].astype(int)\n",
    "    out['latest_donation_is_projects_last'] = latest['gift_is_projects_last'].astype(int)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Payment type and behavior\n",
    "    # =========================================================================\n",
    "    \n",
    "    out['latest_payment_type_is_green'] = is_green.astype(int)\n",
    "    \n",
    "    # Optional donation as percentage of total\n",
    "    out['latest_optional_donation_percent'] = latest.get('optional_donation_rate', 0)\n",
    "    \n",
    "    # Gift card purchase flag\n",
    "    if 'gift_card_purchase' in latest.columns:\n",
    "        out['latest_is_giftcard_purchase'] = (\n",
    "            latest['gift_card_purchase'].fillna(0).astype(int)\n",
    "        )\n",
    "    else:\n",
    "        out['latest_is_giftcard_purchase'] = 0\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Categorical features (for one-hot encoding downstream)\n",
    "    # =========================================================================\n",
    "    \n",
    "    out['latest_project_grade'] = latest['project_grade']\n",
    "    out['latest_project_category'] = latest['project_category']\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Referral channel (same logic as Repeat Donor Behaviors)\n",
    "    # =========================================================================\n",
    "    \n",
    "    valid_media = {\n",
    "        'email', 'directlink', 'facebook', 'nextdoor',\n",
    "        'sharetray', 'mobilesharetray', 'page', 'ig', 'sendfriend'\n",
    "    }\n",
    "    valid_sources = {'dc', 'google'}\n",
    "    \n",
    "    # If referral_medium is in valid_media, use it; otherwise use referral_source\n",
    "    # Treat non-dc/google sources as \"Oth\"\n",
    "    referral_source_clean = latest.get('referral_source', pd.Series(index=latest.index))\n",
    "    referral_source_clean = referral_source_clean.where(\n",
    "        referral_source_clean.isin(valid_sources),\n",
    "        'Oth'  # Replace non-dc/google sources with \"Oth\"\n",
    "    )\n",
    "    \n",
    "    referral_medium = latest.get('referral_medium', pd.Series(index=latest.index))\n",
    "    \n",
    "    out['latest_referral_channel'] = np.where(\n",
    "        referral_medium.isin(valid_media),\n",
    "        referral_medium,\n",
    "        referral_source_clean\n",
    "    )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Distance to school\n",
    "    # =========================================================================\n",
    "    \n",
    "    if 'distance_mi' in latest.columns:\n",
    "        out['latest_distance_mi'] = latest['distance_mi']\n",
    "    else:\n",
    "        out['latest_distance_mi'] = np.nan\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Social sharing in month of latest donation\n",
    "    # =========================================================================\n",
    "    \n",
    "    if df_share is not None and not df_share.empty:\n",
    "        # Extract year-month from latest donation date\n",
    "        latest_month = pd.to_datetime(latest['payment_date']).dt.to_period('M').astype(str)\n",
    "        \n",
    "        # Create a mapping of donor_id -> set of months they shared\n",
    "        share_months = (\n",
    "            df_share\n",
    "            .groupby('donor_id')['share_sent_month']\n",
    "            .apply(set)\n",
    "            .to_dict()\n",
    "        )\n",
    "        \n",
    "        # For each donor, check if they shared in their latest donation month\n",
    "        out['latest_shared_any'] = out.index.map(\n",
    "            lambda donor_id: int(\n",
    "                latest_month.loc[donor_id] in share_months.get(donor_id, set())\n",
    "                if donor_id in latest_month.index\n",
    "                else 0\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        out['latest_shared_any'] = 0\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.13 Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _build_labels(df_dpr, df_monthly, df_share, T, H):\n",
    "    \"\"\"\n",
    "    Build label/target variables for future horizon H.\n",
    "    \n",
    "    This is a basic implementation covering repeat giving labels.\n",
    "    You can extend this for:\n",
    "    - Monthly program labels (became_monthly, churned_monthly)\n",
    "    - Share labels (shared_in_H)\n",
    "    - Upgrade/downgrade labels\n",
    "    - High-value donor labels\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_dpr : pd.DataFrame\n",
    "        Complete donation records (not pre-filtered)\n",
    "    df_monthly : pd.DataFrame\n",
    "        Monthly subscription records\n",
    "    df_share : pd.DataFrame\n",
    "        Share events\n",
    "    T : pd.Timestamp\n",
    "        Start of label window\n",
    "    H : pd.Timedelta or int\n",
    "        Length of label window (e.g., 365 days for 12-month prediction)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    labels : pd.DataFrame\n",
    "        Label matrix indexed by donor_id\n",
    "    \"\"\"\n",
    "    T = pd.to_datetime(T)\n",
    "    if isinstance(H, int):\n",
    "        H = pd.Timedelta(days=H)\n",
    "    \n",
    "    start = T\n",
    "    end = T + H\n",
    "    \n",
    "    # --- Repeat giving labels ---\n",
    "    df_dpr = df_dpr.copy()\n",
    "    df_dpr['payment_date'] = pd.to_datetime(df_dpr['payment_date'])\n",
    "    \n",
    "    # Filter to label window\n",
    "    dpr_label = df_dpr[\n",
    "        (df_dpr['payment_date'] >= start) &\n",
    "        (df_dpr['payment_date'] < end)\n",
    "    ]\n",
    "    \n",
    "    by_label = dpr_label.groupby('donor_id')['payment_amount']\n",
    "    \n",
    "    # Basic repeat giving labels\n",
    "    gave_any_in_H = by_label.size().gt(0).astype(int)\n",
    "    gift_count_in_H = by_label.size()\n",
    "    gift_amount_in_H = by_label.sum()\n",
    "    median_gift_in_H = by_label.median()\n",
    "    \n",
    "    labels = pd.DataFrame(index=gave_any_in_H.index)\n",
    "    labels['gave_any_in_H'] = gave_any_in_H\n",
    "    labels['gift_count_in_H'] = gift_count_in_H\n",
    "    labels['gift_amount_in_H'] = gift_amount_in_H\n",
    "    labels['median_gift_amount_in_H'] = median_gift_in_H\n",
    "    \n",
    "    # Could add more labels here:\n",
    "    # - became_monthly_in_H (from df_monthly)\n",
    "    # - churned_monthly_in_H\n",
    "    # - shared_in_H (from df_share)\n",
    "    # - upgrade_in_H (median_gift_in_H > median_gift_12m)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Main Construction Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Build Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def build_features(\n",
    "    df_dpr,\n",
    "    df_email,\n",
    "    df_site,\n",
    "    df_monthly,\n",
    "    df_share,\n",
    "    df_zip_acs,\n",
    "    df_project_dates,\n",
    "    E,\n",
    "    T,\n",
    "    H=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Build complete donor-level feature matrix as of time T.\n",
    "    \n",
    "    This is the main entry point for feature engineering. It:\n",
    "    1. Normalizes all timestamps\n",
    "    2. Filters data to events before T\n",
    "    3. Creates windowed subsets (3m, 12m, 36m)\n",
    "    4. Calls helper functions for each feature group\n",
    "    5. Optionally builds labels for horizon H\n",
    "    \n",
    "    IMPORTANT: This does NOT do final imputation or encoding.\n",
    "    You should call finalize_features() after this to handle:\n",
    "    - Missing value imputation\n",
    "    - Categorical encoding\n",
    "    - Feature scaling (if desired)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_dpr : pd.DataFrame\n",
    "        Donor Project Records with columns:\n",
    "        - donor_id, payment_date, payment_amount, donation_n\n",
    "        - donor_zip, is_teacher, is_teacher_referred\n",
    "        - teacher_id, school_id, project_id, project_category, etc.\n",
    "    df_email : pd.DataFrame\n",
    "        Email Events 12mo with columns:\n",
    "        - donor_id, email_sent_month\n",
    "        - email_sent_count, email_open_count, email_click_count\n",
    "    df_site : pd.DataFrame\n",
    "        Site Events with columns:\n",
    "        - donor_id, activity_date\n",
    "        - device_type, came_from_campaign\n",
    "        - project_page_visits_day, teacher_page_visits_day, etc.\n",
    "    df_monthly : pd.DataFrame\n",
    "        Monthly DonationLevel with columns:\n",
    "        - donor_id, monthly_subscription_joined_date\n",
    "        - monthly_subscription_retired_date\n",
    "        - monthly_subscription_payment_amount, charge_date\n",
    "    df_share : pd.DataFrame\n",
    "        Share Events with columns:\n",
    "        - donor_id, share_sent_month, share_event_count\n",
    "    df_zip_acs : pd.DataFrame\n",
    "        ZIP-level ACS demographics with column:\n",
    "        - ZIP5 (index), pct_households_with_children, unemployment_rate, etc.\n",
    "    T : pd.Timestamp or str\n",
    "        Reference time (as-of date) for feature computation\n",
    "        All features use only data strictly before this timestamp\n",
    "    H : pd.Timedelta, int, or None\n",
    "        Label horizon (e.g., pd.Timedelta(days=365) or 365)\n",
    "        If provided, labels will be computed for window [T, T+H)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : pd.DataFrame\n",
    "        Donor-level feature matrix indexed by donor_id\n",
    "        Contains ~150 columns across 11 feature groups\n",
    "        May contain NaN values that should be imputed\n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "    >>> T = pd.Timestamp('2024-01-01')\n",
    "    >>> H = pd.Timedelta(days=365)  # 12-month prediction\n",
    "    >>> features = build_features(\n",
    "    ...     df_dpr, df_email, df_site, df_monthly, df_share, df_zip_acs,\n",
    "    ...     T=T, H=H\n",
    "    ... )\n",
    "    >>> print(features.shape)\n",
    "    (100000, 152)  # 100k donors, 152 features\n",
    "    \"\"\"\n",
    "    # =====================================================================\n",
    "    # SETUP: Convert dates and normalize T\n",
    "    # =====================================================================\n",
    "    \n",
    "    T = pd.to_datetime(T)\n",
    "    \n",
    "    # Convert all date columns upfront (before eligibility filtering)\n",
    "    df_dpr = df_dpr.copy()\n",
    "    df_dpr['payment_date'] = pd.to_datetime(df_dpr['payment_date'])\n",
    "    \n",
    "    df_monthly = df_monthly.copy()\n",
    "    df_monthly['monthly_subscription_joined_date'] = pd.to_datetime(\n",
    "        df_monthly['monthly_subscription_joined_date']\n",
    "    )\n",
    "    df_monthly['monthly_subscription_retired_date'] = pd.to_datetime(\n",
    "        df_monthly['monthly_subscription_retired_date']\n",
    "    )\n",
    "    if 'charge_date' in df_monthly.columns:\n",
    "        df_monthly['charge_date'] = pd.to_datetime(df_monthly['charge_date'])\n",
    "    \n",
    "    # =====================================================================\n",
    "    # ELIGIBILITY FILTERING (if requested)\n",
    "    # =====================================================================\n",
    "    \n",
    "    if E is not None:\n",
    "        eligibility_start = T - pd.DateOffset(months=E)\n",
    "        \n",
    "        # Donors with project donations in eligibility window\n",
    "        active_project_donors = df_dpr[\n",
    "            (df_dpr['payment_date'] >= eligibility_start) &\n",
    "            (df_dpr['payment_date'] < T)\n",
    "        ]['donor_id'].unique()\n",
    "        \n",
    "        # Donors active in monthly program during eligibility window\n",
    "        active_monthly_donors = df_monthly[\n",
    "            (df_monthly['monthly_subscription_joined_date'] < T) &\n",
    "            (df_monthly['monthly_subscription_retired_date'].isna() | \n",
    "             (df_monthly['monthly_subscription_retired_date'] >= eligibility_start))\n",
    "        ]['donor_id'].unique()\n",
    "        \n",
    "        # Union of active donors\n",
    "        base_donor_ids = pd.Index(\n",
    "            pd.unique(\n",
    "                pd.concat([\n",
    "                    pd.Series(active_project_donors),\n",
    "                    pd.Series(active_monthly_donors)\n",
    "                ], ignore_index=True)\n",
    "            ),\n",
    "            name='donor_id'\n",
    "        )        \n",
    "\n",
    "    else:\n",
    "        # Original behavior: all donors from both sources\n",
    "        base_donor_ids = pd.Index(\n",
    "            pd.unique(\n",
    "                pd.concat([\n",
    "                    df_dpr['donor_id'],\n",
    "                    df_monthly['donor_id']\n",
    "                ], ignore_index=True)\n",
    "            ),\n",
    "            name='donor_id'\n",
    "        )\n",
    "    \n",
    "    # Create master feature dataframe\n",
    "    features = pd.DataFrame(index=base_donor_ids)\n",
    "    \n",
    "    # Restrict all event tables to the base donor universe\n",
    "    df_dpr = df_dpr[df_dpr['donor_id'].isin(base_donor_ids)].copy()\n",
    "    df_email = df_email[df_email['donor_id'].isin(base_donor_ids)].copy()\n",
    "    df_site = df_site[df_site['donor_id'].isin(base_donor_ids)].copy()\n",
    "    df_monthly = df_monthly[df_monthly['donor_id'].isin(base_donor_ids)].copy()\n",
    "    df_share = df_share[df_share['donor_id'].isin(base_donor_ids)].copy()\n",
    "\n",
    "    # =====================================================================\n",
    "    # NORMALIZE DATES & FILTER PRE-T\n",
    "    # =====================================================================\n",
    "    \n",
    "    # DPR: main donation records\n",
    "    df_dpr = df_dpr.copy()\n",
    "    df_dpr['payment_date'] = pd.to_datetime(df_dpr['payment_date'])\n",
    "    dpr_pre_T = df_dpr[df_dpr['payment_date'] < T].copy()\n",
    "\n",
    "\n",
    "    # Precompute distances once using direct lat/lon â†’ miles\n",
    "    if {'donor_lat_long', 'school_lat_long'}.issubset(dpr_pre_T.columns):\n",
    "\n",
    "        # Parse lat/long strings into numeric columns\n",
    "        dpr_pre_T['donor_lat_long'] = dpr_pre_T['donor_lat_long'].astype(str)\n",
    "        dpr_pre_T['school_lat_long'] = dpr_pre_T['school_lat_long'].astype(str)\n",
    "\n",
    "        donor_lat_lon = dpr_pre_T['donor_lat_long'].str.split(',', expand=True)\n",
    "        school_lat_lon = dpr_pre_T['school_lat_long'].str.split(',', expand=True)\n",
    "\n",
    "        dpr_pre_T['donor_lat'] = donor_lat_lon[0].astype(float)\n",
    "        dpr_pre_T['donor_lon'] = donor_lat_lon[1].astype(float)\n",
    "        dpr_pre_T['school_lat'] = school_lat_lon[0].astype(float)\n",
    "        dpr_pre_T['school_lon'] = school_lat_lon[1].astype(float)\n",
    "\n",
    "        # Direct haversine distance from donor to project\n",
    "        dpr_pre_T['distance_mi'] = haversine_miles(\n",
    "            dpr_pre_T['donor_lat'],\n",
    "            dpr_pre_T['donor_lon'],\n",
    "            dpr_pre_T['school_lat'],\n",
    "            dpr_pre_T['school_lon'],\n",
    "        )\n",
    "    else:\n",
    "        dpr_pre_T['distance_mi'] = np.nan\n",
    "    \n",
    "    # Site events\n",
    "    df_site = df_site.copy()\n",
    "    df_site['activity_date'] = pd.to_datetime(df_site['activity_date'])\n",
    "    site_pre_T = df_site[df_site['activity_date'] < T].copy()\n",
    "    \n",
    "    # Share events (monthly aggregates)\n",
    "    df_share = df_share.copy()\n",
    "    df_share['share_month_start'] = pd.to_datetime(\n",
    "        df_share['share_sent_month']\n",
    "    ).dt.to_period('M').dt.to_timestamp()\n",
    "    share_pre_T = df_share[df_share['share_month_start'] < T].copy()\n",
    "    \n",
    "    # Email events (monthly aggregates)\n",
    "    df_email = df_email.copy()\n",
    "    df_email['email_month_start'] = pd.to_datetime(\n",
    "        df_email['email_sent_month']\n",
    "    ).dt.to_period('M').dt.to_timestamp()\n",
    "    email_pre_T = df_email[df_email['email_month_start'] < T].copy()\n",
    "    \n",
    "    # Monthly subscriptions\n",
    "    df_monthly = df_monthly.copy()\n",
    "    df_monthly['monthly_subscription_joined_date'] = pd.to_datetime(\n",
    "        df_monthly['monthly_subscription_joined_date']\n",
    "    )\n",
    "    df_monthly['monthly_subscription_retired_date'] = pd.to_datetime(\n",
    "        df_monthly['monthly_subscription_retired_date']\n",
    "    )\n",
    "    if 'charge_date' in df_monthly.columns:\n",
    "        df_monthly['charge_date'] = pd.to_datetime(df_monthly['charge_date'])\n",
    "    \n",
    "    md_pre_T = df_monthly[\n",
    "        df_monthly['monthly_subscription_joined_date'] < T\n",
    "    ].copy()\n",
    "    \n",
    "    # =====================================================================\n",
    "    # WINDOW BOUNDARIES\n",
    "    # =====================================================================\n",
    "    # These define our lookback periods for windowed features\n",
    "    \n",
    "    W_short_start = T - pd.DateOffset(months=3)   # [T-3m, T)\n",
    "    W_mid_start = T - pd.DateOffset(months=12)    # [T-12m, T)\n",
    "    W_long_start = T - pd.DateOffset(months=36)   # [T-36m, T)\n",
    "    \n",
    "    # Create windowed DPR subsets for counts, amounts, velocities\n",
    "    dpr_3m = dpr_pre_T[dpr_pre_T['payment_date'] >= W_short_start]\n",
    "    dpr_12m = dpr_pre_T[dpr_pre_T['payment_date'] >= W_mid_start]\n",
    "    dpr_36m = dpr_pre_T[dpr_pre_T['payment_date'] >= W_long_start]\n",
    "    \n",
    "    # Intermediate periods for velocity calculations\n",
    "    dpr_3to12m = dpr_pre_T[\n",
    "        (dpr_pre_T['payment_date'] >= W_mid_start) &\n",
    "        (dpr_pre_T['payment_date'] < W_short_start)\n",
    "    ]\n",
    "    dpr_12to36m = dpr_pre_T[\n",
    "        (dpr_pre_T['payment_date'] >= W_long_start) &\n",
    "        (dpr_pre_T['payment_date'] < W_mid_start)\n",
    "    ]\n",
    "    \n",
    "    # Email and site windows\n",
    "    email_12m = email_pre_T[email_pre_T['email_month_start'] >= W_mid_start]\n",
    "    email_3m = email_pre_T[email_pre_T['email_month_start'] >= W_short_start]\n",
    "    site_3m = site_pre_T[site_pre_T['activity_date'] >= W_short_start]\n",
    "    share_12m = share_pre_T[share_pre_T['share_month_start'] >= W_mid_start]\n",
    "    \n",
    "    # =====================================================================\n",
    "    # BUILD FEATURE GROUPS\n",
    "    # =====================================================================\n",
    "    # Each join adds a group of related features\n",
    "    # Using left joins to preserve all donor_ids\n",
    "    \n",
    "    # 1. Identity & ZIP / ACS demographics\n",
    "    features = features.join(\n",
    "        _identity_and_zip_features(dpr_pre_T, df_zip_acs, md_pre_T),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 2. Lifetime giving behavior & tenure\n",
    "    features = features.join(\n",
    "        _lifetime_giving_features(dpr_pre_T, T),  # Now includes T\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 3. Windowed giving & velocity trends\n",
    "    features = features.join(\n",
    "        _windowed_giving_features(\n",
    "            dpr_pre_T, dpr_3m, dpr_12m, dpr_36m, dpr_3to12m, dpr_12to36m, T\n",
    "        ),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 4. Channel/payment type mix\n",
    "    features = features.join(\n",
    "        _channel_mix_features(dpr_pre_T, dpr_12m),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 5. Monthly subscription program\n",
    "    features = features.join(\n",
    "        _monthly_features(md_pre_T, dpr_pre_T, dpr_12m, T),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 6. Teacher/school/content preferences\n",
    "    features = features.join(\n",
    "        _teacher_school_features(dpr_pre_T),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 7. Seasonality & rhythm patterns\n",
    "    features = features.join(\n",
    "        _seasonality_features(dpr_pre_T),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 8. Email engagement\n",
    "    features = features.join(\n",
    "        _email_features(email_pre_T, email_3m, email_12m, T),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 9. Site behavior\n",
    "    features = features.join(\n",
    "        _site_features(site_pre_T, site_3m, T),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 10. Share events\n",
    "    features = features.join(\n",
    "        _share_features(share_pre_T, share_12m, T),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 11. Project outcomes & matching\n",
    "    features = features.join(\n",
    "        _project_outcome_features(dpr_pre_T),\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # 12) School/teacher availability\n",
    "    if df_project_dates is not None and not df_project_dates.empty:\n",
    "        horizon = H if H is not None else pd.Timedelta(days=365)\n",
    "        features = features.join(\n",
    "            _future_opportunity_features(dpr_pre_T, df_project_dates, T, horizon),\n",
    "            how='left'\n",
    "        )\n",
    "    else:\n",
    "        features['school_still_available_during_range'] = 0\n",
    "        features['teacher_still_available_during_range'] = 0\n",
    "\n",
    "    # 13) Latest donation\n",
    "    f_latest = _latest_donation_features(\n",
    "        dpr_pre_T=dpr_pre_T,\n",
    "        df_share=df_share,\n",
    "        T=T\n",
    "    )\n",
    "    features = features.join(f_latest, how='left')\n",
    "    \n",
    "    # =====================================================================\n",
    "    # OPTIONAL: BUILD LABELS\n",
    "    # =====================================================================\n",
    "    # If H is provided, create labels for prediction horizon\n",
    "    \n",
    "    if H is not None:\n",
    "        labels = _build_labels(df_dpr, df_monthly, df_share, T, H)\n",
    "        features = features.join(labels, how='left')\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Filter Cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_cohort_filters(features, cohort_definitions):\n",
    "    \"\"\"\n",
    "    Filter feature dataframes by cohort definitions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    features : pd.DataFrame\n",
    "        Feature matrix from build_features()\n",
    "    cohort_definitions : list of dict\n",
    "        Each dict defines a cohort with keys:\n",
    "        - 'name': str - cohort identifier (used in output keys)\n",
    "        - 'filters': dict - {column_name: filter_spec}\n",
    "        \n",
    "        Filter specs can be:\n",
    "        - scalar: exact match (e.g., {'is_teacher': 1})\n",
    "        - tuple ('op', value): comparison operation\n",
    "          Supported ops: '>', '>=', '<', '<=', '==', '!='\n",
    "          (e.g., {'lifetime_gift_count': ('>', 3)})\n",
    "        - tuple ('between', low, high): inclusive range\n",
    "          (e.g., {'tenure_years': ('between', 1, 5)})\n",
    "        - list: isin check (e.g., {'state': ['CA', 'NY', 'TX']})\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict of pd.DataFrame\n",
    "        Keys are cohort names, values are filtered feature dataframes\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> cohorts = [\n",
    "    ...     {\n",
    "    ...         'name': 'teachers_3plus',\n",
    "    ...         'filters': {\n",
    "    ...             'is_teacher': 1,\n",
    "    ...             'lifetime_gift_count': ('>', 3)\n",
    "    ...         }\n",
    "    ...     },\n",
    "    ...     {\n",
    "    ...         'name': 'high_value_1to3yrs',\n",
    "    ...         'filters': {\n",
    "    ...             'lifetime_amount': ('>=', 500),\n",
    "    ...             'tenure_years': ('between', 1, 3)\n",
    "    ...         }\n",
    "    ...     },\n",
    "    ...     {\n",
    "    ...         'name': 'all_donors',\n",
    "    ...         'filters': {}  # No filtering\n",
    "    ...     }\n",
    "    ... ]\n",
    "    >>> \n",
    "    >>> result = apply_cohort_filters(train_features, cohorts)\n",
    "    >>> print(result.keys())\n",
    "    dict_keys(['teachers_3plus', 'high_value_1to3yrs', 'all_donors'])\n",
    "    >>> print(result['teachers_3plus'].shape)\n",
    "    (12543, 153)\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for cohort in cohort_definitions:\n",
    "        name = cohort['name']\n",
    "        filters = cohort.get('filters', {})\n",
    "        \n",
    "        # Start with all rows\n",
    "        mask = pd.Series(True, index=features.index)\n",
    "        \n",
    "        # Apply each filter\n",
    "        for col, spec in filters.items():\n",
    "            if col not in features.columns:\n",
    "                raise ValueError(f\"Column '{col}' not found in features\")\n",
    "            \n",
    "            col_data = features[col]\n",
    "            \n",
    "            # Handle different filter specifications\n",
    "            if isinstance(spec, tuple):\n",
    "                op = spec[0]\n",
    "                \n",
    "                if op == 'between' and len(spec) == 3:\n",
    "                    # Range filter\n",
    "                    low, high = spec[1], spec[2]\n",
    "                    mask &= (col_data >= low) & (col_data <= high)\n",
    "                \n",
    "                elif op in ('>', '>=', '<', '<=', '==', '!='):\n",
    "                    # Comparison filter\n",
    "                    value = spec[1]\n",
    "                    if op == '>':\n",
    "                        mask &= col_data > value\n",
    "                    elif op == '>=':\n",
    "                        mask &= col_data >= value\n",
    "                    elif op == '<':\n",
    "                        mask &= col_data < value\n",
    "                    elif op == '<=':\n",
    "                        mask &= col_data <= value\n",
    "                    elif op == '==':\n",
    "                        mask &= col_data == value\n",
    "                    elif op == '!=':\n",
    "                        mask &= col_data != value\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown operator: {op}\")\n",
    "            \n",
    "            elif isinstance(spec, list):\n",
    "                # isin filter\n",
    "                mask &= col_data.isin(spec)\n",
    "            \n",
    "            else:\n",
    "                # Exact match (scalar)\n",
    "                mask &= col_data == spec\n",
    "        \n",
    "        # Apply mask and store\n",
    "        results[name] = features[mask].copy()\n",
    "        \n",
    "        print(f\"Cohort '{name}': {mask.sum():,} donors ({mask.sum()/len(features)*100:.1f}%)\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Usage\n",
    "\n",
    "Here's how to use the pipeline with your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Example workflow (uncomment and adapt to your data)\\n\\n# 1. Load your data\\ndf_dpr = pd.read_csv('/Users/matt.fritz/Desktop/DonorProjectRecords_251118.csv')\\ndf_email = pd.read_csv('/Users/matt.fritz/Desktop/Email Events 36mo.csv')\\ndf_site = pd.read_csv('/Users/matt.fritz/Desktop/Site Events FY25-26.csv')\\ndf_monthly = pd.read_csv('/Users/matt.fritz/Desktop/Monthly Donation Data All Time.csv')\\ndf_share = pd.read_csv('/Users/matt.fritz/Desktop/Share Events All Time.csv')\\ndf_project_dates = pd.read_csv('/Users/matt.fritz/Desktop/Project Dates FY22-26.csv')\\ndf_zip_acs = pd.read_csv('/Users/matt.fritz/Desktop/Merged_Zip_ACS_Demographics.csv')\\n\\n# 2. Define reference time, horizon, and eligibility window\\neligibility_months = 12             # Only include donors who gave in N months prior to T\\nT = pd.Timestamp('2025-11-13')      # Training features end date \\nH = pd.Timedelta(days= 90)          # Label prediction horizon\\nO = pd.Timedelta(days=365)          # Out-of-time lag to apply to T\\n\\n# 3. Build features\\ntrain_features = build_features(\\n    df_dpr=df_dpr,\\n    df_email=df_email,\\n    df_site=df_site,\\n    df_monthly=df_monthly,\\n    df_share=df_share,\\n    df_project_dates=df_project_dates,\\n    df_zip_acs=df_zip_acs,\\n    eligibility_months=eligibility_months,\\n    T=T,\\n    H=H\\n)\\noot_features = build_features(\\n    df_dpr=df_dpr,\\n    df_email=df_email,\\n    df_site=df_site,\\n    df_monthly=df_monthly,\\n    df_share=df_share,\\n    df_project_dates=df_project_dates,\\n    df_zip_acs=df_zip_acs,\\n    eligibility_months=eligibility_months,\\n    T=T+O,\\n    H=H\\n)\\n\\n# 4. Finalize for modeling\\n# X, y = finalize_features(\\n#     features,\\n#     label_cols=['gave_any_in_H', 'gift_amount_in_H'],\\n#     numeric_impute_strategy='median'\\n# )\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Example workflow (uncomment and adapt to your data)\n",
    "\n",
    "# 1. Load your data\n",
    "df_dpr = pd.read_csv('/Users/matt.fritz/Desktop/DonorProjectRecords_251118.csv')\n",
    "df_email = pd.read_csv('/Users/matt.fritz/Desktop/Email Events 36mo.csv')\n",
    "df_site = pd.read_csv('/Users/matt.fritz/Desktop/Site Events FY25-26.csv')\n",
    "df_monthly = pd.read_csv('/Users/matt.fritz/Desktop/Monthly Donation Data All Time.csv')\n",
    "df_share = pd.read_csv('/Users/matt.fritz/Desktop/Share Events All Time.csv')\n",
    "df_project_dates = pd.read_csv('/Users/matt.fritz/Desktop/Project Dates FY22-26.csv')\n",
    "df_zip_acs = pd.read_csv('/Users/matt.fritz/Desktop/Merged_Zip_ACS_Demographics.csv')\n",
    "\n",
    "# 2. Define reference time, horizon, and eligibility window\n",
    "eligibility_months = 12             # Only include donors who gave in N months prior to T\n",
    "T = pd.Timestamp('2025-11-13')      # Training features end date \n",
    "H = pd.Timedelta(days= 90)          # Label prediction horizon\n",
    "O = pd.Timedelta(days=365)          # Out-of-time lag to apply to T\n",
    "\n",
    "# 3. Build features\n",
    "train_features = build_features(\n",
    "    df_dpr=df_dpr,\n",
    "    df_email=df_email,\n",
    "    df_site=df_site,\n",
    "    df_monthly=df_monthly,\n",
    "    df_share=df_share,\n",
    "    df_project_dates=df_project_dates,\n",
    "    df_zip_acs=df_zip_acs,\n",
    "    eligibility_months=eligibility_months,\n",
    "    T=T,\n",
    "    H=H\n",
    ")\n",
    "oot_features = build_features(\n",
    "    df_dpr=df_dpr,\n",
    "    df_email=df_email,\n",
    "    df_site=df_site,\n",
    "    df_monthly=df_monthly,\n",
    "    df_share=df_share,\n",
    "    df_project_dates=df_project_dates,\n",
    "    df_zip_acs=df_zip_acs,\n",
    "    eligibility_months=eligibility_months,\n",
    "    T=T+O,\n",
    "    H=H\n",
    ")\n",
    "\n",
    "# 4. Finalize for modeling\n",
    "# X, y = finalize_features(\n",
    "#     features,\n",
    "#     label_cols=['gave_any_in_H', 'gift_amount_in_H'],\n",
    "#     numeric_impute_strategy='median'\n",
    "# )'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cohort Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohort 'all_donors': 25,332 donors (100.0%)\n",
      "Cohort 'teachers_active': 2,375 donors (9.4%)\n",
      "Cohort 'high_ltv_mid_tenure': 3,746 donors (14.8%)\n",
      "Cohort 'monthly_only_subscribers': 10,792 donors (42.6%)\n",
      "Cohort 'all_donors': 30,325 donors (100.0%)\n",
      "Cohort 'teachers_active': 3,360 donors (11.1%)\n",
      "Cohort 'high_ltv_mid_tenure': 4,968 donors (16.4%)\n",
      "Cohort 'monthly_only_subscribers': 9,447 donors (31.2%)\n",
      "\n",
      "all_donors:\n",
      "  Train: (25332, 169)\n",
      "  OOT:   (30325, 180)\n",
      "\n",
      "teachers_active:\n",
      "  Train: (2375, 169)\n",
      "  OOT:   (3360, 180)\n",
      "\n",
      "high_ltv_mid_tenure:\n",
      "  Train: (3746, 169)\n",
      "  OOT:   (4968, 180)\n",
      "\n",
      "monthly_only_subscribers:\n",
      "  Train: (10792, 169)\n",
      "  OOT:   (9447, 180)\n"
     ]
    }
   ],
   "source": [
    "# 1. Load your data\n",
    "df_dpr = pd.read_csv('/Users/matt.fritz/Desktop/DonorProjectRecords_251118.csv')\n",
    "df_email = pd.read_csv('/Users/matt.fritz/Desktop/Email Events 36mo.csv')\n",
    "df_site = pd.read_csv('/Users/matt.fritz/Desktop/Site Events FY25-26.csv')\n",
    "df_monthly = pd.read_csv('/Users/matt.fritz/Desktop/Monthly Donation Data All Time.csv')\n",
    "df_share = pd.read_csv('/Users/matt.fritz/Desktop/Share Events All Time.csv')\n",
    "df_project_dates = pd.read_csv('/Users/matt.fritz/Desktop/Project Dates FY22-26.csv')\n",
    "df_zip_acs = pd.read_csv('/Users/matt.fritz/Desktop/Merged_Zip_ACS_Demographics.csv')\n",
    "\n",
    "# 2. Define reference time, horizon, and eligibility window\n",
    "E = 12                              # Only donors who gave in E months prior to T are eligible\n",
    "T = pd.Timestamp('2024-07-01')      # Training features end date \n",
    "H = pd.Timedelta(days= 90)          # Label prediction horizon\n",
    "O = pd.Timedelta(days=365)          # Out-of-time lag to apply to T\n",
    "\n",
    "'''\n",
    "                                    ELIGIBILITY\n",
    "                              T-E | ----------- |\n",
    "                                  \n",
    "                              TRAINING FEATURES       TRAINING LABEL\n",
    "  | ALL HISTORY ------------------------------- | T | -------------- | T+H\n",
    "                                                      \n",
    "                                                      OOT LAG\n",
    "                                                    | -- O -- |\n",
    "                                                    \n",
    "                                                 OOT FEATURES           OOT LABEL\n",
    "  | ALL HISTORY --------------------------------------------- | T+O | -------------- | T+O+H\n",
    "'''\n",
    "\n",
    "# 3. Define your cohorts\n",
    "cohorts = [\n",
    "    {\n",
    "        'name': 'all_donors',\n",
    "        'filters': {}\n",
    "    },\n",
    "    {\n",
    "        'name': 'teachers_active',\n",
    "        'filters': {\n",
    "            'is_teacher': 1,\n",
    "            'lifetime_gift_count': ('>', 3)\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'high_ltv_mid_tenure',\n",
    "        'filters': {\n",
    "            'lifetime_amount': ('>=', 500),\n",
    "            'tenure_years': ('between', 1, 5)\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'monthly_only_subscribers',\n",
    "        'filters': {\n",
    "            'is_monthly_only_donor': 1\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# 4. Build features\n",
    "train_features = build_features(\n",
    "    df_dpr=df_dpr,\n",
    "    df_email=df_email,\n",
    "    df_site=df_site,\n",
    "    df_monthly=df_monthly,\n",
    "    df_share=df_share,\n",
    "    df_project_dates=df_project_dates,\n",
    "    df_zip_acs=df_zip_acs,\n",
    "    E=E,\n",
    "    T=T,\n",
    "    H=H\n",
    ")\n",
    "oot_features = build_features(\n",
    "    df_dpr=df_dpr,\n",
    "    df_email=df_email,\n",
    "    df_site=df_site,\n",
    "    df_monthly=df_monthly,\n",
    "    df_share=df_share,\n",
    "    df_project_dates=df_project_dates,\n",
    "    df_zip_acs=df_zip_acs,\n",
    "    E=E,\n",
    "    T=T+O,\n",
    "    H=H\n",
    ")\n",
    "\n",
    "# 5. Generate cohorts\n",
    "train_cohorts = apply_cohort_filters(train_features, cohorts)\n",
    "oot_cohorts = apply_cohort_filters(oot_features, cohorts)\n",
    "\n",
    "# Now you have dictionaries of dataframes for each cohort\n",
    "for cohort_name in cohorts:\n",
    "    name = cohort_name['name']\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Train: {train_cohorts[name].shape}\")\n",
    "    print(f\"  OOT:   {oot_cohorts[name].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Inventory\n",
    "\n",
    "Quick reference of all features by category:\n",
    "\n",
    "### Identity & Demographics (17 features)\n",
    "- donor_zip5, is_teacher, is_teacher_referred\n",
    "- is_marketing_subscribed, is_major_gift_donor\n",
    "- ever_used_account_credit, current_account_credit_balance\n",
    "- zip_* (9 ACS features)\n",
    "\n",
    "### Lifetime Giving (14 features)\n",
    "- first_donation_date, last_donation_date\n",
    "- tenure_days, tenure_years, tenure_bucket\n",
    "- lifetime_gift_count, lifetime_amount\n",
    "- lifetime_median/max/cv_gift_amount\n",
    "- mean/cv_gap_between_gifts_days\n",
    "- max_donation_sequence_number\n",
    "- pct_early_gifts_in_lifetime\n",
    "\n",
    "### Windowed Giving (12 features)\n",
    "- gift_count/amount/median_amount for 3m, 12m, 36m\n",
    "- days_since_last/second_to_last_gift\n",
    "- amount_velocity_0to3_vs_3to12\n",
    "- amount/count_velocity_0to12_vs_12to36\n",
    "\n",
    "### Channel Mix (26 features)\n",
    "- pct_amount/count_daf (lifetime, 12m)\n",
    "- pct_amount/count_green (lifetime, 12m)\n",
    "- pct_gifts/amount_gift_card (lifetime, 12m)\n",
    "- pct_amount/count_big_event (lifetime, 12m)\n",
    "- avg_optional_donation_rate (lifetime, 12m)\n",
    "- pct_gifts_anonymous (lifetime, 12m)\n",
    "- pct_amount_classroom_essentials (lifetime, 12m)\n",
    "\n",
    "### Monthly Program (10 features)\n",
    "- is_monthly_donor_current\n",
    "- monthly_lifetime_amount, monthly_amount_12m\n",
    "- monthly_median_gift_amount\n",
    "- pct_amount_monthly (lifetime, 12m)\n",
    "- months_on_program, months_since_last_monthly_charge\n",
    "- monthly_longest_streak_months\n",
    "- monthly_joined_before_first_project_gift\n",
    "\n",
    "### Teacher/School Preferences (17 features)\n",
    "- entropy_* (5: teacher, school, zip, category, grade)\n",
    "- num_unique_* (5)\n",
    "- pct_amount_to_top_* (4)\n",
    "- pct_gifts_first/last_project\n",
    "- mean_teacher_lifetime_projects_fully_funded\n",
    "- mean_teacher_lifetime_donations\n",
    "\n",
    "### Seasonality (10 features)\n",
    "- pct_amount_in_back_to_school\n",
    "- pct_amount_in_final_week_of_year\n",
    "- pct_amount_on_weekends\n",
    "- entropy_gift_month\n",
    "- pct_amount_in_top_month/quarter\n",
    "- first_donation_month/quarter\n",
    "- first_donation_dow_sin/cos\n",
    "\n",
    "### Email Engagement (11 features)\n",
    "- emails_sent/opened/clicked (3m, 12m)\n",
    "- email_open/click_rate (3m, 12m)\n",
    "- email_open_rate_velocity_3m_vs_12m\n",
    "- days_since_last_email_sent\n",
    "\n",
    "### Site Behavior (11 features)\n",
    "- days_with_any_site_activity_3m\n",
    "- avg_sessions_per_active_day_3m\n",
    "- avg_session_duration_min_3m\n",
    "- checkout_intent_min_per_session_3m\n",
    "- days_since_last_cart_visit\n",
    "- campaign_session_share_3m\n",
    "- share_*_page_session_pct_3m (3)\n",
    "- device_share_*_3m (3)\n",
    "\n",
    "### Share Events (5 features)\n",
    "- share_events_lifetime/12m\n",
    "- share_active_months_12m\n",
    "- share_gap_mean/cv_days\n",
    "- share_month_coverage_ratio\n",
    "\n",
    "### Project Outcomes (8 features)\n",
    "- pct_projects_fully_funded\n",
    "- mean/median_project_total_cost\n",
    "- mean_match_multiplier\n",
    "- pct_gifts_with_match\n",
    "- median_donor_to_project_distance_mi\n",
    "- pct_gifts_within_15mi\n",
    "- is_local_donor\n",
    "\n",
    "### Labels (4 features, if H provided)\n",
    "- gave_any_in_H\n",
    "- gift_count_in_H\n",
    "- gift_amount_in_H\n",
    "- median_gift_amount_in_H\n",
    "\n",
    "**Total: ~145+ base features** (before one-hot encoding categoricals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Notes & Best Practices\n",
    "\n",
    "### Time Scope Summary\n",
    "\n",
    "- **STATIC**: Does not depend on T\n",
    "  - ZIP/ACS features\n",
    "  - Some \"once ever\" flags (is_major_gift_donor, etc.)\n",
    "  - First donation seasonality\n",
    "\n",
    "- **AS_OF_T**: Cumulative through time T\n",
    "  - Lifetime giving metrics\n",
    "  - Distance/locality\n",
    "  - Channel mix (lifetime)\n",
    "  - Teacher/school concentration\n",
    "  - Overall seasonality patterns\n",
    "\n",
    "- **WINDOWED**: Specific lookback relative to T\n",
    "  - 3m/12m/36m counts & amounts\n",
    "  - Velocity metrics\n",
    "  - Email engagement (3m/12m)\n",
    "  - Site behavior (3m)\n",
    "  - Share activity (12m)\n",
    "\n",
    "- **LABEL**: Future horizon [T, T+H)\n",
    "  - Repeat giving targets\n",
    "  - Monthly program changes\n",
    "  - Upgrade/downgrade indicators\n",
    "\n",
    "### Key Design Decisions\n",
    "\n",
    "1. **No duplicate concepts**: Single distance metric, single velocity pattern\n",
    "2. **Consistent windows**: 3m (short), 12m (mid), 36m (long)\n",
    "3. **Defensive epsilon**: Small values (1e-6) prevent division by zero\n",
    "4. **Separation of concerns**: Feature engineering â‰  imputation\n",
    "5. **Time-relative**: All features parameterized by T\n",
    "\n",
    "### Recommended Workflow\n",
    "\n",
    "1. **Build features** for each training example at different T values\n",
    "2. **Finalize features** with consistent imputation strategy\n",
    "3. **Feature selection** based on importance/correlation\n",
    "4. **Model training** with cross-validation\n",
    "5. **Production scoring** with latest T value\n",
    "\n",
    "### Common Pitfalls to Avoid\n",
    "\n",
    "- **Leakage**: Don't use features from [T, T+H) for predictions\n",
    "- **Inconsistent windows**: Always use same T-relative boundaries\n",
    "- **Missing joins**: Ensure all tables have donor_id\n",
    "- **Scale mismatch**: Consider feature scaling for some models\n",
    "- **Category explosion**: Monitor one-hot encoding dimension\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "- For large datasets, consider building features in chunks\n",
    "- Cache intermediate results (windowed subsets)\n",
    "- Use categorical dtypes to save memory\n",
    "- Consider feature hashing for high-cardinality categoricals\n",
    "- Profile your code to identify bottlenecks\n",
    "\n",
    "### Extensions\n",
    "\n",
    "This schema can be extended with:\n",
    "- Interaction features (e.g., tenure Ã— amount)\n",
    "- Polynomial features for non-linear patterns\n",
    "- Embedding features from text (project descriptions)\n",
    "- Time-series features (rolling statistics)\n",
    "- Graph features (donor networks)\n",
    "- External data (economic indicators, events)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
